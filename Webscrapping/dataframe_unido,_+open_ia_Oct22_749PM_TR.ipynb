{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E90TNwUPLJqr",
    "outputId": "713a38dd-de60-466e-ab8c-d53d7aa7fc7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GoogleNews\n",
      "  Downloading GoogleNews-1.6.15-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (4.13.5)\n",
      "Collecting dateparser (from GoogleNews)\n",
      "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (2.9.0.post0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (4.15.0)\n",
      "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2025.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2024.11.6)\n",
      "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (5.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->GoogleNews) (1.17.0)\n",
      "Downloading GoogleNews-1.6.15-py3-none-any.whl (8.8 kB)\n",
      "Downloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dateparser, GoogleNews\n",
      "Successfully installed GoogleNews-1.6.15 dateparser-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkSvsAjyLKZa",
    "outputId": "8df348e6-3a14-48cf-a1a9-e69dda0c1050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
      "Collecting newspaper3k\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.5)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.3)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.4.0)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.4)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.15.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2025.10.5)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.20.0)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=a139028e1ff25cbab59e3b46f717cb62447ca845de77a0ca4e1daf9cd67ea93b\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=291702234c4fac824b3104b8a9f2ee532d6e9d2837395e97b49578b8ee92c44c\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=9faa73b185a5c3b73edaff1ead4a70228a915f17ba010d58d51890742c525fbe\n",
      "  Stored in directory: /root/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=ef4723508acf11b7fd5707fa0a9ad594df7f779bd9c48fc3e037b64312a4f680\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
      "Successfully installed cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.12 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-3.0.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.3.0\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.37.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Downloading selenium-4.37.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 selenium-4.37.0 trio-0.31.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Collecting serpapi\n",
      "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from serpapi) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2025.10.5)\n",
      "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: serpapi\n",
      "Successfully installed serpapi-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install newspaper3k\n",
    "!pip install selenium\n",
    "!pip install openai\n",
    "!pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3VyXVu0LQTp",
    "outputId": "c3127526-bdd9-4503-89b3-0e5e63748022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googlesearch-python\n",
      "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (4.13.5)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (2.32.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2025.10.5)\n",
      "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
      "Installing collected packages: googlesearch-python\n",
      "Successfully installed googlesearch-python-1.3.0\n",
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.10.5)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=4b9c62eb35b6f893b1ba8ee918bba2f015f61fb1b8296585c58478db50d20020\n",
      "  Stored in directory: /root/.cache/pip/wheels/0c/47/f5/89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install googlesearch-python\n",
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLtwWsAHLUgx",
    "outputId": "9abac1b3-a99d-4111-a82b-c445c1ca82a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx[http2] in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (3.11)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.3.0)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx[http2]) (0.16.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"httpx[http2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FUaqRMNLvHz",
    "outputId": "90274436-a75c-41f4-9cea-549d19abfa5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
      "Collecting lxml_html_clean (from lxml[html_clean])\n",
      "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install \"lxml[html_clean]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TyeXW1uiL0sD"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NoVtb1yKNoa"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from GoogleNews import GoogleNews\n",
    "from serpapi import GoogleSearch\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# ================================================================\n",
    "# Keys\n",
    "# ================================================================\n",
    "OPENAI_API_KEY = \"\"\n",
    "SerpAPI_tkn1 = \"\"\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d81230e5"
   },
   "outputs": [],
   "source": [
    "!pip install GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oJYCffFKmMS",
    "outputId": "d4250cf5-422f-4071-ac20-c1edc942bb29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "🔥 INICIANDO SCRAPER + ANÁLISIS IA\n",
      "============================================================\n",
      "\n",
      "📰 FASE 1: Recopilando noticias...\n",
      "\n",
      "🔍 Buscando en El Tiempo: paro maestros 2023\n",
      "📰 Encontrados 15 artículos en El Tiempo\n",
      "\n",
      "🔍 Buscando en El Tiempo: paro nacional docentes 2023\n",
      "📰 Encontrados 15 artículos en El Tiempo\n",
      "\n",
      "🔍 Buscando en El Tiempo: ADE 2023\n",
      "📰 Encontrados 15 artículos en El Tiempo\n",
      "\n",
      "🔍 Buscando en El Tiempo: FECODE 2023\n",
      "📰 Encontrados 15 artículos en El Tiempo\n",
      "\n",
      "🔍 Buscando en ADE: paro docentes\n",
      "📰 Encontrados 0 artículos en ADE\n",
      "\n",
      "🔍 Buscando en ADE: paro maestros\n",
      "📰 Encontrados 0 artículos en ADE\n",
      "\n",
      "🔍 Buscando en ADE: Fecode\n",
      "📰 Encontrados 0 artículos en ADE\n",
      "\n",
      "🔍 Buscando en ADE: educación Bogotá\n",
      "📰 Encontrados 0 artículos en ADE\n",
      "\n",
      "🔍 Buscando en FECODE: paro nacional\n",
      "❌ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=paro+nacional\n",
      "\n",
      "🔍 Buscando en FECODE: paro docentes\n",
      "❌ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=paro+docentes\n",
      "\n",
      "🔍 Buscando en FECODE: maestros\n",
      "❌ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=maestros\n",
      "\n",
      "🔍 Buscando en FECODE: educación Colombia\n",
      "❌ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=educaci%C3%B3n+Colombia\n",
      "✅ GoogleNews: 100 resultados\n",
      "\n",
      "🔍 Buscando con SerpAPI...\n",
      " • (\"suspensión de clases\" OR \"cese de actividades\" OR \"interrupción académica\") Bogotá 2023\n",
      " • (\"paro de maestros\" OR \"paro docente\" OR \"huelga de profesores\") Bogotá 2023\n",
      " • (\"interrupción de clases\" OR \"cancelación de clases\") Bogotá 2023\n",
      " • (\"sindicato de maestros\" OR \"FECODE\" OR \"ADE Bogotá\") AND (paro OR huelga) 2023\n",
      "✅ SerpAPI: 40 resultados\n",
      "\n",
      "✅ Total de noticias recopiladas: 140\n",
      "\n",
      "🤖 FASE 2: Analizando con IA...\n",
      "\n",
      "[1/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores...\n",
      "\n",
      "[2/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[3/140]   🤖 Analizando: Confirman suspensión de clases en estos colegios de Bogotá d...\n",
      "\n",
      "[4/140]   🤖 Analizando: Caso Maestro Esteban: Fue declarado culpable por muerte de a...\n",
      "\n",
      "[5/140]   🤖 Analizando: Confirmado: no habrá clases a partir del 23 de junio en todo...\n",
      "\n",
      "[6/140]   🤖 Analizando: Las razones detrás del paro nacional del 28 y 29 de mayo...\n",
      "\n",
      "[7/140]   🤖 Analizando: Paro Nacional 28 de mayo: Rutas y puntos de concentración en...\n",
      "\n",
      "[8/140]   🤖 Analizando: ¿Adiós a las clases?: esto pasará si el sindicato de docente...\n",
      "\n",
      "[9/140]   🤖 Analizando: Paro nacional del 28 y 29 de mayo podría ser un “pulso polít...\n",
      "\n",
      "[10/140]   🤖 Analizando: Paro nacional de transportistas: aymaras, docentes y transpo...\n",
      "\n",
      "[11/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores...\n",
      "\n",
      "[12/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[13/140]   🤖 Analizando: Confirman suspensión de clases en estos colegios de Bogotá d...\n",
      "\n",
      "[14/140]   🤖 Analizando: Caso Maestro Esteban: Fue declarado culpable por muerte de a...\n",
      "\n",
      "[15/140]   🤖 Analizando: Confirmado: no habrá clases a partir del 23 de junio en todo...\n",
      "\n",
      "[16/140]   🤖 Analizando: Las razones detrás del paro nacional del 28 y 29 de mayo...\n",
      "\n",
      "[17/140]   🤖 Analizando: Paro Nacional 28 de mayo: Rutas y puntos de concentración en...\n",
      "\n",
      "[18/140]   🤖 Analizando: ¿Adiós a las clases?: esto pasará si el sindicato de docente...\n",
      "\n",
      "[19/140]   🤖 Analizando: Paro nacional del 28 y 29 de mayo podría ser un “pulso polít...\n",
      "\n",
      "[20/140]   🤖 Analizando: Paro nacional de transportistas: aymaras, docentes y transpo...\n",
      "\n",
      "[21/140]   🤖 Analizando: Fecode anunció paro nacional de maestros: habrá concentracio...\n",
      "\n",
      "[22/140]   🤖 Analizando: Paro docente confirmado: todos los maestros adhieren y no ha...\n",
      "\n",
      "[23/140]   🤖 Analizando: Fecode confirma paro nacional de 24 horas el 30 de octubre y...\n",
      "\n",
      "[24/140]   🤖 Analizando: Anuncian nuevo paro nacional en Colombia: la movilidad se ve...\n",
      "\n",
      "[25/140]   🤖 Analizando: Docentes de Bogotá continúan en paro: Secretaría de Educació...\n",
      "\n",
      "[26/140]   🤖 Analizando: ¿Qué actividades realizarán hoy los maestros del Eje Cafeter...\n",
      "\n",
      "[27/140]   🤖 Analizando: Paro de profesores de 72 horas en el Eje Cafetero: marchas e...\n",
      "\n",
      "[28/140]   🤖 Analizando: ¿Dónde marcharán esta semana los maestros del Eje Cafetero e...\n",
      "\n",
      "[29/140]   🤖 Analizando: Paro de docentes de Eje Cafetero durará 72 horas: marchas en...\n",
      "\n",
      "[30/140]   🤖 Analizando: Sintrenal advierte paro nacional indefinido en el sector edu...\n",
      "\n",
      "[31/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores...\n",
      "\n",
      "[32/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[33/140]   🤖 Analizando: Confirman suspensión de clases en estos colegios de Bogotá d...\n",
      "\n",
      "[34/140]   🤖 Analizando: Caso Maestro Esteban: Fue declarado culpable por muerte de a...\n",
      "\n",
      "[35/140]   🤖 Analizando: Confirmado: no habrá clases a partir del 23 de junio en todo...\n",
      "\n",
      "[36/140]   🤖 Analizando: Las razones detrás del paro nacional del 28 y 29 de mayo...\n",
      "\n",
      "[37/140]   🤖 Analizando: Paro Nacional 28 de mayo: Rutas y puntos de concentración en...\n",
      "\n",
      "[38/140]   🤖 Analizando: ¿Adiós a las clases?: esto pasará si el sindicato de docente...\n",
      "\n",
      "[39/140]   🤖 Analizando: Paro nacional del 28 y 29 de mayo podría ser un “pulso polít...\n",
      "\n",
      "[40/140]   🤖 Analizando: Paro nacional de transportistas: aymaras, docentes y transpo...\n",
      "\n",
      "[41/140]   🤖 Analizando: Fecode anunció paro nacional de maestros: habrá concentracio...\n",
      "\n",
      "[42/140]   🤖 Analizando: Paro docente confirmado: todos los maestros adhieren y no ha...\n",
      "\n",
      "[43/140]   🤖 Analizando: Fecode confirma paro nacional de 24 horas el 30 de octubre y...\n",
      "\n",
      "[44/140]   🤖 Analizando: Anuncian nuevo paro nacional en Colombia: la movilidad se ve...\n",
      "\n",
      "[45/140]   🤖 Analizando: Docentes de Bogotá continúan en paro: Secretaría de Educació...\n",
      "\n",
      "[46/140]   🤖 Analizando: ¿Qué actividades realizarán hoy los maestros del Eje Cafeter...\n",
      "\n",
      "[47/140]   🤖 Analizando: Paro de profesores de 72 horas en el Eje Cafetero: marchas e...\n",
      "\n",
      "[48/140]   🤖 Analizando: ¿Dónde marcharán esta semana los maestros del Eje Cafetero e...\n",
      "\n",
      "[49/140]   🤖 Analizando: Paro de docentes de Eje Cafetero durará 72 horas: marchas en...\n",
      "\n",
      "[50/140]   🤖 Analizando: Sintrenal advierte paro nacional indefinido en el sector edu...\n",
      "\n",
      "[51/140]   🤖 Analizando: Paro magisterial deja sin clases a más de un millón de estud...\n",
      "\n",
      "[52/140]   🤖 Analizando: Acuerdo histórico en Bogotá: docentes recuperan salarios y e...\n",
      "\n",
      "[53/140]   🤖 Analizando: Sindicatos del Sena anuncian paro nacional de 24 horas este ...\n",
      "\n",
      "[54/140]   🤖 Analizando: Confirmado: no habrá clases a partir del 23 de junio en todo...\n",
      "\n",
      "[55/140]   🤖 Analizando: Noticias Tolima: Grave déficit de profesores en colegio de P...\n",
      "\n",
      "[56/140]   🤖 Analizando: Secretaría de Educación reveló qué pasará con los colegios e...\n",
      "\n",
      "[57/140]   🤖 Analizando: ¿Habrá clases por el Paro Nacional de este 28 y 29 de mayo?...\n",
      "\n",
      "[58/140]   🤖 Analizando: Un feminicidio en la Universidad del Valle reabre el debate ...\n",
      "\n",
      "[59/140]   🤖 Analizando: Crisis en la Normal Superior de Charalá: más de 700 estudian...\n",
      "\n",
      "[60/140]   🤖 Analizando: Paros de maestros: la tensión entre la protesta y la educaci...\n",
      "\n",
      "[61/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores...\n",
      "\n",
      "[62/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[63/140]   🤖 Analizando: Confirman suspensión de clases en estos colegios de Bogotá d...\n",
      "\n",
      "[64/140]   🤖 Analizando: Caso Maestro Esteban: Fue declarado culpable por muerte de a...\n",
      "\n",
      "[65/140]   🤖 Analizando: Confirmado: no habrá clases a partir del 23 de junio en todo...\n",
      "\n",
      "[66/140]   🤖 Analizando: Las razones detrás del paro nacional del 28 y 29 de mayo...\n",
      "\n",
      "[67/140]   🤖 Analizando: Paro Nacional 28 de mayo: Rutas y puntos de concentración en...\n",
      "\n",
      "[68/140]   🤖 Analizando: ¿Adiós a las clases?: esto pasará si el sindicato de docente...\n",
      "\n",
      "[69/140]   🤖 Analizando: Paro nacional del 28 y 29 de mayo podría ser un “pulso polít...\n",
      "\n",
      "[70/140]   🤖 Analizando: Paro nacional de transportistas: aymaras, docentes y transpo...\n",
      "\n",
      "[71/140]   🤖 Analizando: Fecode anunció paro nacional de maestros: habrá concentracio...\n",
      "\n",
      "[72/140]   🤖 Analizando: Paro docente confirmado: todos los maestros adhieren y no ha...\n",
      "\n",
      "[73/140]   🤖 Analizando: Fecode confirma paro nacional de 24 horas el 30 de octubre y...\n",
      "\n",
      "[74/140]   🤖 Analizando: Anuncian nuevo paro nacional en Colombia: la movilidad se ve...\n",
      "\n",
      "[75/140]   🤖 Analizando: Docentes de Bogotá continúan en paro: Secretaría de Educació...\n",
      "\n",
      "[76/140]   🤖 Analizando: ¿Qué actividades realizarán hoy los maestros del Eje Cafeter...\n",
      "\n",
      "[77/140]   🤖 Analizando: Paro de profesores de 72 horas en el Eje Cafetero: marchas e...\n",
      "\n",
      "[78/140]   🤖 Analizando: ¿Dónde marcharán esta semana los maestros del Eje Cafetero e...\n",
      "\n",
      "[79/140]   🤖 Analizando: Paro de docentes de Eje Cafetero durará 72 horas: marchas en...\n",
      "\n",
      "[80/140]   🤖 Analizando: Sintrenal advierte paro nacional indefinido en el sector edu...\n",
      "\n",
      "[81/140]   🤖 Analizando: Paro magisterial deja sin clases a más de un millón de estud...\n",
      "\n",
      "[82/140]   🤖 Analizando: Acuerdo histórico en Bogotá: docentes recuperan salarios y e...\n",
      "\n",
      "[83/140]   🤖 Analizando: Sindicatos del Sena anuncian paro nacional de 24 horas este ...\n",
      "\n",
      "[84/140]   🤖 Analizando: Confirmado: no habrá clases a partir del 23 de junio en todo...\n",
      "\n",
      "[85/140]   🤖 Analizando: Noticias Tolima: Grave déficit de profesores en colegio de P...\n",
      "\n",
      "[86/140]   🤖 Analizando: Secretaría de Educación reveló qué pasará con los colegios e...\n",
      "\n",
      "[87/140]   🤖 Analizando: ¿Habrá clases por el Paro Nacional de este 28 y 29 de mayo?...\n",
      "\n",
      "[88/140]   🤖 Analizando: Un feminicidio en la Universidad del Valle reabre el debate ...\n",
      "\n",
      "[89/140]   🤖 Analizando: Crisis en la Normal Superior de Charalá: más de 700 estudian...\n",
      "\n",
      "[90/140]   🤖 Analizando: Paros de maestros: la tensión entre la protesta y la educaci...\n",
      "\n",
      "[91/140]   🤖 Analizando: ¿Qué está pasando en la Universidad Nacional? Vicerrectora, ...\n",
      "\n",
      "[92/140]   🤖 Analizando: Paro docente confirmado: todos los maestros adhieren y no ha...\n",
      "\n",
      "[93/140]   🤖 Analizando: Fecode anunció nuevo paro nacional en octubre: ¿estudiantes ...\n",
      "\n",
      "[94/140]   🤖 Analizando: Soacha suspenderá clases en colegios públicos por paro de co...\n",
      "\n",
      "[95/140]   🤖 Analizando: Suspensión de clases presenciales en instituciones educativa...\n",
      "\n",
      "[96/140]   🤖 Analizando: Colegios oficiales de Soacha suspenden clases por paro en Bo...\n",
      "\n",
      "[97/140]   🤖 Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[98/140]   🤖 Analizando: Suspenden clases por gran manifestación de conductores en Bo...\n",
      "\n",
      "[99/140]   🤖 Analizando: Paro en Bogotá 16 de septiembre: estos colegios ya confirmar...\n",
      "\n",
      "[100/140]   🤖 Analizando: Maestros del Eje Cafetero protestan en Bogotá y exigen mejor...\n",
      "\n",
      "[101/140]   🤖 Analizando: CIRCULAR No. 004 de 2023 PARA...\n",
      "\n",
      "[102/140]   🤖 Analizando: Concepto 217971 de 2023 Departamento Administrativo ......\n",
      "\n",
      "[103/140]   🤖 Analizando: Protestas en Bogotá 28 y 29 de marzo 2023...\n",
      "\n",
      "[104/140]   🤖 Analizando: cundinamarca...\n",
      "\n",
      "[105/140]   🤖 Analizando: Sentencia T-210 de 2023 Corte Constitucional de Colombia...\n",
      "\n",
      "[106/140]   🤖 Analizando: Sala Laboral señala que no puede haber una prohibición ......\n",
      "\n",
      "[107/140]   🤖 Analizando: Protesta de profesores en Bogotá: así avanza la marcha...\n",
      "\n",
      "[108/140]   🤖 Analizando: Información sobre las acciones de hecho de la Junta ......\n",
      "\n",
      "[109/140]   🤖 Analizando: Marchas HOY 28 de marzo Bogotá: Minuto a ......\n",
      "\n",
      "[110/140]   🤖 Analizando: T-577/23...\n",
      "\n",
      "[111/140]   🤖 Analizando: Paro nacional de profesores, 30 de agosto de 2023: fecha ......\n",
      "\n",
      "[112/140]   🤖 Analizando: Fecode anuncia paro nacional de maestros por 24 horas ......\n",
      "\n",
      "[113/140]   🤖 Analizando: MAÑANA HAY CLASES | Se levanta el paro docente ......\n",
      "\n",
      "[114/140]   🤖 Analizando: María Fernanda Cabal les pide a los profesores que ......\n",
      "\n",
      "[115/140]   🤖 Analizando: Sindicato de maestros Sintrenal convocan paro nacional ......\n",
      "\n",
      "[116/140]   🤖 Analizando: “Por legítimas que sean las demandas, el paro afecta ......\n",
      "\n",
      "[117/140]   🤖 Analizando: Qué es el Fomag y por qué está a punto de causar un paro ......\n",
      "\n",
      "[118/140]   🤖 Analizando: Paro de Fecode: ¿Qué tan grave está el sistema de salud ......\n",
      "\n",
      "[119/140]   🤖 Analizando: Paro de maestros por 48 horas: puntos de concentración...\n",
      "\n",
      "[120/140]   🤖 Analizando: ‍♀️ Paro martes 14/03 y ⚠ASAMBLEA en 📌Escuela Julio ......\n",
      "\n",
      "[121/140]   🤖 Analizando: Calendario Académico...\n",
      "\n",
      "[122/140]   🤖 Analizando: COLEGIO DIANA TURBAY IED - Bogotá...\n",
      "\n",
      "[123/140]   🤖 Analizando: Agenda Colegio Luis Amigó 2023...\n",
      "\n",
      "[124/140]   🤖 Analizando: MANUAL DE CONVIVENCIA 2024 COLEGIO TIBABUYES ......\n",
      "\n",
      "[125/140]   🤖 Analizando: informe anual 2023...\n",
      "\n",
      "[126/140]   🤖 Analizando: Malestar entre los padres de familia de la Institución ......\n",
      "\n",
      "[127/140]   🤖 Analizando: incidencia de los comportamientos disruptivos de...\n",
      "\n",
      "[128/140]   🤖 Analizando: Terminos-y-Condiciones-10-de-descuento-Intensivo- ......\n",
      "\n",
      "[129/140]   🤖 Analizando: Prueba Aprender: en primaria, la mitad de los chicos no ......\n",
      "\n",
      "[130/140]   🤖 Analizando: Humor sobre la Cancelación de Clases en la Escuela...\n",
      "\n",
      "[131/140]   🤖 Analizando: Convocan a paro nacional de profesores para este 30 ......\n",
      "\n",
      "[132/140]   🤖 Analizando: Secretaría de Prensa y Comunicaciones...\n",
      "\n",
      "[133/140]   🤖 Analizando: ¿Cuándo hay paro de FECODE 2023? Día de marchas y ......\n",
      "\n",
      "[134/140]   🤖 Analizando: Sindicato de maestros convocó a paro el 29 y 30 de ......\n",
      "\n",
      "[135/140]   🤖 Analizando: Fecode anuncia paro nacional de maestros por 24 horas ......\n",
      "\n",
      "[136/140]   🤖 Analizando: Fecode anunció un paro nacional para el próximo 30 de ......\n",
      "\n",
      "[137/140]   🤖 Analizando: ¿Cuándo es el Paro de FECODE en Bogotá? Fecha oficial ......\n",
      "\n",
      "[138/140]   🤖 Analizando: Estudiantes pierden hasta un 35% del tiempo de clase al ......\n",
      "\n",
      "[139/140]   🤖 Analizando: Los viejos y nuevos motivos de las marchas ......\n",
      "\n",
      "[140/140]   🤖 Analizando: fecode...\n",
      "\n",
      "💾 FASE 3: Guardando resultados...\n",
      "✅ Archivo guardado: noticias_paros_docentes_2023_ANALIZADO.csv\n",
      "📊 Total de noticias: 140\n",
      "\n",
      "============================================================\n",
      "📈 ESTADÍSTICAS DEL ANÁLISIS\n",
      "============================================================\n",
      "🔴 Paros verdaderos (con suspensión de clases): 58\n",
      "📍 Eventos en Bogotá: 67\n",
      "⏱️ Duración promedio: 4.0 días\n",
      "\n",
      "🎉 ¡Análisis completado!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================================================\n",
    "# 🌐 PARTE 1: FUNCIONES DE SCRAPING (Tu código original)\n",
    "# ================================================================\n",
    "\n",
    "def buscar_noticias_generales(nombre_fuente, url_base, termino_busqueda, max_resultados=15):\n",
    "    \"\"\"\n",
    "    🔍 EXPLICACIÓN:\n",
    "    Esta función busca noticias en sitios web específicos (El Tiempo, ADE, FECODE).\n",
    "\n",
    "    - Construye una URL de búsqueda usando el término\n",
    "    - Hace una petición HTTP para obtener el HTML\n",
    "    - Usa BeautifulSoup para extraer información de los artículos\n",
    "    - Devuelve una lista de diccionarios con los datos de cada noticia\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔍 Buscando en {nombre_fuente}: {termino_busqueda}\")\n",
    "    datos = []\n",
    "\n",
    "    # quote_plus convierte espacios en + para URLs (ej: \"paro maestros\" → \"paro+maestros\")\n",
    "    termino_codificado = quote_plus(termino_busqueda)\n",
    "    url_busqueda = f\"{url_base}{termino_codificado}\"\n",
    "\n",
    "    # User-Agent simula que somos un navegador real (algunos sitios bloquean bots)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url_busqueda, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # Lanza error si status code != 200\n",
    "\n",
    "        # BeautifulSoup parsea el HTML para poder buscar elementos\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # find_all busca todos los tags <article> (donde suelen estar las noticias)\n",
    "        articulos = soup.find_all('article', limit=max_resultados)\n",
    "        print(f\"📰 Encontrados {len(articulos)} artículos en {nombre_fuente}\")\n",
    "\n",
    "        for articulo in articulos:\n",
    "            # Extrae título (busca <h2>), descripción (<p>), link (<a>), fecha (<time>)\n",
    "            titulo = articulo.find('h2').get_text(strip=True) if articulo.find('h2') else \"\"\n",
    "            descripcion = articulo.find('p').get_text(strip=True) if articulo.find('p') else \"\"\n",
    "            link_elem = articulo.find('a', href=True)\n",
    "            link = link_elem['href'] if link_elem else \"\"\n",
    "\n",
    "            # Si el link es relativo (ej: /noticia/123), lo convierte a absoluto\n",
    "            if link and not link.startswith('http'):\n",
    "                link = f\"{url_base.rstrip('/')}/{link.lstrip('/')}\"\n",
    "\n",
    "            fecha_elem = articulo.find('time')\n",
    "            fecha = fecha_elem.get_text(strip=True) if fecha_elem else 'N/A'\n",
    "\n",
    "            # Solo guarda si tiene título válido\n",
    "            if titulo and len(titulo) > 10:\n",
    "                datos.append({\n",
    "                    'titulo': titulo,\n",
    "                    'fuente': nombre_fuente,\n",
    "                    'fecha_publicacion': fecha,\n",
    "                    'descripcion': descripcion,\n",
    "                    'url': link,\n",
    "                    'periodo_busqueda': termino_busqueda,\n",
    "                    'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en {nombre_fuente}: {e}\")\n",
    "\n",
    "    return datos\n",
    "\n",
    "\n",
    "def buscar_con_googlenews():\n",
    "    \"\"\"\n",
    "    🔍 EXPLICACIÓN:\n",
    "    Usa la librería GoogleNews para buscar noticias en español.\n",
    "\n",
    "    - set_time_range limita resultados al año 2023\n",
    "    - Hace múltiples búsquedas con diferentes queries\n",
    "    - Devuelve lista de noticias encontradas\n",
    "    \"\"\"\n",
    "    googlenews = GoogleNews(lang='es', encode='utf-8')\n",
    "    googlenews.set_time_range('01/01/2023', '12/31/2023')\n",
    "\n",
    "    queries = [\n",
    "    # Originales\n",
    "    '\"paro de docentes\" Bogotá \"clases suspendidas 2023\"',\n",
    "    '(paro OR \"cese de actividades 2023\") AND (docentes OR maestros) AND Bogotá',\n",
    "    '\"estudiantes sin clase 2023\" AND paro Bogotá 2023',\n",
    "    '\"suspensión de clases\" AND docentes Bogotá',\n",
    "\n",
    "    # Mejoradas\n",
    "    '(\"paro de docentes\" OR \"cese de actividades\") AND Bogotá AND (\"clases suspendidas\" OR \"clases interrumpidas\") AND 2023',\n",
    "    '(paro OR \"cese de actividades\") AND (docentes OR maestros OR profesores) AND Bogotá AND 2023',\n",
    "    '(\"estudiantes sin clase\" OR \"no hay clases\" OR \"interrupción académica\") AND paro AND Bogotá AND 2023',\n",
    "    '(\"suspensión de clases\" OR \"clases suspendidas\" OR \"no hay clases\") AND (docentes OR maestros) AND Bogotá AND 2023'\n",
    "]\n",
    "\n",
    "\n",
    "    resultados = []\n",
    "    for q in queries:\n",
    "        googlenews.search(q)\n",
    "        time.sleep(random.uniform(2, 4))  # Espera aleatoria para no ser bloqueado\n",
    "        res = googlenews.result()\n",
    "\n",
    "        for r in res:\n",
    "            resultados.append({\n",
    "                'titulo': r.get('title'),\n",
    "                'fuente': r.get('media'),\n",
    "                'fecha_publicacion': r.get('date'),\n",
    "                'descripcion': '',\n",
    "                'url': r.get('link'),\n",
    "                'periodo_busqueda': q,\n",
    "                'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            })\n",
    "\n",
    "    print(f\"✅ GoogleNews: {len(resultados)} resultados\")\n",
    "    return resultados\n",
    "\n",
    "\n",
    "def buscar_con_serpapi(api_key):\n",
    "    \"\"\"\n",
    "    🔍 EXPLICACIÓN:\n",
    "    Usa SerpAPI (servicio de pago) para buscar en Google de forma programática.\n",
    "\n",
    "    - Permite búsquedas avanzadas con operadores de Google\n",
    "    - Devuelve resultados estructurados (organic_results)\n",
    "    - Más confiable que el scraping directo\n",
    "    \"\"\"\n",
    "    print(\"\\n🔍 Buscando con SerpAPI...\")\n",
    "    queries = [\n",
    "        '(\"suspensión de clases\" OR \"cese de actividades\" OR \"interrupción académica\") Bogotá 2023',\n",
    "        '(\"paro de maestros\" OR \"paro docente\" OR \"huelga de profesores\") Bogotá 2023',\n",
    "        '(\"interrupción de clases\" OR \"cancelación de clases\") Bogotá 2023',\n",
    "        '(\"sindicato de maestros\" OR \"FECODE\" OR \"ADE Bogotá\") AND (paro OR huelga) 2023',\n",
    "    ]\n",
    "\n",
    "    resultados = []\n",
    "    for query in queries:\n",
    "        print(f\" • {query}\")\n",
    "        params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"q\": f\"{query} after:2023-01-01 before:2023-12-31\",\n",
    "            \"api_key\": api_key,\n",
    "            \"num\": 50,  # Número máximo de resultados por query\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            search = GoogleSearch(params)\n",
    "            results = search.get_dict()\n",
    "            items = results.get(\"organic_results\", [])\n",
    "\n",
    "            for item in items:\n",
    "                resultados.append({\n",
    "                    'titulo': item.get('title'),\n",
    "                    'fuente': 'Google (SerpAPI)',\n",
    "                    'fecha_publicacion': '',\n",
    "                    'descripcion': item.get('snippet', ''),\n",
    "                    'url': item.get('link'),\n",
    "                    'periodo_busqueda': query,\n",
    "                    'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error con SerpAPI: {e}\")\n",
    "\n",
    "    print(f\"✅ SerpAPI: {len(resultados)} resultados\")\n",
    "    return resultados\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 🤖 PARTE 2: ANÁLISIS CON IA (Tu código de OpenAI adaptado)\n",
    "# ================================================================\n",
    "\n",
    "def obtener_texto_completo(url):\n",
    "    \"\"\"\n",
    "    📄 EXPLICACIÓN:\n",
    "    Descarga el contenido completo de una URL y extrae solo el texto legible.\n",
    "\n",
    "    - Elimina scripts, estilos, headers, footers (no son contenido útil)\n",
    "    - stripped_strings elimina espacios innecesarios\n",
    "    - Limita a 8000 caracteres para no exceder límites de OpenAI\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=15)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        # Elimina elementos que no son contenido principal\n",
    "        for s in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"aside\", \"form\"]):\n",
    "            s.extract()\n",
    "\n",
    "        texto = \" \".join(soup.stripped_strings)\n",
    "        return texto[:8000]  # Máximo 8000 caracteres\n",
    "    except Exception as e:\n",
    "        return f\"Error al obtener contenido: {e}\"\n",
    "\n",
    "\n",
    "def analizar_con_ia(titulo, descripcion, url):\n",
    "    \"\"\"\n",
    "    🤖 EXPLICACIÓN (LA MÁS IMPORTANTE):\n",
    "    Esta función envía la noticia a GPT-4 para que la analice siguiendo criterios estrictos.\n",
    "\n",
    "    PROCESO:\n",
    "    1. Intenta descargar el contenido completo de la URL\n",
    "    2. Si falla, usa solo título + descripción, indicame si pudiste o no acceder al URL\n",
    "    3. Construye un prompt detallado con instrucciones para la IA\n",
    "    4. Envía el prompt a OpenAI (modelo gpt-4o-mini)\n",
    "    5. Recibe respuesta en formato JSON\n",
    "    6. Parsea el JSON y devuelve un diccionario con las características\n",
    "\n",
    "    CARACTERÍSTICAS QUE ANALIZA:\n",
    "    - es_paro_docente: ¿Hubo suspensión de clases?\n",
    "    - organizaciones_sindicales: ¿Qué sindicatos u organizaciones políticas participaron?\n",
    "    - duracion_dias: ¿Cuántos días duró?\n",
    "    - ubicacion_bogota: ¿Ocurrió en Bogotá?\n",
    "    - ubicacion_Colombia: ¿Abarcó todo el territorio Nacional=\n",
    "    - costo_mencionado: ¿Se habla de costos económicos?\n",
    "    - fecha_paro: ¿cuál es la fecha exacta del paro (día, mes, año)? \n",
    "    \"\"\"\n",
    "    print(f\"  🤖 Analizando: {titulo[:60]}...\")\n",
    "\n",
    "    # Intenta obtener contenido completo de la URL\n",
    "    contenido_completo = obtener_texto_completo(url) if url else \"\"\n",
    "\n",
    "    # Si no pudo descargar el contenido, usa título + descripción\n",
    "    if \"Error\" in contenido_completo or not contenido_completo:\n",
    "        texto_analizar = f\"Título: {titulo}\\nDescripción: {descripcion}\"\n",
    "    else:\n",
    "        texto_analizar = contenido_completo\n",
    "\n",
    "    # ============================================\n",
    "    # 📝 PROMPT PARA LA IA\n",
    "    # ============================================\n",
    "    # Este es el \"cerebro\" del análisis. Le dice a GPT exactamente qué debe hacer.\n",
    "    prompt = f\"\"\"\n",
    "Analiza la siguiente noticia en español sobre educación, sindicatos o protestas de docentes.\n",
    "\n",
    "CRITERIOS ESTRICTOS:\n",
    "- Un **paro docente verdadero** solo existe si hubo suspensión de clases programadas.\n",
    "- Si fue marcha, manifestación o concentración SIN suspensión de clases, NO es paro.\n",
    "- Debes explicar tu razonamiento.\n",
    "\n",
    "Devuelve un JSON con estas claves:\n",
    "\n",
    "- \"es_paro_docente\": true/false → true solo si hubo suspensión de clases\n",
    "- \"justificacion_paro\": texto breve (2-4 líneas) explicando por qué es o no un paro\n",
    "- \"organizaciones_sindicales\": lista de sindicatos mencionados u organizaciones políticas o partidos políticos (ej: [\"FECODE\", \"ADE\"]), o []\n",
    "- \"hay_suspension_clases\": true/false → si se suspendieron clases\n",
    "- \"duracion_dias\": número de días estimados, o null\n",
    "- \"razones_paro\": resumen de las demandas principales\n",
    "- \"ubicacion_bogota\": true/false → si ocurre en Bogotá/Cundinamarca\n",
    "- \"ubicacion_Colombia\": true/false → si el paro abarca el territorio Nacional\n",
    "- \"costo_mencionado\": monto económico si se menciona, o null\n",
    "- \"resumen\": breve resumen (máx. 3 líneas)\n",
    "- \"fecha_paro\": ¿cuál es la fecha exacta del paro (día, mes, año)? \n",
    "- \"tipo_movilizacion\": ¿cuál es el tipo de movilización, paro docente con las caracteristicas que ya vimos, paro de otro gremio, demostración, plantón, toma, marcha pacífica, etc?\n",
    "- \"ubicacion\": además del país y ciudad, podemos identificar localidades? barrios? calles? edificios? colegios específicos? edificios del gobierno?\n",
    "Devuelve SOLO el JSON válido, sin texto extra.\n",
    "\n",
    "Texto a analizar:\n",
    "{texto_analizar}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        # ============================================\n",
    "        # 🚀 LLAMADA A LA API DE OPENAI\n",
    "        # ============================================\n",
    "        # - model: versión de GPT a usar (gpt-4o-mini es rápida y barata)\n",
    "        # - temperature: 0.1 = respuestas consistentes (menos creatividad)\n",
    "        # - messages: formato de conversación (role: user/assistant)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "\n",
    "        # Extrae el texto de la respuesta\n",
    "        respuesta_texto = response.choices[0].message.content.strip()\n",
    "\n",
    "        # ============================================\n",
    "        # 📊 PARSEO DEL JSON\n",
    "        # ============================================\n",
    "        # La IA devuelve un JSON como string, lo convertimos a diccionario\n",
    "        try:\n",
    "            # Intenta parsear directamente\n",
    "            analisis = json.loads(respuesta_texto)\n",
    "        except json.JSONDecodeError:\n",
    "            # Si falla, busca el JSON dentro de bloques de código ```json```\n",
    "            if \"```json\" in respuesta_texto:\n",
    "                inicio = respuesta_texto.find(\"```json\") + 7\n",
    "                fin = respuesta_texto.find(\"```\", inicio)\n",
    "                json_str = respuesta_texto[inicio:fin].strip()\n",
    "                analisis = json.loads(json_str)\n",
    "            else:\n",
    "                # Si todo falla, devuelve valores por defecto\n",
    "                print(\"    ⚠️ No se pudo parsear el JSON\")\n",
    "                analisis = {\n",
    "                    'es_paro_docente': False,\n",
    "                    'justificacion_paro': 'Error al analizar',\n",
    "                    'organizaciones_sindicales': [],\n",
    "                    'hay_suspension_clases': False,\n",
    "                    'duracion_dias': None,\n",
    "                    'razones_paro': '',\n",
    "                    'ubicacion_bogota': False,\n",
    "                    'costo_mencionado': None,\n",
    "                    'resumen': ''\n",
    "                }\n",
    "\n",
    "        return analisis\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error en análisis IA: {e}\")\n",
    "        return {\n",
    "            'es_paro_docente': False,\n",
    "            'justificacion_paro': f'Error: {str(e)}',\n",
    "            'organizaciones_sindicales': [],\n",
    "            'hay_suspension_clases': False,\n",
    "            'duracion_dias': None,\n",
    "            'razones_paro': '',\n",
    "            'ubicacion_bogota': False,\n",
    "            'costo_mencionado': None,\n",
    "            'resumen': ''\n",
    "        }\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# 🚀 PARTE 3: EJECUCIÓN PRINCIPAL (Combina todo)\n",
    "# ================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*60)\n",
    "    print(\"🔥 INICIANDO SCRAPER + ANÁLISIS IA\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    resultados_totales = []\n",
    "\n",
    "    # ============================================\n",
    "    # FASE 1: RECOPILACIÓN DE NOTICIAS\n",
    "    # ============================================\n",
    "    print(\"\\n📰 FASE 1: Recopilando noticias...\")\n",
    "\n",
    "    # --- El Tiempo ---\n",
    "    terminos_tiempo = [\"paro maestros 2023\", \"paro nacional docentes 2023\", \"ADE 2023\", \"FECODE 2023\"]\n",
    "    for termino in terminos_tiempo:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"El Tiempo\", \"https://www.eltiempo.com/buscar/\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- ADE ---\n",
    "    terminos_ade = [\"paro docentes\", \"paro maestros\", \"Fecode\", \"educación Bogotá\"]\n",
    "    for termino in terminos_ade:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"ADE\", \"https://adebogota.org/?s=\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- FECODE ---\n",
    "    terminos_fecode = [\"paro nacional\", \"paro docentes\", \"maestros\", \"educación Colombia\"]\n",
    "    for termino in terminos_fecode:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"FECODE\", \"https://www.fecode.edu.co/index.php/component/search/?searchword=\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- GoogleNews ---\n",
    "    resultados_totales.extend(buscar_con_googlenews())\n",
    "\n",
    "    # --- SerpAPI ---\n",
    "    resultados_totales.extend(buscar_con_serpapi(SerpAPI_tkn1))\n",
    "\n",
    "    print(f\"\\n✅ Total de noticias recopiladas: {len(resultados_totales)}\")\n",
    "\n",
    "    # ============================================\n",
    "    # FASE 2: ANÁLISIS CON IA\n",
    "    # ============================================\n",
    "    print(\"\\n🤖 FASE 2: Analizando con IA...\")\n",
    "\n",
    "    for i, noticia in enumerate(resultados_totales, 1):\n",
    "        print(f\"\\n[{i}/{len(resultados_totales)}]\", end=\" \")\n",
    "\n",
    "        # Llama a la función de análisis IA\n",
    "        analisis = analizar_con_ia(\n",
    "            noticia['titulo'],\n",
    "            noticia.get('descripcion', ''),\n",
    "            noticia.get('url', '')\n",
    "        )\n",
    "\n",
    "        # Agrega los resultados del análisis al diccionario de la noticia\n",
    "        noticia.update(analisis)\n",
    "\n",
    "        # Espera 2 segundos entre llamadas (para no saturar la API de OpenAI)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # ============================================\n",
    "    # FASE 3: GUARDAR RESULTADOS EN CSV\n",
    "    # ============================================\n",
    "    print(\"\\n💾 FASE 3: Guardando resultados...\")\n",
    "\n",
    "    df = pd.DataFrame(resultados_totales)\n",
    "\n",
    "    # Reordena columnas para mejor visualización\n",
    "    columnas_importantes = [\n",
    "        'titulo', 'fuente', 'fecha_publicacion', 'url',\n",
    "        'es_paro_docente', 'hay_suspension_clases', 'ubicacion_bogota',\n",
    "        'duracion_dias', 'organizaciones_sindicales', 'razones_paro',\n",
    "        'costo_mencionado', 'justificacion_paro', 'resumen',\n",
    "        'descripcion', 'periodo_busqueda', 'fecha_extraccion'\n",
    "    ]\n",
    "\n",
    "    # Solo incluye columnas que existan en el DataFrame\n",
    "    columnas_finales = [col for col in columnas_importantes if col in df.columns]\n",
    "    df = df[columnas_finales]\n",
    "\n",
    "    # Guarda en CSV\n",
    "    nombre_archivo = \"noticias_paros_docentes_2023_ANALIZADO.csv\"\n",
    "    df.to_csv(nombre_archivo, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"✅ Archivo guardado: {nombre_archivo}\")\n",
    "    print(f\"📊 Total de noticias: {len(df)}\")\n",
    "\n",
    "    # ============================================\n",
    "    # ESTADÍSTICAS FINALES\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"📈 ESTADÍSTICAS DEL ANÁLISIS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    paros_verdaderos = df[df['es_paro_docente'] == True]\n",
    "    print(f\"🔴 Paros verdaderos (con suspensión de clases): {len(paros_verdaderos)}\")\n",
    "\n",
    "    en_bogota = df[df['ubicacion_bogota'] == True]\n",
    "    print(f\"📍 Eventos en Bogotá: {len(en_bogota)}\")\n",
    "\n",
    "    con_duracion = df[df['duracion_dias'].notna()]\n",
    "    if len(con_duracion) > 0:\n",
    "        print(f\"⏱️ Duración promedio: {con_duracion['duracion_dias'].mean():.1f} días\")\n",
    "\n",
    "    print(\"\\n🎉 ¡Análisis completado!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
