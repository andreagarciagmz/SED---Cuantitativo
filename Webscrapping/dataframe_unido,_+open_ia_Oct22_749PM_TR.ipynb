{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E90TNwUPLJqr",
    "outputId": "713a38dd-de60-466e-ab8c-d53d7aa7fc7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GoogleNews\n",
      "  Downloading GoogleNews-1.6.15-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (4.13.5)\n",
      "Collecting dateparser (from GoogleNews)\n",
      "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (2.9.0.post0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (4.15.0)\n",
      "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2025.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2024.11.6)\n",
      "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (5.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->GoogleNews) (1.17.0)\n",
      "Downloading GoogleNews-1.6.15-py3-none-any.whl (8.8 kB)\n",
      "Downloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dateparser, GoogleNews\n",
      "Successfully installed GoogleNews-1.6.15 dateparser-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DkSvsAjyLKZa",
    "outputId": "8df348e6-3a14-48cf-a1a9-e69dda0c1050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
      "Collecting newspaper3k\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.5)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.3)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.4.0)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.4)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.15.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2025.10.5)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.20.0)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=a139028e1ff25cbab59e3b46f717cb62447ca845de77a0ca4e1daf9cd67ea93b\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=291702234c4fac824b3104b8a9f2ee532d6e9d2837395e97b49578b8ee92c44c\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=9faa73b185a5c3b73edaff1ead4a70228a915f17ba010d58d51890742c525fbe\n",
      "  Stored in directory: /root/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=ef4723508acf11b7fd5707fa0a9ad594df7f779bd9c48fc3e037b64312a4f680\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
      "Successfully installed cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.12 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-3.0.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.3.0\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.37.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Downloading selenium-4.37.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 selenium-4.37.0 trio-0.31.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Collecting serpapi\n",
      "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from serpapi) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2025.10.5)\n",
      "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: serpapi\n",
      "Successfully installed serpapi-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install newspaper3k\n",
    "!pip install selenium\n",
    "!pip install openai\n",
    "!pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3VyXVu0LQTp",
    "outputId": "c3127526-bdd9-4503-89b3-0e5e63748022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googlesearch-python\n",
      "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (4.13.5)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (2.32.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2025.10.5)\n",
      "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
      "Installing collected packages: googlesearch-python\n",
      "Successfully installed googlesearch-python-1.3.0\n",
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.10.5)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=4b9c62eb35b6f893b1ba8ee918bba2f015f61fb1b8296585c58478db50d20020\n",
      "  Stored in directory: /root/.cache/pip/wheels/0c/47/f5/89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install googlesearch-python\n",
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLtwWsAHLUgx",
    "outputId": "9abac1b3-a99d-4111-a82b-c445c1ca82a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx[http2] in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (3.11)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.3.0)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx[http2]) (0.16.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"httpx[http2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FUaqRMNLvHz",
    "outputId": "90274436-a75c-41f4-9cea-549d19abfa5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
      "Collecting lxml_html_clean (from lxml[html_clean])\n",
      "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install \"lxml[html_clean]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "TyeXW1uiL0sD"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NoVtb1yKNoa"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from GoogleNews import GoogleNews\n",
    "from serpapi import GoogleSearch\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# ================================================================\n",
    "# Keys\n",
    "# ================================================================\n",
    "OPENAI_API_KEY = \"\"\n",
    "SerpAPI_tkn1 = \"\"\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d81230e5"
   },
   "outputs": [],
   "source": [
    "!pip install GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oJYCffFKmMS",
    "outputId": "d4250cf5-422f-4071-ac20-c1edc942bb29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ”¥ INICIANDO SCRAPER + ANÃLISIS IA\n",
      "============================================================\n",
      "\n",
      "ğŸ“° FASE 1: Recopilando noticias...\n",
      "\n",
      "ğŸ” Buscando en El Tiempo: paro maestros 2023\n",
      "ğŸ“° Encontrados 15 artÃ­culos en El Tiempo\n",
      "\n",
      "ğŸ” Buscando en El Tiempo: paro nacional docentes 2023\n",
      "ğŸ“° Encontrados 15 artÃ­culos en El Tiempo\n",
      "\n",
      "ğŸ” Buscando en El Tiempo: ADE 2023\n",
      "ğŸ“° Encontrados 15 artÃ­culos en El Tiempo\n",
      "\n",
      "ğŸ” Buscando en El Tiempo: FECODE 2023\n",
      "ğŸ“° Encontrados 15 artÃ­culos en El Tiempo\n",
      "\n",
      "ğŸ” Buscando en ADE: paro docentes\n",
      "ğŸ“° Encontrados 0 artÃ­culos en ADE\n",
      "\n",
      "ğŸ” Buscando en ADE: paro maestros\n",
      "ğŸ“° Encontrados 0 artÃ­culos en ADE\n",
      "\n",
      "ğŸ” Buscando en ADE: Fecode\n",
      "ğŸ“° Encontrados 0 artÃ­culos en ADE\n",
      "\n",
      "ğŸ” Buscando en ADE: educaciÃ³n BogotÃ¡\n",
      "ğŸ“° Encontrados 0 artÃ­culos en ADE\n",
      "\n",
      "ğŸ” Buscando en FECODE: paro nacional\n",
      "âŒ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=paro+nacional\n",
      "\n",
      "ğŸ” Buscando en FECODE: paro docentes\n",
      "âŒ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=paro+docentes\n",
      "\n",
      "ğŸ” Buscando en FECODE: maestros\n",
      "âŒ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=maestros\n",
      "\n",
      "ğŸ” Buscando en FECODE: educaciÃ³n Colombia\n",
      "âŒ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=educaci%C3%B3n+Colombia\n",
      "âœ… GoogleNews: 100 resultados\n",
      "\n",
      "ğŸ” Buscando con SerpAPI...\n",
      " â€¢ (\"suspensiÃ³n de clases\" OR \"cese de actividades\" OR \"interrupciÃ³n acadÃ©mica\") BogotÃ¡ 2023\n",
      " â€¢ (\"paro de maestros\" OR \"paro docente\" OR \"huelga de profesores\") BogotÃ¡ 2023\n",
      " â€¢ (\"interrupciÃ³n de clases\" OR \"cancelaciÃ³n de clases\") BogotÃ¡ 2023\n",
      " â€¢ (\"sindicato de maestros\" OR \"FECODE\" OR \"ADE BogotÃ¡\") AND (paro OR huelga) 2023\n",
      "âœ… SerpAPI: 40 resultados\n",
      "\n",
      "âœ… Total de noticias recopiladas: 140\n",
      "\n",
      "ğŸ¤– FASE 2: Analizando con IA...\n",
      "\n",
      "[1/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores...\n",
      "\n",
      "[2/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[3/140]   ğŸ¤– Analizando: Confirman suspensiÃ³n de clases en estos colegios de BogotÃ¡ d...\n",
      "\n",
      "[4/140]   ğŸ¤– Analizando: Caso Maestro Esteban: Fue declarado culpable por muerte de a...\n",
      "\n",
      "[5/140]   ğŸ¤– Analizando: Confirmado: no habrÃ¡ clases a partir del 23 de junio en todo...\n",
      "\n",
      "[6/140]   ğŸ¤– Analizando: Las razones detrÃ¡s del paro nacional del 28 y 29 de mayo...\n",
      "\n",
      "[7/140]   ğŸ¤– Analizando: Paro Nacional 28 de mayo: Rutas y puntos de concentraciÃ³n en...\n",
      "\n",
      "[8/140]   ğŸ¤– Analizando: Â¿AdiÃ³s a las clases?: esto pasarÃ¡ si el sindicato de docente...\n",
      "\n",
      "[9/140]   ğŸ¤– Analizando: Paro nacional del 28 y 29 de mayo podrÃ­a ser un â€œpulso polÃ­t...\n",
      "\n",
      "[10/140]   ğŸ¤– Analizando: Paro nacional de transportistas: aymaras, docentes y transpo...\n",
      "\n",
      "[11/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores...\n",
      "\n",
      "[12/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[13/140]   ğŸ¤– Analizando: Confirman suspensiÃ³n de clases en estos colegios de BogotÃ¡ d...\n",
      "\n",
      "[14/140]   ğŸ¤– Analizando: Caso Maestro Esteban: Fue declarado culpable por muerte de a...\n",
      "\n",
      "[15/140]   ğŸ¤– Analizando: Confirmado: no habrÃ¡ clases a partir del 23 de junio en todo...\n",
      "\n",
      "[16/140]   ğŸ¤– Analizando: Las razones detrÃ¡s del paro nacional del 28 y 29 de mayo...\n",
      "\n",
      "[17/140]   ğŸ¤– Analizando: Paro Nacional 28 de mayo: Rutas y puntos de concentraciÃ³n en...\n",
      "\n",
      "[18/140]   ğŸ¤– Analizando: Â¿AdiÃ³s a las clases?: esto pasarÃ¡ si el sindicato de docente...\n",
      "\n",
      "[19/140]   ğŸ¤– Analizando: Paro nacional del 28 y 29 de mayo podrÃ­a ser un â€œpulso polÃ­t...\n",
      "\n",
      "[20/140]   ğŸ¤– Analizando: Paro nacional de transportistas: aymaras, docentes y transpo...\n",
      "\n",
      "[21/140]   ğŸ¤– Analizando: Fecode anunciÃ³ paro nacional de maestros: habrÃ¡ concentracio...\n",
      "\n",
      "[22/140]   ğŸ¤– Analizando: Paro docente confirmado: todos los maestros adhieren y no ha...\n",
      "\n",
      "[23/140]   ğŸ¤– Analizando: Fecode confirma paro nacional de 24 horas el 30 de octubre y...\n",
      "\n",
      "[24/140]   ğŸ¤– Analizando: Anuncian nuevo paro nacional en Colombia: la movilidad se ve...\n",
      "\n",
      "[25/140]   ğŸ¤– Analizando: Docentes de BogotÃ¡ continÃºan en paro: SecretarÃ­a de EducaciÃ³...\n",
      "\n",
      "[26/140]   ğŸ¤– Analizando: Â¿QuÃ© actividades realizarÃ¡n hoy los maestros del Eje Cafeter...\n",
      "\n",
      "[27/140]   ğŸ¤– Analizando: Paro de profesores de 72 horas en el Eje Cafetero: marchas e...\n",
      "\n",
      "[28/140]   ğŸ¤– Analizando: Â¿DÃ³nde marcharÃ¡n esta semana los maestros del Eje Cafetero e...\n",
      "\n",
      "[29/140]   ğŸ¤– Analizando: Paro de docentes de Eje Cafetero durarÃ¡ 72 horas: marchas en...\n",
      "\n",
      "[30/140]   ğŸ¤– Analizando: Sintrenal advierte paro nacional indefinido en el sector edu...\n",
      "\n",
      "[31/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores...\n",
      "\n",
      "[32/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[33/140]   ğŸ¤– Analizando: Confirman suspensiÃ³n de clases en estos colegios de BogotÃ¡ d...\n",
      "\n",
      "[34/140]   ğŸ¤– Analizando: Caso Maestro Esteban: Fue declarado culpable por muerte de a...\n",
      "\n",
      "[35/140]   ğŸ¤– Analizando: Confirmado: no habrÃ¡ clases a partir del 23 de junio en todo...\n",
      "\n",
      "[36/140]   ğŸ¤– Analizando: Las razones detrÃ¡s del paro nacional del 28 y 29 de mayo...\n",
      "\n",
      "[37/140]   ğŸ¤– Analizando: Paro Nacional 28 de mayo: Rutas y puntos de concentraciÃ³n en...\n",
      "\n",
      "[38/140]   ğŸ¤– Analizando: Â¿AdiÃ³s a las clases?: esto pasarÃ¡ si el sindicato de docente...\n",
      "\n",
      "[39/140]   ğŸ¤– Analizando: Paro nacional del 28 y 29 de mayo podrÃ­a ser un â€œpulso polÃ­t...\n",
      "\n",
      "[40/140]   ğŸ¤– Analizando: Paro nacional de transportistas: aymaras, docentes y transpo...\n",
      "\n",
      "[41/140]   ğŸ¤– Analizando: Fecode anunciÃ³ paro nacional de maestros: habrÃ¡ concentracio...\n",
      "\n",
      "[42/140]   ğŸ¤– Analizando: Paro docente confirmado: todos los maestros adhieren y no ha...\n",
      "\n",
      "[43/140]   ğŸ¤– Analizando: Fecode confirma paro nacional de 24 horas el 30 de octubre y...\n",
      "\n",
      "[44/140]   ğŸ¤– Analizando: Anuncian nuevo paro nacional en Colombia: la movilidad se ve...\n",
      "\n",
      "[45/140]   ğŸ¤– Analizando: Docentes de BogotÃ¡ continÃºan en paro: SecretarÃ­a de EducaciÃ³...\n",
      "\n",
      "[46/140]   ğŸ¤– Analizando: Â¿QuÃ© actividades realizarÃ¡n hoy los maestros del Eje Cafeter...\n",
      "\n",
      "[47/140]   ğŸ¤– Analizando: Paro de profesores de 72 horas en el Eje Cafetero: marchas e...\n",
      "\n",
      "[48/140]   ğŸ¤– Analizando: Â¿DÃ³nde marcharÃ¡n esta semana los maestros del Eje Cafetero e...\n",
      "\n",
      "[49/140]   ğŸ¤– Analizando: Paro de docentes de Eje Cafetero durarÃ¡ 72 horas: marchas en...\n",
      "\n",
      "[50/140]   ğŸ¤– Analizando: Sintrenal advierte paro nacional indefinido en el sector edu...\n",
      "\n",
      "[51/140]   ğŸ¤– Analizando: Paro magisterial deja sin clases a mÃ¡s de un millÃ³n de estud...\n",
      "\n",
      "[52/140]   ğŸ¤– Analizando: Acuerdo histÃ³rico en BogotÃ¡: docentes recuperan salarios y e...\n",
      "\n",
      "[53/140]   ğŸ¤– Analizando: Sindicatos del Sena anuncian paro nacional de 24 horas este ...\n",
      "\n",
      "[54/140]   ğŸ¤– Analizando: Confirmado: no habrÃ¡ clases a partir del 23 de junio en todo...\n",
      "\n",
      "[55/140]   ğŸ¤– Analizando: Noticias Tolima: Grave dÃ©ficit de profesores en colegio de P...\n",
      "\n",
      "[56/140]   ğŸ¤– Analizando: SecretarÃ­a de EducaciÃ³n revelÃ³ quÃ© pasarÃ¡ con los colegios e...\n",
      "\n",
      "[57/140]   ğŸ¤– Analizando: Â¿HabrÃ¡ clases por el Paro Nacional de este 28 y 29 de mayo?...\n",
      "\n",
      "[58/140]   ğŸ¤– Analizando: Un feminicidio en la Universidad del Valle reabre el debate ...\n",
      "\n",
      "[59/140]   ğŸ¤– Analizando: Crisis en la Normal Superior de CharalÃ¡: mÃ¡s de 700 estudian...\n",
      "\n",
      "[60/140]   ğŸ¤– Analizando: Paros de maestros: la tensiÃ³n entre la protesta y la educaci...\n",
      "\n",
      "[61/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores...\n",
      "\n",
      "[62/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[63/140]   ğŸ¤– Analizando: Confirman suspensiÃ³n de clases en estos colegios de BogotÃ¡ d...\n",
      "\n",
      "[64/140]   ğŸ¤– Analizando: Caso Maestro Esteban: Fue declarado culpable por muerte de a...\n",
      "\n",
      "[65/140]   ğŸ¤– Analizando: Confirmado: no habrÃ¡ clases a partir del 23 de junio en todo...\n",
      "\n",
      "[66/140]   ğŸ¤– Analizando: Las razones detrÃ¡s del paro nacional del 28 y 29 de mayo...\n",
      "\n",
      "[67/140]   ğŸ¤– Analizando: Paro Nacional 28 de mayo: Rutas y puntos de concentraciÃ³n en...\n",
      "\n",
      "[68/140]   ğŸ¤– Analizando: Â¿AdiÃ³s a las clases?: esto pasarÃ¡ si el sindicato de docente...\n",
      "\n",
      "[69/140]   ğŸ¤– Analizando: Paro nacional del 28 y 29 de mayo podrÃ­a ser un â€œpulso polÃ­t...\n",
      "\n",
      "[70/140]   ğŸ¤– Analizando: Paro nacional de transportistas: aymaras, docentes y transpo...\n",
      "\n",
      "[71/140]   ğŸ¤– Analizando: Fecode anunciÃ³ paro nacional de maestros: habrÃ¡ concentracio...\n",
      "\n",
      "[72/140]   ğŸ¤– Analizando: Paro docente confirmado: todos los maestros adhieren y no ha...\n",
      "\n",
      "[73/140]   ğŸ¤– Analizando: Fecode confirma paro nacional de 24 horas el 30 de octubre y...\n",
      "\n",
      "[74/140]   ğŸ¤– Analizando: Anuncian nuevo paro nacional en Colombia: la movilidad se ve...\n",
      "\n",
      "[75/140]   ğŸ¤– Analizando: Docentes de BogotÃ¡ continÃºan en paro: SecretarÃ­a de EducaciÃ³...\n",
      "\n",
      "[76/140]   ğŸ¤– Analizando: Â¿QuÃ© actividades realizarÃ¡n hoy los maestros del Eje Cafeter...\n",
      "\n",
      "[77/140]   ğŸ¤– Analizando: Paro de profesores de 72 horas en el Eje Cafetero: marchas e...\n",
      "\n",
      "[78/140]   ğŸ¤– Analizando: Â¿DÃ³nde marcharÃ¡n esta semana los maestros del Eje Cafetero e...\n",
      "\n",
      "[79/140]   ğŸ¤– Analizando: Paro de docentes de Eje Cafetero durarÃ¡ 72 horas: marchas en...\n",
      "\n",
      "[80/140]   ğŸ¤– Analizando: Sintrenal advierte paro nacional indefinido en el sector edu...\n",
      "\n",
      "[81/140]   ğŸ¤– Analizando: Paro magisterial deja sin clases a mÃ¡s de un millÃ³n de estud...\n",
      "\n",
      "[82/140]   ğŸ¤– Analizando: Acuerdo histÃ³rico en BogotÃ¡: docentes recuperan salarios y e...\n",
      "\n",
      "[83/140]   ğŸ¤– Analizando: Sindicatos del Sena anuncian paro nacional de 24 horas este ...\n",
      "\n",
      "[84/140]   ğŸ¤– Analizando: Confirmado: no habrÃ¡ clases a partir del 23 de junio en todo...\n",
      "\n",
      "[85/140]   ğŸ¤– Analizando: Noticias Tolima: Grave dÃ©ficit de profesores en colegio de P...\n",
      "\n",
      "[86/140]   ğŸ¤– Analizando: SecretarÃ­a de EducaciÃ³n revelÃ³ quÃ© pasarÃ¡ con los colegios e...\n",
      "\n",
      "[87/140]   ğŸ¤– Analizando: Â¿HabrÃ¡ clases por el Paro Nacional de este 28 y 29 de mayo?...\n",
      "\n",
      "[88/140]   ğŸ¤– Analizando: Un feminicidio en la Universidad del Valle reabre el debate ...\n",
      "\n",
      "[89/140]   ğŸ¤– Analizando: Crisis en la Normal Superior de CharalÃ¡: mÃ¡s de 700 estudian...\n",
      "\n",
      "[90/140]   ğŸ¤– Analizando: Paros de maestros: la tensiÃ³n entre la protesta y la educaci...\n",
      "\n",
      "[91/140]   ğŸ¤– Analizando: Â¿QuÃ© estÃ¡ pasando en la Universidad Nacional? Vicerrectora, ...\n",
      "\n",
      "[92/140]   ğŸ¤– Analizando: Paro docente confirmado: todos los maestros adhieren y no ha...\n",
      "\n",
      "[93/140]   ğŸ¤– Analizando: Fecode anunciÃ³ nuevo paro nacional en octubre: Â¿estudiantes ...\n",
      "\n",
      "[94/140]   ğŸ¤– Analizando: Soacha suspenderÃ¡ clases en colegios pÃºblicos por paro de co...\n",
      "\n",
      "[95/140]   ğŸ¤– Analizando: SuspensiÃ³n de clases presenciales en instituciones educativa...\n",
      "\n",
      "[96/140]   ğŸ¤– Analizando: Colegios oficiales de Soacha suspenden clases por paro en Bo...\n",
      "\n",
      "[97/140]   ğŸ¤– Analizando: Soacha suspende clases presenciales por paro de conductores ...\n",
      "\n",
      "[98/140]   ğŸ¤– Analizando: Suspenden clases por gran manifestaciÃ³n de conductores en Bo...\n",
      "\n",
      "[99/140]   ğŸ¤– Analizando: Paro en BogotÃ¡ 16 de septiembre: estos colegios ya confirmar...\n",
      "\n",
      "[100/140]   ğŸ¤– Analizando: Maestros del Eje Cafetero protestan en BogotÃ¡ y exigen mejor...\n",
      "\n",
      "[101/140]   ğŸ¤– Analizando: CIRCULAR No. 004 de 2023 PARA...\n",
      "\n",
      "[102/140]   ğŸ¤– Analizando: Concepto 217971 de 2023 Departamento Administrativo ......\n",
      "\n",
      "[103/140]   ğŸ¤– Analizando: Protestas en BogotÃ¡ 28 y 29 de marzo 2023...\n",
      "\n",
      "[104/140]   ğŸ¤– Analizando: cundinamarca...\n",
      "\n",
      "[105/140]   ğŸ¤– Analizando: Sentencia T-210 de 2023 Corte Constitucional de Colombia...\n",
      "\n",
      "[106/140]   ğŸ¤– Analizando: Sala Laboral seÃ±ala que no puede haber una prohibiciÃ³n ......\n",
      "\n",
      "[107/140]   ğŸ¤– Analizando: Protesta de profesores en BogotÃ¡: asÃ­ avanza la marcha...\n",
      "\n",
      "[108/140]   ğŸ¤– Analizando: InformaciÃ³n sobre las acciones de hecho de la Junta ......\n",
      "\n",
      "[109/140]   ğŸ¤– Analizando: Marchas HOY 28 de marzo BogotÃ¡: Minuto a ......\n",
      "\n",
      "[110/140]   ğŸ¤– Analizando: T-577/23...\n",
      "\n",
      "[111/140]   ğŸ¤– Analizando: Paro nacional de profesores, 30 de agosto de 2023: fecha ......\n",
      "\n",
      "[112/140]   ğŸ¤– Analizando: Fecode anuncia paro nacional de maestros por 24 horas ......\n",
      "\n",
      "[113/140]   ğŸ¤– Analizando: MAÃ‘ANA HAY CLASES | Se levanta el paro docente ......\n",
      "\n",
      "[114/140]   ğŸ¤– Analizando: MarÃ­a Fernanda Cabal les pide a los profesores que ......\n",
      "\n",
      "[115/140]   ğŸ¤– Analizando: Sindicato de maestros Sintrenal convocan paro nacional ......\n",
      "\n",
      "[116/140]   ğŸ¤– Analizando: â€œPor legÃ­timas que sean las demandas, el paro afecta ......\n",
      "\n",
      "[117/140]   ğŸ¤– Analizando: QuÃ© es el Fomag y por quÃ© estÃ¡ a punto de causar un paro ......\n",
      "\n",
      "[118/140]   ğŸ¤– Analizando: Paro de Fecode: Â¿QuÃ© tan grave estÃ¡ el sistema de salud ......\n",
      "\n",
      "[119/140]   ğŸ¤– Analizando: Paro de maestros por 48 horas: puntos de concentraciÃ³n...\n",
      "\n",
      "[120/140]   ğŸ¤– Analizando: â€â™€ï¸ Paro martes 14/03 y âš ASAMBLEA en ğŸ“ŒEscuela Julio ......\n",
      "\n",
      "[121/140]   ğŸ¤– Analizando: Calendario AcadÃ©mico...\n",
      "\n",
      "[122/140]   ğŸ¤– Analizando: COLEGIO DIANA TURBAY IED - BogotÃ¡...\n",
      "\n",
      "[123/140]   ğŸ¤– Analizando: Agenda Colegio Luis AmigÃ³ 2023...\n",
      "\n",
      "[124/140]   ğŸ¤– Analizando: MANUAL DE CONVIVENCIA 2024 COLEGIO TIBABUYES ......\n",
      "\n",
      "[125/140]   ğŸ¤– Analizando: informe anual 2023...\n",
      "\n",
      "[126/140]   ğŸ¤– Analizando: Malestar entre los padres de familia de la InstituciÃ³n ......\n",
      "\n",
      "[127/140]   ğŸ¤– Analizando: incidencia de los comportamientos disruptivos de...\n",
      "\n",
      "[128/140]   ğŸ¤– Analizando: Terminos-y-Condiciones-10-de-descuento-Intensivo- ......\n",
      "\n",
      "[129/140]   ğŸ¤– Analizando: Prueba Aprender: en primaria, la mitad de los chicos no ......\n",
      "\n",
      "[130/140]   ğŸ¤– Analizando: Humor sobre la CancelaciÃ³n de Clases en la Escuela...\n",
      "\n",
      "[131/140]   ğŸ¤– Analizando: Convocan a paro nacional de profesores para este 30 ......\n",
      "\n",
      "[132/140]   ğŸ¤– Analizando: SecretarÃ­a de Prensa y Comunicaciones...\n",
      "\n",
      "[133/140]   ğŸ¤– Analizando: Â¿CuÃ¡ndo hay paro de FECODE 2023? DÃ­a de marchas y ......\n",
      "\n",
      "[134/140]   ğŸ¤– Analizando: Sindicato de maestros convocÃ³ a paro el 29 y 30 de ......\n",
      "\n",
      "[135/140]   ğŸ¤– Analizando: Fecode anuncia paro nacional de maestros por 24 horas ......\n",
      "\n",
      "[136/140]   ğŸ¤– Analizando: Fecode anunciÃ³ un paro nacional para el prÃ³ximo 30 de ......\n",
      "\n",
      "[137/140]   ğŸ¤– Analizando: Â¿CuÃ¡ndo es el Paro de FECODE en BogotÃ¡? Fecha oficial ......\n",
      "\n",
      "[138/140]   ğŸ¤– Analizando: Estudiantes pierden hasta un 35% del tiempo de clase al ......\n",
      "\n",
      "[139/140]   ğŸ¤– Analizando: Los viejos y nuevos motivos de las marchas ......\n",
      "\n",
      "[140/140]   ğŸ¤– Analizando: fecode...\n",
      "\n",
      "ğŸ’¾ FASE 3: Guardando resultados...\n",
      "âœ… Archivo guardado: noticias_paros_docentes_2023_ANALIZADO.csv\n",
      "ğŸ“Š Total de noticias: 140\n",
      "\n",
      "============================================================\n",
      "ğŸ“ˆ ESTADÃSTICAS DEL ANÃLISIS\n",
      "============================================================\n",
      "ğŸ”´ Paros verdaderos (con suspensiÃ³n de clases): 58\n",
      "ğŸ“ Eventos en BogotÃ¡: 67\n",
      "â±ï¸ DuraciÃ³n promedio: 4.0 dÃ­as\n",
      "\n",
      "ğŸ‰ Â¡AnÃ¡lisis completado!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================================================\n",
    "# ğŸŒ PARTE 1: FUNCIONES DE SCRAPING (Tu cÃ³digo original)\n",
    "# ================================================================\n",
    "\n",
    "def buscar_noticias_generales(nombre_fuente, url_base, termino_busqueda, max_resultados=15):\n",
    "    \"\"\"\n",
    "    ğŸ” EXPLICACIÃ“N:\n",
    "    Esta funciÃ³n busca noticias en sitios web especÃ­ficos (El Tiempo, ADE, FECODE).\n",
    "\n",
    "    - Construye una URL de bÃºsqueda usando el tÃ©rmino\n",
    "    - Hace una peticiÃ³n HTTP para obtener el HTML\n",
    "    - Usa BeautifulSoup para extraer informaciÃ³n de los artÃ­culos\n",
    "    - Devuelve una lista de diccionarios con los datos de cada noticia\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸ” Buscando en {nombre_fuente}: {termino_busqueda}\")\n",
    "    datos = []\n",
    "\n",
    "    # quote_plus convierte espacios en + para URLs (ej: \"paro maestros\" â†’ \"paro+maestros\")\n",
    "    termino_codificado = quote_plus(termino_busqueda)\n",
    "    url_busqueda = f\"{url_base}{termino_codificado}\"\n",
    "\n",
    "    # User-Agent simula que somos un navegador real (algunos sitios bloquean bots)\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url_busqueda, headers=headers, timeout=10)\n",
    "        response.raise_for_status()  # Lanza error si status code != 200\n",
    "\n",
    "        # BeautifulSoup parsea el HTML para poder buscar elementos\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # find_all busca todos los tags <article> (donde suelen estar las noticias)\n",
    "        articulos = soup.find_all('article', limit=max_resultados)\n",
    "        print(f\"ğŸ“° Encontrados {len(articulos)} artÃ­culos en {nombre_fuente}\")\n",
    "\n",
    "        for articulo in articulos:\n",
    "            # Extrae tÃ­tulo (busca <h2>), descripciÃ³n (<p>), link (<a>), fecha (<time>)\n",
    "            titulo = articulo.find('h2').get_text(strip=True) if articulo.find('h2') else \"\"\n",
    "            descripcion = articulo.find('p').get_text(strip=True) if articulo.find('p') else \"\"\n",
    "            link_elem = articulo.find('a', href=True)\n",
    "            link = link_elem['href'] if link_elem else \"\"\n",
    "\n",
    "            # Si el link es relativo (ej: /noticia/123), lo convierte a absoluto\n",
    "            if link and not link.startswith('http'):\n",
    "                link = f\"{url_base.rstrip('/')}/{link.lstrip('/')}\"\n",
    "\n",
    "            fecha_elem = articulo.find('time')\n",
    "            fecha = fecha_elem.get_text(strip=True) if fecha_elem else 'N/A'\n",
    "\n",
    "            # Solo guarda si tiene tÃ­tulo vÃ¡lido\n",
    "            if titulo and len(titulo) > 10:\n",
    "                datos.append({\n",
    "                    'titulo': titulo,\n",
    "                    'fuente': nombre_fuente,\n",
    "                    'fecha_publicacion': fecha,\n",
    "                    'descripcion': descripcion,\n",
    "                    'url': link,\n",
    "                    'periodo_busqueda': termino_busqueda,\n",
    "                    'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error en {nombre_fuente}: {e}\")\n",
    "\n",
    "    return datos\n",
    "\n",
    "\n",
    "def buscar_con_googlenews():\n",
    "    \"\"\"\n",
    "    ğŸ” EXPLICACIÃ“N:\n",
    "    Usa la librerÃ­a GoogleNews para buscar noticias en espaÃ±ol.\n",
    "\n",
    "    - set_time_range limita resultados al aÃ±o 2023\n",
    "    - Hace mÃºltiples bÃºsquedas con diferentes queries\n",
    "    - Devuelve lista de noticias encontradas\n",
    "    \"\"\"\n",
    "    googlenews = GoogleNews(lang='es', encode='utf-8')\n",
    "    googlenews.set_time_range('01/01/2023', '12/31/2023')\n",
    "\n",
    "    queries = [\n",
    "    # Originales\n",
    "    '\"paro de docentes\" BogotÃ¡ \"clases suspendidas 2023\"',\n",
    "    '(paro OR \"cese de actividades 2023\") AND (docentes OR maestros) AND BogotÃ¡',\n",
    "    '\"estudiantes sin clase 2023\" AND paro BogotÃ¡ 2023',\n",
    "    '\"suspensiÃ³n de clases\" AND docentes BogotÃ¡',\n",
    "\n",
    "    # Mejoradas\n",
    "    '(\"paro de docentes\" OR \"cese de actividades\") AND BogotÃ¡ AND (\"clases suspendidas\" OR \"clases interrumpidas\") AND 2023',\n",
    "    '(paro OR \"cese de actividades\") AND (docentes OR maestros OR profesores) AND BogotÃ¡ AND 2023',\n",
    "    '(\"estudiantes sin clase\" OR \"no hay clases\" OR \"interrupciÃ³n acadÃ©mica\") AND paro AND BogotÃ¡ AND 2023',\n",
    "    '(\"suspensiÃ³n de clases\" OR \"clases suspendidas\" OR \"no hay clases\") AND (docentes OR maestros) AND BogotÃ¡ AND 2023'\n",
    "]\n",
    "\n",
    "\n",
    "    resultados = []\n",
    "    for q in queries:\n",
    "        googlenews.search(q)\n",
    "        time.sleep(random.uniform(2, 4))  # Espera aleatoria para no ser bloqueado\n",
    "        res = googlenews.result()\n",
    "\n",
    "        for r in res:\n",
    "            resultados.append({\n",
    "                'titulo': r.get('title'),\n",
    "                'fuente': r.get('media'),\n",
    "                'fecha_publicacion': r.get('date'),\n",
    "                'descripcion': '',\n",
    "                'url': r.get('link'),\n",
    "                'periodo_busqueda': q,\n",
    "                'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            })\n",
    "\n",
    "    print(f\"âœ… GoogleNews: {len(resultados)} resultados\")\n",
    "    return resultados\n",
    "\n",
    "\n",
    "def buscar_con_serpapi(api_key):\n",
    "    \"\"\"\n",
    "    ğŸ” EXPLICACIÃ“N:\n",
    "    Usa SerpAPI (servicio de pago) para buscar en Google de forma programÃ¡tica.\n",
    "\n",
    "    - Permite bÃºsquedas avanzadas con operadores de Google\n",
    "    - Devuelve resultados estructurados (organic_results)\n",
    "    - MÃ¡s confiable que el scraping directo\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ” Buscando con SerpAPI...\")\n",
    "    queries = [\n",
    "        '(\"suspensiÃ³n de clases\" OR \"cese de actividades\" OR \"interrupciÃ³n acadÃ©mica\") BogotÃ¡ 2023',\n",
    "        '(\"paro de maestros\" OR \"paro docente\" OR \"huelga de profesores\") BogotÃ¡ 2023',\n",
    "        '(\"interrupciÃ³n de clases\" OR \"cancelaciÃ³n de clases\") BogotÃ¡ 2023',\n",
    "        '(\"sindicato de maestros\" OR \"FECODE\" OR \"ADE BogotÃ¡\") AND (paro OR huelga) 2023',\n",
    "    ]\n",
    "\n",
    "    resultados = []\n",
    "    for query in queries:\n",
    "        print(f\" â€¢ {query}\")\n",
    "        params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"q\": f\"{query} after:2023-01-01 before:2023-12-31\",\n",
    "            \"api_key\": api_key,\n",
    "            \"num\": 50,  # NÃºmero mÃ¡ximo de resultados por query\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            search = GoogleSearch(params)\n",
    "            results = search.get_dict()\n",
    "            items = results.get(\"organic_results\", [])\n",
    "\n",
    "            for item in items:\n",
    "                resultados.append({\n",
    "                    'titulo': item.get('title'),\n",
    "                    'fuente': 'Google (SerpAPI)',\n",
    "                    'fecha_publicacion': '',\n",
    "                    'descripcion': item.get('snippet', ''),\n",
    "                    'url': item.get('link'),\n",
    "                    'periodo_busqueda': query,\n",
    "                    'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error con SerpAPI: {e}\")\n",
    "\n",
    "    print(f\"âœ… SerpAPI: {len(resultados)} resultados\")\n",
    "    return resultados\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# ğŸ¤– PARTE 2: ANÃLISIS CON IA (Tu cÃ³digo de OpenAI adaptado)\n",
    "# ================================================================\n",
    "\n",
    "def obtener_texto_completo(url):\n",
    "    \"\"\"\n",
    "    ğŸ“„ EXPLICACIÃ“N:\n",
    "    Descarga el contenido completo de una URL y extrae solo el texto legible.\n",
    "\n",
    "    - Elimina scripts, estilos, headers, footers (no son contenido Ãºtil)\n",
    "    - stripped_strings elimina espacios innecesarios\n",
    "    - Limita a 8000 caracteres para no exceder lÃ­mites de OpenAI\n",
    "    \"\"\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=15)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        # Elimina elementos que no son contenido principal\n",
    "        for s in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"aside\", \"form\"]):\n",
    "            s.extract()\n",
    "\n",
    "        texto = \" \".join(soup.stripped_strings)\n",
    "        return texto[:8000]  # MÃ¡ximo 8000 caracteres\n",
    "    except Exception as e:\n",
    "        return f\"Error al obtener contenido: {e}\"\n",
    "\n",
    "\n",
    "def analizar_con_ia(titulo, descripcion, url):\n",
    "    \"\"\"\n",
    "    ğŸ¤– EXPLICACIÃ“N (LA MÃS IMPORTANTE):\n",
    "    Esta funciÃ³n envÃ­a la noticia a GPT-4 para que la analice siguiendo criterios estrictos.\n",
    "\n",
    "    PROCESO:\n",
    "    1. Intenta descargar el contenido completo de la URL\n",
    "    2. Si falla, usa solo tÃ­tulo + descripciÃ³n, indicame si pudiste o no acceder al URL\n",
    "    3. Construye un prompt detallado con instrucciones para la IA\n",
    "    4. EnvÃ­a el prompt a OpenAI (modelo gpt-4o-mini)\n",
    "    5. Recibe respuesta en formato JSON\n",
    "    6. Parsea el JSON y devuelve un diccionario con las caracterÃ­sticas\n",
    "\n",
    "    CARACTERÃSTICAS QUE ANALIZA:\n",
    "    - es_paro_docente: Â¿Hubo suspensiÃ³n de clases?\n",
    "    - organizaciones_sindicales: Â¿QuÃ© sindicatos u organizaciones polÃ­ticas participaron?\n",
    "    - duracion_dias: Â¿CuÃ¡ntos dÃ­as durÃ³?\n",
    "    - ubicacion_bogota: Â¿OcurriÃ³ en BogotÃ¡?\n",
    "    - ubicacion_Colombia: Â¿AbarcÃ³ todo el territorio Nacional=\n",
    "    - costo_mencionado: Â¿Se habla de costos econÃ³micos?\n",
    "    - fecha_paro: Â¿cuÃ¡l es la fecha exacta del paro (dÃ­a, mes, aÃ±o)? \n",
    "    \"\"\"\n",
    "    print(f\"  ğŸ¤– Analizando: {titulo[:60]}...\")\n",
    "\n",
    "    # Intenta obtener contenido completo de la URL\n",
    "    contenido_completo = obtener_texto_completo(url) if url else \"\"\n",
    "\n",
    "    # Si no pudo descargar el contenido, usa tÃ­tulo + descripciÃ³n\n",
    "    if \"Error\" in contenido_completo or not contenido_completo:\n",
    "        texto_analizar = f\"TÃ­tulo: {titulo}\\nDescripciÃ³n: {descripcion}\"\n",
    "    else:\n",
    "        texto_analizar = contenido_completo\n",
    "\n",
    "    # ============================================\n",
    "    # ğŸ“ PROMPT PARA LA IA\n",
    "    # ============================================\n",
    "    # Este es el \"cerebro\" del anÃ¡lisis. Le dice a GPT exactamente quÃ© debe hacer.\n",
    "    prompt = f\"\"\"\n",
    "Analiza la siguiente noticia en espaÃ±ol sobre educaciÃ³n, sindicatos o protestas de docentes.\n",
    "\n",
    "CRITERIOS ESTRICTOS:\n",
    "- Un **paro docente verdadero** solo existe si hubo suspensiÃ³n de clases programadas.\n",
    "- Si fue marcha, manifestaciÃ³n o concentraciÃ³n SIN suspensiÃ³n de clases, NO es paro.\n",
    "- Debes explicar tu razonamiento.\n",
    "\n",
    "Devuelve un JSON con estas claves:\n",
    "\n",
    "- \"es_paro_docente\": true/false â†’ true solo si hubo suspensiÃ³n de clases\n",
    "- \"justificacion_paro\": texto breve (2-4 lÃ­neas) explicando por quÃ© es o no un paro\n",
    "- \"organizaciones_sindicales\": lista de sindicatos mencionados u organizaciones polÃ­ticas o partidos polÃ­ticos (ej: [\"FECODE\", \"ADE\"]), o []\n",
    "- \"hay_suspension_clases\": true/false â†’ si se suspendieron clases\n",
    "- \"duracion_dias\": nÃºmero de dÃ­as estimados, o null\n",
    "- \"razones_paro\": resumen de las demandas principales\n",
    "- \"ubicacion_bogota\": true/false â†’ si ocurre en BogotÃ¡/Cundinamarca\n",
    "- \"ubicacion_Colombia\": true/false â†’ si el paro abarca el territorio Nacional\n",
    "- \"costo_mencionado\": monto econÃ³mico si se menciona, o null\n",
    "- \"resumen\": breve resumen (mÃ¡x. 3 lÃ­neas)\n",
    "- \"fecha_paro\": Â¿cuÃ¡l es la fecha exacta del paro (dÃ­a, mes, aÃ±o)? \n",
    "- \"tipo_movilizacion\": Â¿cuÃ¡l es el tipo de movilizaciÃ³n, paro docente con las caracteristicas que ya vimos, paro de otro gremio, demostraciÃ³n, plantÃ³n, toma, marcha pacÃ­fica, etc?\n",
    "- \"ubicacion\": ademÃ¡s del paÃ­s y ciudad, podemos identificar localidades? barrios? calles? edificios? colegios especÃ­ficos? edificios del gobierno?\n",
    "Devuelve SOLO el JSON vÃ¡lido, sin texto extra.\n",
    "\n",
    "Texto a analizar:\n",
    "{texto_analizar}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        # ============================================\n",
    "        # ğŸš€ LLAMADA A LA API DE OPENAI\n",
    "        # ============================================\n",
    "        # - model: versiÃ³n de GPT a usar (gpt-4o-mini es rÃ¡pida y barata)\n",
    "        # - temperature: 0.1 = respuestas consistentes (menos creatividad)\n",
    "        # - messages: formato de conversaciÃ³n (role: user/assistant)\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0.1,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "\n",
    "        # Extrae el texto de la respuesta\n",
    "        respuesta_texto = response.choices[0].message.content.strip()\n",
    "\n",
    "        # ============================================\n",
    "        # ğŸ“Š PARSEO DEL JSON\n",
    "        # ============================================\n",
    "        # La IA devuelve un JSON como string, lo convertimos a diccionario\n",
    "        try:\n",
    "            # Intenta parsear directamente\n",
    "            analisis = json.loads(respuesta_texto)\n",
    "        except json.JSONDecodeError:\n",
    "            # Si falla, busca el JSON dentro de bloques de cÃ³digo ```json```\n",
    "            if \"```json\" in respuesta_texto:\n",
    "                inicio = respuesta_texto.find(\"```json\") + 7\n",
    "                fin = respuesta_texto.find(\"```\", inicio)\n",
    "                json_str = respuesta_texto[inicio:fin].strip()\n",
    "                analisis = json.loads(json_str)\n",
    "            else:\n",
    "                # Si todo falla, devuelve valores por defecto\n",
    "                print(\"    âš ï¸ No se pudo parsear el JSON\")\n",
    "                analisis = {\n",
    "                    'es_paro_docente': False,\n",
    "                    'justificacion_paro': 'Error al analizar',\n",
    "                    'organizaciones_sindicales': [],\n",
    "                    'hay_suspension_clases': False,\n",
    "                    'duracion_dias': None,\n",
    "                    'razones_paro': '',\n",
    "                    'ubicacion_bogota': False,\n",
    "                    'costo_mencionado': None,\n",
    "                    'resumen': ''\n",
    "                }\n",
    "\n",
    "        return analisis\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"    âŒ Error en anÃ¡lisis IA: {e}\")\n",
    "        return {\n",
    "            'es_paro_docente': False,\n",
    "            'justificacion_paro': f'Error: {str(e)}',\n",
    "            'organizaciones_sindicales': [],\n",
    "            'hay_suspension_clases': False,\n",
    "            'duracion_dias': None,\n",
    "            'razones_paro': '',\n",
    "            'ubicacion_bogota': False,\n",
    "            'costo_mencionado': None,\n",
    "            'resumen': ''\n",
    "        }\n",
    "\n",
    "\n",
    "# ================================================================\n",
    "# ğŸš€ PARTE 3: EJECUCIÃ“N PRINCIPAL (Combina todo)\n",
    "# ================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*60)\n",
    "    print(\"ğŸ”¥ INICIANDO SCRAPER + ANÃLISIS IA\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    resultados_totales = []\n",
    "\n",
    "    # ============================================\n",
    "    # FASE 1: RECOPILACIÃ“N DE NOTICIAS\n",
    "    # ============================================\n",
    "    print(\"\\nğŸ“° FASE 1: Recopilando noticias...\")\n",
    "\n",
    "    # --- El Tiempo ---\n",
    "    terminos_tiempo = [\"paro maestros 2023\", \"paro nacional docentes 2023\", \"ADE 2023\", \"FECODE 2023\"]\n",
    "    for termino in terminos_tiempo:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"El Tiempo\", \"https://www.eltiempo.com/buscar/\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- ADE ---\n",
    "    terminos_ade = [\"paro docentes\", \"paro maestros\", \"Fecode\", \"educaciÃ³n BogotÃ¡\"]\n",
    "    for termino in terminos_ade:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"ADE\", \"https://adebogota.org/?s=\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- FECODE ---\n",
    "    terminos_fecode = [\"paro nacional\", \"paro docentes\", \"maestros\", \"educaciÃ³n Colombia\"]\n",
    "    for termino in terminos_fecode:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"FECODE\", \"https://www.fecode.edu.co/index.php/component/search/?searchword=\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- GoogleNews ---\n",
    "    resultados_totales.extend(buscar_con_googlenews())\n",
    "\n",
    "    # --- SerpAPI ---\n",
    "    resultados_totales.extend(buscar_con_serpapi(SerpAPI_tkn1))\n",
    "\n",
    "    print(f\"\\nâœ… Total de noticias recopiladas: {len(resultados_totales)}\")\n",
    "\n",
    "    # ============================================\n",
    "    # FASE 2: ANÃLISIS CON IA\n",
    "    # ============================================\n",
    "    print(\"\\nğŸ¤– FASE 2: Analizando con IA...\")\n",
    "\n",
    "    for i, noticia in enumerate(resultados_totales, 1):\n",
    "        print(f\"\\n[{i}/{len(resultados_totales)}]\", end=\" \")\n",
    "\n",
    "        # Llama a la funciÃ³n de anÃ¡lisis IA\n",
    "        analisis = analizar_con_ia(\n",
    "            noticia['titulo'],\n",
    "            noticia.get('descripcion', ''),\n",
    "            noticia.get('url', '')\n",
    "        )\n",
    "\n",
    "        # Agrega los resultados del anÃ¡lisis al diccionario de la noticia\n",
    "        noticia.update(analisis)\n",
    "\n",
    "        # Espera 2 segundos entre llamadas (para no saturar la API de OpenAI)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # ============================================\n",
    "    # FASE 3: GUARDAR RESULTADOS EN CSV\n",
    "    # ============================================\n",
    "    print(\"\\nğŸ’¾ FASE 3: Guardando resultados...\")\n",
    "\n",
    "    df = pd.DataFrame(resultados_totales)\n",
    "\n",
    "    # Reordena columnas para mejor visualizaciÃ³n\n",
    "    columnas_importantes = [\n",
    "        'titulo', 'fuente', 'fecha_publicacion', 'url',\n",
    "        'es_paro_docente', 'hay_suspension_clases', 'ubicacion_bogota',\n",
    "        'duracion_dias', 'organizaciones_sindicales', 'razones_paro',\n",
    "        'costo_mencionado', 'justificacion_paro', 'resumen',\n",
    "        'descripcion', 'periodo_busqueda', 'fecha_extraccion'\n",
    "    ]\n",
    "\n",
    "    # Solo incluye columnas que existan en el DataFrame\n",
    "    columnas_finales = [col for col in columnas_importantes if col in df.columns]\n",
    "    df = df[columnas_finales]\n",
    "\n",
    "    # Guarda en CSV\n",
    "    nombre_archivo = \"noticias_paros_docentes_2023_ANALIZADO.csv\"\n",
    "    df.to_csv(nombre_archivo, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "    print(f\"âœ… Archivo guardado: {nombre_archivo}\")\n",
    "    print(f\"ğŸ“Š Total de noticias: {len(df)}\")\n",
    "\n",
    "    # ============================================\n",
    "    # ESTADÃSTICAS FINALES\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“ˆ ESTADÃSTICAS DEL ANÃLISIS\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    paros_verdaderos = df[df['es_paro_docente'] == True]\n",
    "    print(f\"ğŸ”´ Paros verdaderos (con suspensiÃ³n de clases): {len(paros_verdaderos)}\")\n",
    "\n",
    "    en_bogota = df[df['ubicacion_bogota'] == True]\n",
    "    print(f\"ğŸ“ Eventos en BogotÃ¡: {len(en_bogota)}\")\n",
    "\n",
    "    con_duracion = df[df['duracion_dias'].notna()]\n",
    "    if len(con_duracion) > 0:\n",
    "        print(f\"â±ï¸ DuraciÃ³n promedio: {con_duracion['duracion_dias'].mean():.1f} dÃ­as\")\n",
    "\n",
    "    print(\"\\nğŸ‰ Â¡AnÃ¡lisis completado!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
