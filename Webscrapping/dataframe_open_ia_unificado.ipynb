{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkSvsAjyLKZa",
        "outputId": "5707748e-49f3-4902-8dda-bf69a962538c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.12/dist-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.5)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (1.3.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.4.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.4)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.12)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.3.0)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2025.10.5)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.20.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.37.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio<1.0,>=0.31.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.31.0)\n",
            "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: serpapi in /usr/local/lib/python3.12/dist-packages (0.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from serpapi) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2025.10.5)\n",
            "Requirement already satisfied: GoogleNews in /usr/local/lib/python3.12/dist-packages (1.6.15)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (4.13.5)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (2.9.0.post0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (4.15.0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (5.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->GoogleNews) (1.17.0)\n",
            "Requirement already satisfied: googlesearch-python in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (4.13.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2025.10.5)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.10.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement concurrent.futures (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for concurrent.futures\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: httpx[http2] in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (3.11)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.3.0)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx[http2]) (0.16.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (4.15.0)\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.12/dist-packages (from lxml[html_clean]) (0.4.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install openpyxl\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install newspaper3k\n",
        "!pip install selenium\n",
        "!pip install openai\n",
        "!pip install serpapi\n",
        "!pip install GoogleNews\n",
        "!pip install googlesearch-python\n",
        "!pip install google-search-results\n",
        "!pip install concurrent.futures\n",
        "!pip install \"httpx[http2]\"\n",
        "!pip install \"lxml[html_clean]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TyeXW1uiL0sD"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote_plus\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "from GoogleNews import GoogleNews\n",
        "from serpapi import GoogleSearch\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3NoVtb1yKNoa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ================================================================\n",
        "# Keys\n",
        "# ================================================================\n",
        "OPENAI_API_KEY = \"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\"\n",
        "SerpAPI_tkn1 = \"3e815855bc007210de64f13b41d3a9dd56da0540c5da030c9b4baf6142e0c830\"\n",
        "SESSION = requests.Session()\n",
        "SESSION.headers.update({'User-Agent': 'Mozilla/5.0 (compatible; EduNews/3.1)'})\n",
        "SESSION_TIMEOUT = 15\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7oJYCffFKmMS",
        "outputId": "a8ea0f9a-ab16-41f5-afd6-17df57cd43b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            " INICIANDO SCRAPER + ANÃLISIS IA\n",
            "============================================================\n",
            "\n",
            " FASE 1: Recopilando noticias...\n",
            "\n",
            "ğŸ” Buscando en El Tiempo: paro docentes\n",
            "ğŸ“° Encontrados 20 artÃ­culos en El Tiempo\n",
            "\n",
            "ğŸ” Buscando en El Tiempo: paro maestros\n",
            "ğŸ“° Encontrados 20 artÃ­culos en El Tiempo\n",
            "\n",
            "ğŸ” Buscando en El Tiempo: suspensiÃ³n de clases 2023\n",
            "ğŸ“° Encontrados 20 artÃ­culos en El Tiempo\n",
            "\n",
            "ğŸ” Buscando en El Tiempo: cese de actividades escolares 2023\n",
            "ğŸ“° Encontrados 20 artÃ­culos en El Tiempo\n",
            "\n",
            "ğŸ” Buscando en El Tiempo: FECODE 2023\n",
            "ğŸ“° Encontrados 20 artÃ­culos en El Tiempo\n",
            "\n",
            "ğŸ” Buscando en El Tiempo: huelga de profesores\n",
            "ğŸ“° Encontrados 20 artÃ­culos en El Tiempo\n",
            "\n",
            "ğŸ” Buscando en El Tiempo: protesta docente 2023\n",
            "ğŸ“° Encontrados 20 artÃ­culos en El Tiempo\n",
            "\n",
            "ğŸ” Buscando en El Espectador: paro docentes\n",
            "ğŸ“° Encontrados 0 artÃ­culos en El Espectador\n",
            "\n",
            "ğŸ” Buscando en El Espectador: paro maestros\n",
            "ğŸ“° Encontrados 0 artÃ­culos en El Espectador\n",
            "\n",
            "ğŸ” Buscando en El Espectador: suspensiÃ³n de clases 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en El Espectador\n",
            "\n",
            "ğŸ” Buscando en El Espectador: cese de actividades escolares 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en El Espectador\n",
            "\n",
            "ğŸ” Buscando en El Espectador: FECODE 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en El Espectador\n",
            "\n",
            "ğŸ” Buscando en El Espectador: huelga de profesores\n",
            "ğŸ“° Encontrados 0 artÃ­culos en El Espectador\n",
            "\n",
            "ğŸ” Buscando en El Espectador: protesta docente 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en El Espectador\n",
            "\n",
            "ğŸ” Buscando en FECODE: paro docentes\n",
            "ğŸ“° Encontrados 4 artÃ­culos en FECODE\n",
            "\n",
            "ğŸ” Buscando en FECODE: paro maestros\n",
            "ğŸ“° Encontrados 2 artÃ­culos en FECODE\n",
            "\n",
            "ğŸ” Buscando en FECODE: suspensiÃ³n de clases 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en FECODE\n",
            "\n",
            "ğŸ” Buscando en FECODE: cese de actividades escolares 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en FECODE\n",
            "\n",
            "ğŸ” Buscando en FECODE: FECODE 2023\n",
            "ğŸ“° Encontrados 5 artÃ­culos en FECODE\n",
            "\n",
            "ğŸ” Buscando en FECODE: huelga de profesores\n",
            "ğŸ“° Encontrados 0 artÃ­culos en FECODE\n",
            "\n",
            "ğŸ” Buscando en FECODE: protesta docente 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en FECODE\n",
            "\n",
            "ğŸ” Buscando en ADE BogotÃ¡: paro docentes\n",
            "ğŸ“° Encontrados 0 artÃ­culos en ADE BogotÃ¡\n",
            "\n",
            "ğŸ” Buscando en ADE BogotÃ¡: paro maestros\n",
            "ğŸ“° Encontrados 0 artÃ­culos en ADE BogotÃ¡\n",
            "\n",
            "ğŸ” Buscando en ADE BogotÃ¡: suspensiÃ³n de clases 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en ADE BogotÃ¡\n",
            "\n",
            "ğŸ” Buscando en ADE BogotÃ¡: cese de actividades escolares 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en ADE BogotÃ¡\n",
            "\n",
            "ğŸ” Buscando en ADE BogotÃ¡: FECODE 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en ADE BogotÃ¡\n",
            "\n",
            "ğŸ” Buscando en ADE BogotÃ¡: huelga de profesores\n",
            "ğŸ“° Encontrados 0 artÃ­culos en ADE BogotÃ¡\n",
            "\n",
            "ğŸ” Buscando en ADE BogotÃ¡: protesta docente 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en ADE BogotÃ¡\n",
            "\n",
            "ğŸ” Buscando en SED: paro docentes\n",
            "ğŸ“° Encontrados 0 artÃ­culos en SED\n",
            "\n",
            "ğŸ” Buscando en SED: paro maestros\n",
            "ğŸ“° Encontrados 0 artÃ­culos en SED\n",
            "\n",
            "ğŸ” Buscando en SED: suspensiÃ³n de clases 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en SED\n",
            "\n",
            "ğŸ” Buscando en SED: cese de actividades escolares 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en SED\n",
            "\n",
            "ğŸ” Buscando en SED: FECODE 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en SED\n",
            "\n",
            "ğŸ” Buscando en SED: huelga de profesores\n",
            "ğŸ“° Encontrados 0 artÃ­culos en SED\n",
            "\n",
            "ğŸ” Buscando en SED: protesta docente 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en SED\n",
            "\n",
            "ğŸ” Buscando en Bogota.gov: paro docentes\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Bogota.gov\n",
            "\n",
            "ğŸ” Buscando en Bogota.gov: paro maestros\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Bogota.gov\n",
            "\n",
            "ğŸ” Buscando en Bogota.gov: suspensiÃ³n de clases 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Bogota.gov\n",
            "\n",
            "ğŸ” Buscando en Bogota.gov: cese de actividades escolares 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Bogota.gov\n",
            "\n",
            "ğŸ” Buscando en Bogota.gov: FECODE 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Bogota.gov\n",
            "\n",
            "ğŸ” Buscando en Bogota.gov: huelga de profesores\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Bogota.gov\n",
            "\n",
            "ğŸ” Buscando en Bogota.gov: protesta docente 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Bogota.gov\n",
            "\n",
            "ğŸ” Buscando en El colombiano: paro docentes\n",
            "âŒ Error en El colombiano: 500 Server Error: 500 for url: https://www.elcolombiano.com/busquedas/-/search/paro+docentes\n",
            "\n",
            "ğŸ” Buscando en El colombiano: paro maestros\n",
            "âŒ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/paro+maestros\n",
            "\n",
            "ğŸ” Buscando en El colombiano: suspensiÃ³n de clases 2023\n",
            "âŒ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/suspensi%C3%B3n+de+clases+2023\n",
            "\n",
            "ğŸ” Buscando en El colombiano: cese de actividades escolares 2023\n",
            "âŒ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/cese+de+actividades+escolares+2023\n",
            "\n",
            "ğŸ” Buscando en El colombiano: FECODE 2023\n",
            "âŒ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/FECODE+2023\n",
            "\n",
            "ğŸ” Buscando en El colombiano: huelga de profesores\n",
            "âŒ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/huelga+de+profesores\n",
            "\n",
            "ğŸ” Buscando en El colombiano: protesta docente 2023\n",
            "âŒ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/protesta+docente+2023\n",
            "\n",
            "ğŸ” Buscando en Caracol: paro docentes\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Caracol\n",
            "\n",
            "ğŸ” Buscando en Caracol: paro maestros\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Caracol\n",
            "\n",
            "ğŸ” Buscando en Caracol: suspensiÃ³n de clases 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Caracol\n",
            "\n",
            "ğŸ” Buscando en Caracol: cese de actividades escolares 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Caracol\n",
            "\n",
            "ğŸ” Buscando en Caracol: FECODE 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Caracol\n",
            "\n",
            "ğŸ” Buscando en Caracol: huelga de profesores\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Caracol\n",
            "\n",
            "ğŸ” Buscando en Caracol: protesta docente 2023\n",
            "ğŸ“° Encontrados 0 artÃ­culos en Caracol\n",
            "\n",
            "ğŸ” Buscando en Valora Analitik: paro docentes\n",
            "âŒ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "ğŸ” Buscando en Valora Analitik: paro maestros\n",
            "âŒ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "ğŸ” Buscando en Valora Analitik: suspensiÃ³n de clases 2023\n",
            "âŒ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "ğŸ” Buscando en Valora Analitik: cese de actividades escolares 2023\n",
            "âŒ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "ğŸ” Buscando en Valora Analitik: FECODE 2023\n",
            "âŒ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "ğŸ” Buscando en Valora Analitik: huelga de profesores\n",
            "âŒ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "ğŸ” Buscando en Valora Analitik: protesta docente 2023\n",
            "âŒ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "ğŸ” Buscando en Portafolio: paro docentes\n",
            "ğŸ“° Encontrados 15 artÃ­culos en Portafolio\n",
            "\n",
            "ğŸ” Buscando en Portafolio: paro maestros\n",
            "ğŸ“° Encontrados 15 artÃ­culos en Portafolio\n",
            "\n",
            "ğŸ” Buscando en Portafolio: suspensiÃ³n de clases 2023\n",
            "ğŸ“° Encontrados 15 artÃ­culos en Portafolio\n",
            "\n",
            "ğŸ” Buscando en Portafolio: cese de actividades escolares 2023\n",
            "ğŸ“° Encontrados 15 artÃ­culos en Portafolio\n",
            "\n",
            "ğŸ” Buscando en Portafolio: FECODE 2023\n",
            "ğŸ“° Encontrados 15 artÃ­culos en Portafolio\n",
            "\n",
            "ğŸ” Buscando en Portafolio: huelga de profesores\n",
            "ğŸ“° Encontrados 15 artÃ­culos en Portafolio\n",
            "\n",
            "ğŸ” Buscando en Portafolio: protesta docente 2023\n",
            "ğŸ“° Encontrados 15 artÃ­culos en Portafolio\n",
            "âœ… GoogleNews: 550 resultados\n",
            "\n",
            "ğŸ” Buscando con SerpAPI...\n",
            "âœ… SerpAPI: 40 resultados\n",
            "\n",
            "âœ… Total de noticias recopiladas: 601\n",
            "\n",
            " FASE 2: Analizando con IA\n",
            "\n",
            "[1/601]   ğŸ¤– Analizando: Circulares 2023...\n",
            "\n",
            "[2/601]   ğŸ¤– Analizando: Documentos 2025...\n",
            "\n",
            "[3/601]   ğŸ¤– Analizando: Circulares 2025...\n",
            "\n",
            "[4/601]   ğŸ¤– Analizando: Inicio...\n",
            "\n",
            "[5/601]   ğŸ¤– Analizando: Circulares 2023...\n",
            "\n",
            "[6/601]   ğŸ¤– Analizando: Documentos 2025...\n",
            "\n",
            "[7/601]   ğŸ¤– Analizando: Elecciones Fecode 2023...\n",
            "\n",
            "[8/601]   ğŸ¤– Analizando: Acuerdo FECODE â€“ MEN 2023...\n",
            "\n",
            "[9/601]   ğŸ¤– Analizando: Circulares 2023...\n",
            "\n",
            "[10/601]   ğŸ¤– Analizando: Inicio...\n",
            "\n",
            "[11/601]   ğŸ¤– Analizando: Escuela Sindical Documentos...\n",
            "\n",
            "[12/601]   ğŸ¤– Analizando: AtenciÃ³n: Este serÃ¡ el nuevo paro nacional que vivirÃ¡ Colomb...\n",
            "\n",
            "[13/601]   ğŸ¤– Analizando: Fecode anunciÃ³ paro nacional de maestros: habrÃ¡ concentracio...\n",
            "\n",
            "[14/601]   ğŸ¤– Analizando: El secretario de EducaciÃ³n afirmÃ³ que el salario docente â€œha...\n",
            "\n",
            "[15/601]   ğŸ¤– Analizando: El Eje Cafetero se levanta: maestros anuncian marchas y bloq...\n",
            "\n",
            "[16/601]   ğŸ¤– Analizando: Paro de docentes de Eje Cafetero durarÃ¡ 72 horas: marchas en...\n",
            "\n",
            "[17/601]   ğŸ¤– Analizando: Maestros de nuevo se van a paro, impactarÃ¡ en tres regiones,...\n",
            "\n",
            "[18/601]   ğŸ¤– Analizando: Paro docente y no docente. Universitarios necesitan un 46% d...\n",
            "\n",
            "[19/601]   ğŸ¤– Analizando: Paro docente universitario: \"Nosotros hemos perdido un 44% d...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2242959668.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Llama a la funciÃ³n de anÃ¡lisis IA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         analisis = analizar_con_ia(\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mnoticia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'titulo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mnoticia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'descripcion'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2242959668.py\u001b[0m in \u001b[0;36manalizar_con_ia\u001b[0;34m(titulo, descripcion, url)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# ============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    983\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import re\n",
        "from dateutil import parser\n",
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote_plus\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "from GoogleNews import GoogleNews\n",
        "from serpapi import GoogleSearch\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import json\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# ================================================================\n",
        "# CONFIGURACIÃ“N\n",
        "# ================================================================\n",
        "HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
        "TIMEOUT = 10\n",
        "MAX_RESULTS = 300  # ğŸ”¼ aumenta el nÃºmero de resultados\n",
        "YEAR = \"2023\"\n",
        "\n",
        "def link_valido(url):\n",
        "    try:\n",
        "        r = requests.head(url, timeout=5, allow_redirects=True)\n",
        "        return r.status_code == 200\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "#  SCRAPING DE FUENTES ESPECÃFICAS\n",
        "# ================================================================\n",
        "def buscar_noticias_generales(nombre_fuente, url_base, termino_busqueda, max_resultados=150):\n",
        "    \"\"\"Scrapea noticias desde sitios como El Tiempo, ADE o FECODE.\"\"\"\n",
        "    print(f\"\\nğŸ” Buscando en {nombre_fuente}: {termino_busqueda}\")\n",
        "    datos = []\n",
        "    termino_codificado = quote_plus(termino_busqueda)\n",
        "    url_busqueda = f\"{url_base}{termino_codificado}\"\n",
        "\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url_busqueda, headers=headers, timeout=20)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        articulos = soup.find_all('article', limit=max_resultados)\n",
        "        print(f\"ğŸ“° Encontrados {len(articulos)} artÃ­culos en {nombre_fuente}\")\n",
        "\n",
        "        for art in articulos:\n",
        "            titulo = (art.find('h2') or art.find('h3'))\n",
        "            enlace = art.find('a', href=True)\n",
        "\n",
        "            if not titulo or not enlace:\n",
        "                continue\n",
        "\n",
        "            link = enlace['href']\n",
        "            if not link.startswith('http'):\n",
        "                link = f\"{url_base.rstrip('/')}/{link.lstrip('/')}\"\n",
        "\n",
        "            if not link_valido(link):\n",
        "                continue\n",
        "\n",
        "            descripcion = art.find('p').get_text(strip=True) if art.find('p') else ''\n",
        "            fecha_elem = art.find('time')\n",
        "            fecha = fecha_elem.get_text(strip=True) if fecha_elem else 'No especificada'\n",
        "\n",
        "            datos.append({\n",
        "                'fuente': nombre_fuente,\n",
        "                'titulo': titulo.get_text(strip=True),\n",
        "                'descripcion': descripcion,\n",
        "                'fecha_publicacion': fecha,\n",
        "                'url': link,\n",
        "                'periodo_busqueda': termino_busqueda,\n",
        "                'fecha_extraccion': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error en {nombre_fuente}: {e}\")\n",
        "\n",
        "    time.sleep(random.uniform(1.5, 3.5))\n",
        "    return datos\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "#  GOOGLE NEWS\n",
        "# ================================================================\n",
        "def buscar_con_googlenews():\n",
        "    googlenews = GoogleNews(lang='es', encode='utf-8')\n",
        "    googlenews.set_time_range('12/01/2022', '02/01/2024')\n",
        "    resultados = []\n",
        "\n",
        "    queries = [\n",
        "        'paro docente Colombia 2023', 'paro maestros BogotÃ¡ 2023', 'FECODE paro 2023',\n",
        "        'huelga de profesores Colombia 2023', 'protestas docentes educaciÃ³n 2023',\n",
        "        'ADE BogotÃ¡ paro 2023', 'magisterio colombiano paro 2023',\n",
        "        'ministerio educaciÃ³n paro maestros 2023', 'paro educativo nacional Colombia 2023',\n",
        "        'suspensiÃ³n de clases por paro docente 2023'\n",
        "    ]\n",
        "\n",
        "    for q in queries:\n",
        "        googlenews.search(q)\n",
        "        time.sleep(random.uniform(2, 4))\n",
        "        res = googlenews.result()\n",
        "        for r in res:\n",
        "            resultados.append({\n",
        "                'fuente': r.get('media', 'GoogleNews'),\n",
        "                'titulo': r.get('title'),\n",
        "                'descripcion': r.get('desc', ''),\n",
        "                'url': r.get('link', ''),\n",
        "                'fecha_publicacion': r.get('date', ''),\n",
        "                'periodo_busqueda': q,\n",
        "                'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            })\n",
        "    print(f\"âœ… GoogleNews: {len(resultados)} resultados\")\n",
        "    return resultados\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "#  SERPAPI\n",
        "# ================================================================\n",
        "def buscar_con_serpapi(api_key):\n",
        "    print(\"\\nğŸ” Buscando con SerpAPI...\")\n",
        "    resultados = []\n",
        "    queries = [\n",
        "        '(paro docente OR paro maestros OR huelga profesores OR FECODE OR ADE) Colombia 2023',\n",
        "        '(paro educativo OR suspensiÃ³n clases) BogotÃ¡ 2023',\n",
        "        '(FECODE protesta OR paro) Colombia 2023',\n",
        "        '(magisterio colombiano OR sindicato maestros) paro 2023',\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        params = {\n",
        "            \"engine\": \"google\",\n",
        "            \"q\": f\"{query} after:2022-12-01 before:2024-02-01\",\n",
        "            \"api_key\": api_key,\n",
        "            \"num\": 190\n",
        "        }\n",
        "        try:\n",
        "            search = GoogleSearch(params)\n",
        "            results = search.get_dict()\n",
        "            items = results.get(\"organic_results\", [])\n",
        "            for item in items:\n",
        "                resultados.append({\n",
        "                    'fuente': 'Google (SerpAPI)',\n",
        "                    'titulo': item.get('title'),\n",
        "                    'descripcion': item.get('snippet', ''),\n",
        "                    'url': item.get('link'),\n",
        "                    'fecha_publicacion': '',\n",
        "                    'periodo_busqueda': query,\n",
        "                    'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Error en SerpAPI: {e}\")\n",
        "            time.sleep(random.uniform(1, 2))\n",
        "    print(f\"âœ… SerpAPI: {len(resultados)} resultados\")\n",
        "    return resultados\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# ANÃLISIS CON IA\n",
        "# ================================================================\n",
        "\n",
        "def obtener_texto_completo(url):\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, timeout=15)\n",
        "        r.raise_for_status()\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "        # Elimina elementos que no son contenido principal\n",
        "        for s in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"aside\", \"form\"]):\n",
        "            s.extract()\n",
        "\n",
        "        texto = \" \".join(soup.stripped_strings)\n",
        "        return texto[:8000]  # MÃ¡ximo 8000 caracteres\n",
        "    except Exception as e:\n",
        "        return f\"Error al obtener contenido: {e}\"\n",
        "\n",
        "\n",
        "def analizar_con_ia(titulo, descripcion, url):\n",
        "    \"\"\"\n",
        "    ğŸ¤– EXPLICACIÃ“N (LA MÃS IMPORTANTE):\n",
        "    Esta funciÃ³n envÃ­a la noticia a GPT-4 para que la analice siguiendo criterios estrictos.\n",
        "\n",
        "    PROCESO:\n",
        "    1. Intenta descargar el contenido completo de la URL\n",
        "    2. Si falla, usa solo tÃ­tulo + descripciÃ³n, indicame si pudiste o no acceder al URL\n",
        "    3. Construye un prompt detallado con instrucciones para la IA\n",
        "    4. EnvÃ­a el prompt a OpenAI (modelo gpt-4o-mini)\n",
        "    5. Recibe respuesta en formato JSON\n",
        "    6. Parsea el JSON y devuelve un diccionario con las caracterÃ­sticas\n",
        "\n",
        "    CARACTERÃSTICAS QUE ANALIZA:\n",
        "    - es_paro_docente: Â¿Hubo suspensiÃ³n de clases?\n",
        "    - organizaciones_sindicales: Â¿QuÃ© sindicatos u organizaciones polÃ­ticas participaron?\n",
        "    - duracion_dias: Â¿CuÃ¡ntos dÃ­as durÃ³?\n",
        "    - ubicacion_bogota: Â¿OcurriÃ³ en BogotÃ¡?\n",
        "    - ubicacion_Colombia: Â¿AbarcÃ³ todo el territorio Nacional=\n",
        "    - costo_mencionado: Â¿Se habla de costos econÃ³micos?\n",
        "    - fecha_paro: Â¿cuÃ¡l es la fecha exacta del paro (dÃ­a, mes, aÃ±o)?\n",
        "    \"\"\"\n",
        "    print(f\"  ğŸ¤– Analizando: {titulo[:60]}...\")\n",
        "\n",
        "    contenido_completo = obtener_texto_completo(url) if url else \"\"\n",
        "\n",
        "    if \"Error\" in contenido_completo or not contenido_completo:\n",
        "        texto_analizar = f\"TÃ­tulo: {titulo}\\nDescripciÃ³n: {descripcion}\"\n",
        "    else:\n",
        "        texto_analizar = contenido_completo\n",
        "\n",
        "    # ============================================\n",
        "    #  PROMPT IA\n",
        "    # ============================================\n",
        "    prompt = f\"\"\"\n",
        "Analiza la siguiente noticia en espaÃ±ol sobre educaciÃ³n, sindicatos o protestas de docentes.\n",
        "\n",
        "CRITERIOS ESTRICTOS:\n",
        "- Un **paro docente verdadero** solo existe si hubo suspensiÃ³n de clases programadas.\n",
        "- Si fue marcha, manifestaciÃ³n o concentraciÃ³n SIN suspensiÃ³n de clases, NO es paro.\n",
        "- Debes explicar tu razonamiento.\n",
        "\n",
        "Devuelve un JSON con estas claves:\n",
        "\n",
        "- \"es_paro_docente\": true/false â†’ true solo si hubo suspensiÃ³n de clases\n",
        "- \"justificacion_paro\": texto breve (2-4 lÃ­neas) explicando por quÃ© es o no un paro\n",
        "- \"organizaciones_sindicales\": lista de sindicatos mencionados u organizaciones polÃ­ticas o partidos polÃ­ticos (ej: [\"FECODE\", \"ADE\"]), o []\n",
        "- \"hay_suspension_clases\": true/false â†’ si se suspendieron clases\n",
        "- \"duracion_dias\": nÃºmero de dÃ­as estimados, o null\n",
        "- \"razones_paro\": resumen de las demandas principales\n",
        "- \"ubicacion_bogota\": true/false â†’ si ocurre en BogotÃ¡/Cundinamarca\n",
        "- \"ubicacion_Colombia\": true/false â†’ si el paro abarca el territorio Nacional\n",
        "- \"costo_mencionado\": monto econÃ³mico si se menciona, o null\n",
        "- \"resumen\": breve resumen (mÃ¡x. 3 lÃ­neas)\n",
        "- \"fecha_paro\": Â¿cuÃ¡l es la fecha exacta del paro (dÃ­a, mes, aÃ±o)?\n",
        "- \"tipo_movilizacion\": Â¿cuÃ¡l es el tipo de movilizaciÃ³n, paro docente con las caracteristicas que ya vimos, paro de otro gremio, demostraciÃ³n, plantÃ³n, toma, marcha pacÃ­fica, etc?\n",
        "- \"ubicacion\": ademÃ¡s del paÃ­s y ciudad, podemos identificar localidades? barrios? calles? edificios? colegios especÃ­ficos o barrios?\n",
        "Devuelve SOLO el JSON vÃ¡lido, sin texto extra.\n",
        "- \"fuente_oficial\": Â¿es una fuente oficial de algÃºn sindicato o es media, si es media cual, si es sindicato, cual?\n",
        "\n",
        "Texto a analizar:\n",
        "{texto_analizar}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        # ============================================\n",
        "        #  API DE OPENAI\n",
        "        # ============================================\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0.1,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "\n",
        "        # Extrae el texto de la respuesta\n",
        "        respuesta_texto = response.choices[0].message.content.strip()\n",
        "\n",
        "        # ============================================\n",
        "        # PARSEO DEL JSON\n",
        "        # ============================================\n",
        "        # La IA devuelve un JSON como string, lo convertimos a diccionario\n",
        "        try:\n",
        "            # Intenta parsear directamente\n",
        "            analisis = json.loads(respuesta_texto)\n",
        "        except json.JSONDecodeError:\n",
        "            # Si falla, busca el JSON dentro de bloques de cÃ³digo ```json```\n",
        "            if \"```json\" in respuesta_texto:\n",
        "                inicio = respuesta_texto.find(\"```json\") + 7\n",
        "                fin = respuesta_texto.find(\"```\", inicio)\n",
        "                json_str = respuesta_texto[inicio:fin].strip()\n",
        "                analisis = json.loads(json_str)\n",
        "            else:\n",
        "                # Si todo falla, devuelve valores por defecto\n",
        "                print(\"    âš ï¸ No se pudo parsear el JSON\")\n",
        "                analisis = {\n",
        "                    'es_paro_docente': False,\n",
        "                    'justificacion_paro': 'Error al analizar',\n",
        "                    'organizaciones_sindicales': [],\n",
        "                    'hay_suspension_clases': False,\n",
        "                    'duracion_dias': None,\n",
        "                    'razones_paro': '',\n",
        "                    'ubicacion_bogota': False,\n",
        "                    'ubicacion_Colombia': False,\n",
        "                    'costo_mencionado': None,\n",
        "                    'resumen': '',\n",
        "                    'fecha_paro': None,\n",
        "                    'tipo_movilizacion': '',\n",
        "                    'ubicacion': '',\n",
        "                    'fuente_oficial': ''\n",
        "                }\n",
        "\n",
        "        return analisis\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    âŒ Error en anÃ¡lisis IA: {e}\")\n",
        "        if \"insufficient_quota\" in str(e):\n",
        "            print(\"    Please check your OpenAI API plan and billing details.\")\n",
        "        return {\n",
        "            'es_paro_docente': False,\n",
        "            'justificacion_paro': f'Error: {str(e)}',\n",
        "            'organizaciones_sindicales': [],\n",
        "            'hay_suspension_clases': False,\n",
        "            'duracion_dias': None,\n",
        "            'razones_paro': '',\n",
        "            'ubicacion_bogota': False,\n",
        "            'ubicacion_Colombia': False,\n",
        "            'costo_mencionado': None,\n",
        "            'resumen': '',\n",
        "            'fecha_paro': None,\n",
        "            'tipo_movilizacion': '',\n",
        "            'ubicacion': '',\n",
        "            'fuente_oficial': ''\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "#  EJECUCIÃ“N PRINCIPAL\n",
        "# ================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*60)\n",
        "    print(\" INICIANDO SCRAPER + ANÃLISIS IA\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    resultados_totales = []\n",
        "\n",
        "    # 1) Fuentes oficiales primero (mayor recall de 2023)\n",
        "    print(\"\\n FASE 1: Recopilando noticias...\")\n",
        "\n",
        "    fuentes = {\n",
        "        \"El Tiempo\": \"https://www.eltiempo.com/buscar/\",\n",
        "        \"El Espectador\": \"https://www.elespectador.com/buscador/\",\n",
        "        \"FECODE\": \"https://fecode.edu.co/?s=\",\n",
        "        \"ADE BogotÃ¡\": \"https://adebogota.org/index.php/buscar?q=\",\n",
        "        \"SED\": \"https://www.educacionbogota.edu.co/noticias?field_noticia_descripcion_value=\",\n",
        "        \"Bogota.gov\": \"https://bogota.gov.co/tag/ingreso-minimo-garantizado?search_api_fulltext=\",\n",
        "        \"Caracol\" : \"https://www.noticiascaracol.com/busqueda?q=\",\n",
        "        \"Valora Analitik\" : \"https://www.valoraanalitik.com/?s=\",\n",
        "        \"Portafolio\": \"https://www.portafolio.co/buscar?q=\",\n",
        "    }\n",
        "    terminos = [\n",
        "        \"paro docentes\", \"paro maestros\", \"suspensiÃ³n de clases 2023\",\n",
        "        \"cese de actividades escolares 2023\", \"FECODE 2023\", \"huelga de profesores\",\n",
        "        \"protesta docente 2023\"\n",
        "    ]\n",
        "    for fuente, url_base in fuentes.items():\n",
        "        for termino in terminos:\n",
        "            resultados_totales.extend(\n",
        "                buscar_noticias_generales(fuente, url_base, termino)\n",
        "            )\n",
        "            time.sleep(random.uniform(2, 4))\n",
        "\n",
        "   # 2) GoogleNews y SerpAPI\n",
        "    resultados_totales.extend(buscar_con_googlenews())\n",
        "    resultados_totales.extend(buscar_con_serpapi(SerpAPI_tkn1))\n",
        "\n",
        "    df = pd.DataFrame(resultados_totales).drop_duplicates(subset=\"url\")\n",
        "    df.to_csv(\"noticias_paros_docentes_2023_SUPER.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "    print(f\"\\nâœ… Total de noticias recopiladas: {len(resultados_totales)}\")\n",
        "\n",
        "    # ============================================\n",
        "    # ANÃLISIS CON IA\n",
        "    # ============================================\n",
        "    print(\"\\n FASE 2: Analizando con IA\")\n",
        "\n",
        "    for i, noticia in enumerate(resultados_totales, 1):\n",
        "        print(f\"\\n[{i}/{len(resultados_totales)}]\", end=\" \")\n",
        "\n",
        "        # Llama a la funciÃ³n de anÃ¡lisis IA\n",
        "        analisis = analizar_con_ia(\n",
        "            noticia['titulo'],\n",
        "            noticia.get('descripcion', ''),\n",
        "            noticia.get('url', '')\n",
        "        )\n",
        "\n",
        "        # Agrega los resultados del anÃ¡lisis al diccionario de la noticia\n",
        "        noticia.update(analisis)\n",
        "\n",
        "        # Espera 2 seconds between calls (to avoid saturating the OpenAI API)\n",
        "        time.sleep(2)\n",
        "\n",
        "    # ============================================\n",
        "    # FASE 3: GUARDAR RESULTADOS EN CSV\n",
        "    # ============================================\n",
        "    print(\"\\n FASE 3: Guardando resultados...\")\n",
        "\n",
        "    df = pd.DataFrame(resultados_totales)\n",
        "    if not df.empty:\n",
        "       df = df.drop_duplicates(subset='url', keep='first')\n",
        "    columnas_importantes = [\n",
        "        'titulo', 'fuente', 'fecha_publicacion', 'url',\n",
        "        'es_paro_docente', 'hay_suspension_clases', 'ubicacion_bogota',\n",
        "        'ubicacion_Colombia', 'duracion_dias', 'organizaciones_sindicales',\n",
        "        'razones_paro', 'costo_mencionado', 'justificacion_paro', 'resumen',\n",
        "        'fecha_paro', 'tipo_movilizacion', 'ubicacion',\n",
        "        'descripcion', 'periodo_busqueda', 'fecha_extraccion', 'fuente_oficial'\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Solo incluye columnas que existan en el DataFrame\n",
        "    columnas_finales = [col for col in columnas_importantes if col in df.columns]\n",
        "    df = df[columnas_finales]\n",
        "\n",
        "    # Guarda en CSV\n",
        "    nombre_archivo = \"noticias_paros_docentes_2023_ANALIZADO.csv\"\n",
        "    df.to_csv(nombre_archivo, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "    print(f\"âœ… Archivo guardado: {nombre_archivo}\")\n",
        "    print(f\"ğŸ“Š Total de noticias: {len(df)}\")\n",
        "\n",
        "    # ============================================\n",
        "    # ESTADÃSTICAS FINALES\n",
        "    # ============================================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ“ˆ ESTADÃSTICAS DEL ANÃLISIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    paros_verdaderos = df[df['es_paro_docente'] == True]\n",
        "    print(f\"ğŸ”´ Paros verdaderos (con suspensiÃ³n de clases): {len(paros_verdaderos)}\")\n",
        "\n",
        "    en_bogota = df[df['ubicacion_bogota'] == True]\n",
        "    print(f\"ğŸ“ Eventos en BogotÃ¡: {len(en_bogota)}\")\n",
        "\n",
        "    con_duracion = df[df['duracion_dias'].notna()]\n",
        "    if len(con_duracion) > 0:\n",
        "        print(f\"â±ï¸ DuraciÃ³n promedio: {con_duracion['duracion_dias'].mean():.1f} dÃ­as\")\n",
        "\n",
        "    print(\"\\nğŸ‰ Â¡AnÃ¡lisis completado!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}