{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkSvsAjyLKZa",
        "outputId": "5707748e-49f3-4902-8dda-bf69a962538c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.12/dist-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.5)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (1.3.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.4.0)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.4)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.12)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.3.0)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.12/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.3.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2025.10.5)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.0.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.20.0)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.12/dist-packages (4.37.0)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio<1.0,>=0.31.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.31.0)\n",
            "Requirement already satisfied: trio-websocket<1.0,>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.12/dist-packages (from trio-websocket<1.0,>=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: serpapi in /usr/local/lib/python3.12/dist-packages (0.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from serpapi) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2025.10.5)\n",
            "Requirement already satisfied: GoogleNews in /usr/local/lib/python3.12/dist-packages (1.6.15)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (4.13.5)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (2.9.0.post0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (4.15.0)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2024.11.6)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (5.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->GoogleNews) (1.17.0)\n",
            "Requirement already satisfied: googlesearch-python in /usr/local/lib/python3.12/dist-packages (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (4.13.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (2.32.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2025.10.5)\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.10.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement concurrent.futures (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for concurrent.futures\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: httpx[http2] in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (3.11)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.3.0)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx[http2]) (0.16.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (4.15.0)\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
            "Requirement already satisfied: lxml_html_clean in /usr/local/lib/python3.12/dist-packages (from lxml[html_clean]) (0.4.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install openpyxl\n",
        "!pip install requests\n",
        "!pip install beautifulsoup4\n",
        "!pip install newspaper3k\n",
        "!pip install selenium\n",
        "!pip install openai\n",
        "!pip install serpapi\n",
        "!pip install GoogleNews\n",
        "!pip install googlesearch-python\n",
        "!pip install google-search-results\n",
        "!pip install concurrent.futures\n",
        "!pip install \"httpx[http2]\"\n",
        "!pip install \"lxml[html_clean]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "TyeXW1uiL0sD"
      },
      "outputs": [],
      "source": [
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote_plus\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "from GoogleNews import GoogleNews\n",
        "from serpapi import GoogleSearch\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "3NoVtb1yKNoa"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ================================================================\n",
        "# Keys\n",
        "# ================================================================\n",
        "OPENAI_API_KEY = \"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\"\n",
        "SerpAPI_tkn1 = \"3e815855bc007210de64f13b41d3a9dd56da0540c5da030c9b4baf6142e0c830\"\n",
        "SESSION = requests.Session()\n",
        "SESSION.headers.update({'User-Agent': 'Mozilla/5.0 (compatible; EduNews/3.1)'})\n",
        "SESSION_TIMEOUT = 15\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7oJYCffFKmMS",
        "outputId": "a8ea0f9a-ab16-41f5-afd6-17df57cd43b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            " INICIANDO SCRAPER + ANÁLISIS IA\n",
            "============================================================\n",
            "\n",
            " FASE 1: Recopilando noticias...\n",
            "\n",
            "🔍 Buscando en El Tiempo: paro docentes\n",
            "📰 Encontrados 20 artículos en El Tiempo\n",
            "\n",
            "🔍 Buscando en El Tiempo: paro maestros\n",
            "📰 Encontrados 20 artículos en El Tiempo\n",
            "\n",
            "🔍 Buscando en El Tiempo: suspensión de clases 2023\n",
            "📰 Encontrados 20 artículos en El Tiempo\n",
            "\n",
            "🔍 Buscando en El Tiempo: cese de actividades escolares 2023\n",
            "📰 Encontrados 20 artículos en El Tiempo\n",
            "\n",
            "🔍 Buscando en El Tiempo: FECODE 2023\n",
            "📰 Encontrados 20 artículos en El Tiempo\n",
            "\n",
            "🔍 Buscando en El Tiempo: huelga de profesores\n",
            "📰 Encontrados 20 artículos en El Tiempo\n",
            "\n",
            "🔍 Buscando en El Tiempo: protesta docente 2023\n",
            "📰 Encontrados 20 artículos en El Tiempo\n",
            "\n",
            "🔍 Buscando en El Espectador: paro docentes\n",
            "📰 Encontrados 0 artículos en El Espectador\n",
            "\n",
            "🔍 Buscando en El Espectador: paro maestros\n",
            "📰 Encontrados 0 artículos en El Espectador\n",
            "\n",
            "🔍 Buscando en El Espectador: suspensión de clases 2023\n",
            "📰 Encontrados 0 artículos en El Espectador\n",
            "\n",
            "🔍 Buscando en El Espectador: cese de actividades escolares 2023\n",
            "📰 Encontrados 0 artículos en El Espectador\n",
            "\n",
            "🔍 Buscando en El Espectador: FECODE 2023\n",
            "📰 Encontrados 0 artículos en El Espectador\n",
            "\n",
            "🔍 Buscando en El Espectador: huelga de profesores\n",
            "📰 Encontrados 0 artículos en El Espectador\n",
            "\n",
            "🔍 Buscando en El Espectador: protesta docente 2023\n",
            "📰 Encontrados 0 artículos en El Espectador\n",
            "\n",
            "🔍 Buscando en FECODE: paro docentes\n",
            "📰 Encontrados 4 artículos en FECODE\n",
            "\n",
            "🔍 Buscando en FECODE: paro maestros\n",
            "📰 Encontrados 2 artículos en FECODE\n",
            "\n",
            "🔍 Buscando en FECODE: suspensión de clases 2023\n",
            "📰 Encontrados 0 artículos en FECODE\n",
            "\n",
            "🔍 Buscando en FECODE: cese de actividades escolares 2023\n",
            "📰 Encontrados 0 artículos en FECODE\n",
            "\n",
            "🔍 Buscando en FECODE: FECODE 2023\n",
            "📰 Encontrados 5 artículos en FECODE\n",
            "\n",
            "🔍 Buscando en FECODE: huelga de profesores\n",
            "📰 Encontrados 0 artículos en FECODE\n",
            "\n",
            "🔍 Buscando en FECODE: protesta docente 2023\n",
            "📰 Encontrados 0 artículos en FECODE\n",
            "\n",
            "🔍 Buscando en ADE Bogotá: paro docentes\n",
            "📰 Encontrados 0 artículos en ADE Bogotá\n",
            "\n",
            "🔍 Buscando en ADE Bogotá: paro maestros\n",
            "📰 Encontrados 0 artículos en ADE Bogotá\n",
            "\n",
            "🔍 Buscando en ADE Bogotá: suspensión de clases 2023\n",
            "📰 Encontrados 0 artículos en ADE Bogotá\n",
            "\n",
            "🔍 Buscando en ADE Bogotá: cese de actividades escolares 2023\n",
            "📰 Encontrados 0 artículos en ADE Bogotá\n",
            "\n",
            "🔍 Buscando en ADE Bogotá: FECODE 2023\n",
            "📰 Encontrados 0 artículos en ADE Bogotá\n",
            "\n",
            "🔍 Buscando en ADE Bogotá: huelga de profesores\n",
            "📰 Encontrados 0 artículos en ADE Bogotá\n",
            "\n",
            "🔍 Buscando en ADE Bogotá: protesta docente 2023\n",
            "📰 Encontrados 0 artículos en ADE Bogotá\n",
            "\n",
            "🔍 Buscando en SED: paro docentes\n",
            "📰 Encontrados 0 artículos en SED\n",
            "\n",
            "🔍 Buscando en SED: paro maestros\n",
            "📰 Encontrados 0 artículos en SED\n",
            "\n",
            "🔍 Buscando en SED: suspensión de clases 2023\n",
            "📰 Encontrados 0 artículos en SED\n",
            "\n",
            "🔍 Buscando en SED: cese de actividades escolares 2023\n",
            "📰 Encontrados 0 artículos en SED\n",
            "\n",
            "🔍 Buscando en SED: FECODE 2023\n",
            "📰 Encontrados 0 artículos en SED\n",
            "\n",
            "🔍 Buscando en SED: huelga de profesores\n",
            "📰 Encontrados 0 artículos en SED\n",
            "\n",
            "🔍 Buscando en SED: protesta docente 2023\n",
            "📰 Encontrados 0 artículos en SED\n",
            "\n",
            "🔍 Buscando en Bogota.gov: paro docentes\n",
            "📰 Encontrados 0 artículos en Bogota.gov\n",
            "\n",
            "🔍 Buscando en Bogota.gov: paro maestros\n",
            "📰 Encontrados 0 artículos en Bogota.gov\n",
            "\n",
            "🔍 Buscando en Bogota.gov: suspensión de clases 2023\n",
            "📰 Encontrados 0 artículos en Bogota.gov\n",
            "\n",
            "🔍 Buscando en Bogota.gov: cese de actividades escolares 2023\n",
            "📰 Encontrados 0 artículos en Bogota.gov\n",
            "\n",
            "🔍 Buscando en Bogota.gov: FECODE 2023\n",
            "📰 Encontrados 0 artículos en Bogota.gov\n",
            "\n",
            "🔍 Buscando en Bogota.gov: huelga de profesores\n",
            "📰 Encontrados 0 artículos en Bogota.gov\n",
            "\n",
            "🔍 Buscando en Bogota.gov: protesta docente 2023\n",
            "📰 Encontrados 0 artículos en Bogota.gov\n",
            "\n",
            "🔍 Buscando en El colombiano: paro docentes\n",
            "❌ Error en El colombiano: 500 Server Error: 500 for url: https://www.elcolombiano.com/busquedas/-/search/paro+docentes\n",
            "\n",
            "🔍 Buscando en El colombiano: paro maestros\n",
            "❌ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/paro+maestros\n",
            "\n",
            "🔍 Buscando en El colombiano: suspensión de clases 2023\n",
            "❌ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/suspensi%C3%B3n+de+clases+2023\n",
            "\n",
            "🔍 Buscando en El colombiano: cese de actividades escolares 2023\n",
            "❌ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/cese+de+actividades+escolares+2023\n",
            "\n",
            "🔍 Buscando en El colombiano: FECODE 2023\n",
            "❌ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/FECODE+2023\n",
            "\n",
            "🔍 Buscando en El colombiano: huelga de profesores\n",
            "❌ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/huelga+de+profesores\n",
            "\n",
            "🔍 Buscando en El colombiano: protesta docente 2023\n",
            "❌ Error en El colombiano: 500 Server Error: Internal Server Error for url: https://www.elcolombiano.com/busquedas/-/search/protesta+docente+2023\n",
            "\n",
            "🔍 Buscando en Caracol: paro docentes\n",
            "📰 Encontrados 0 artículos en Caracol\n",
            "\n",
            "🔍 Buscando en Caracol: paro maestros\n",
            "📰 Encontrados 0 artículos en Caracol\n",
            "\n",
            "🔍 Buscando en Caracol: suspensión de clases 2023\n",
            "📰 Encontrados 0 artículos en Caracol\n",
            "\n",
            "🔍 Buscando en Caracol: cese de actividades escolares 2023\n",
            "📰 Encontrados 0 artículos en Caracol\n",
            "\n",
            "🔍 Buscando en Caracol: FECODE 2023\n",
            "📰 Encontrados 0 artículos en Caracol\n",
            "\n",
            "🔍 Buscando en Caracol: huelga de profesores\n",
            "📰 Encontrados 0 artículos en Caracol\n",
            "\n",
            "🔍 Buscando en Caracol: protesta docente 2023\n",
            "📰 Encontrados 0 artículos en Caracol\n",
            "\n",
            "🔍 Buscando en Valora Analitik: paro docentes\n",
            "❌ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "🔍 Buscando en Valora Analitik: paro maestros\n",
            "❌ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "🔍 Buscando en Valora Analitik: suspensión de clases 2023\n",
            "❌ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "🔍 Buscando en Valora Analitik: cese de actividades escolares 2023\n",
            "❌ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "🔍 Buscando en Valora Analitik: FECODE 2023\n",
            "❌ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "🔍 Buscando en Valora Analitik: huelga de profesores\n",
            "❌ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "🔍 Buscando en Valora Analitik: protesta docente 2023\n",
            "❌ Error en Valora Analitik: HTTPSConnectionPool(host='www.valoraanalitik.com', port=443): Read timed out. (read timeout=10)\n",
            "\n",
            "🔍 Buscando en Portafolio: paro docentes\n",
            "📰 Encontrados 15 artículos en Portafolio\n",
            "\n",
            "🔍 Buscando en Portafolio: paro maestros\n",
            "📰 Encontrados 15 artículos en Portafolio\n",
            "\n",
            "🔍 Buscando en Portafolio: suspensión de clases 2023\n",
            "📰 Encontrados 15 artículos en Portafolio\n",
            "\n",
            "🔍 Buscando en Portafolio: cese de actividades escolares 2023\n",
            "📰 Encontrados 15 artículos en Portafolio\n",
            "\n",
            "🔍 Buscando en Portafolio: FECODE 2023\n",
            "📰 Encontrados 15 artículos en Portafolio\n",
            "\n",
            "🔍 Buscando en Portafolio: huelga de profesores\n",
            "📰 Encontrados 15 artículos en Portafolio\n",
            "\n",
            "🔍 Buscando en Portafolio: protesta docente 2023\n",
            "📰 Encontrados 15 artículos en Portafolio\n",
            "✅ GoogleNews: 550 resultados\n",
            "\n",
            "🔍 Buscando con SerpAPI...\n",
            "✅ SerpAPI: 40 resultados\n",
            "\n",
            "✅ Total de noticias recopiladas: 601\n",
            "\n",
            " FASE 2: Analizando con IA\n",
            "\n",
            "[1/601]   🤖 Analizando: Circulares 2023...\n",
            "\n",
            "[2/601]   🤖 Analizando: Documentos 2025...\n",
            "\n",
            "[3/601]   🤖 Analizando: Circulares 2025...\n",
            "\n",
            "[4/601]   🤖 Analizando: Inicio...\n",
            "\n",
            "[5/601]   🤖 Analizando: Circulares 2023...\n",
            "\n",
            "[6/601]   🤖 Analizando: Documentos 2025...\n",
            "\n",
            "[7/601]   🤖 Analizando: Elecciones Fecode 2023...\n",
            "\n",
            "[8/601]   🤖 Analizando: Acuerdo FECODE – MEN 2023...\n",
            "\n",
            "[9/601]   🤖 Analizando: Circulares 2023...\n",
            "\n",
            "[10/601]   🤖 Analizando: Inicio...\n",
            "\n",
            "[11/601]   🤖 Analizando: Escuela Sindical Documentos...\n",
            "\n",
            "[12/601]   🤖 Analizando: Atención: Este será el nuevo paro nacional que vivirá Colomb...\n",
            "\n",
            "[13/601]   🤖 Analizando: Fecode anunció paro nacional de maestros: habrá concentracio...\n",
            "\n",
            "[14/601]   🤖 Analizando: El secretario de Educación afirmó que el salario docente “ha...\n",
            "\n",
            "[15/601]   🤖 Analizando: El Eje Cafetero se levanta: maestros anuncian marchas y bloq...\n",
            "\n",
            "[16/601]   🤖 Analizando: Paro de docentes de Eje Cafetero durará 72 horas: marchas en...\n",
            "\n",
            "[17/601]   🤖 Analizando: Maestros de nuevo se van a paro, impactará en tres regiones,...\n",
            "\n",
            "[18/601]   🤖 Analizando: Paro docente y no docente. Universitarios necesitan un 46% d...\n",
            "\n",
            "[19/601]   🤖 Analizando: Paro docente universitario: \"Nosotros hemos perdido un 44% d...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2242959668.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0;31m# Llama a la función de análisis IA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         analisis = analizar_con_ia(\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0mnoticia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'titulo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0mnoticia\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'descripcion'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2242959668.py\u001b[0m in \u001b[0;36manalizar_con_ia\u001b[0;34m(titulo, descripcion, url)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# ============================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m         response = client.chat.completions.create(\n\u001b[0m\u001b[1;32m    262\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    983\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mauth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_request_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         response = self._send_handling_auth(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                 response = self._send_handling_redirects(\n\u001b[0m\u001b[1;32m    943\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m                     \u001b[0mfollow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_redirects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m                 \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_single_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_hooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"response\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m_send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSyncByteStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    248\u001b[0m         )\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_close_connections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Return the response. Note that in this case we still have to manage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m                     \u001b[0;31m# Send the request on the assigned connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m                     response = connection.handle_request(\n\u001b[0m\u001b[1;32m    237\u001b[0m                         \u001b[0mpool_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNetworkStream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"response_closed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_response_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Sending the request...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36mhandle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    104\u001b[0m                     \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtrailing_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 ) = self._receive_response_headers(**kwargs)\n\u001b[0m\u001b[1;32m    107\u001b[0m                 trace.return_value = (\n\u001b[1;32m    108\u001b[0m                     \u001b[0mhttp_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import re\n",
        "from dateutil import parser\n",
        "from tabulate import tabulate\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote_plus\n",
        "import time\n",
        "import random\n",
        "from datetime import datetime\n",
        "from GoogleNews import GoogleNews\n",
        "from serpapi import GoogleSearch\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "import json\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# ================================================================\n",
        "# CONFIGURACIÓN\n",
        "# ================================================================\n",
        "HEADERS = {'User-Agent': 'Mozilla/5.0'}\n",
        "TIMEOUT = 10\n",
        "MAX_RESULTS = 300  # 🔼 aumenta el número de resultados\n",
        "YEAR = \"2023\"\n",
        "\n",
        "def link_valido(url):\n",
        "    try:\n",
        "        r = requests.head(url, timeout=5, allow_redirects=True)\n",
        "        return r.status_code == 200\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "#  SCRAPING DE FUENTES ESPECÍFICAS\n",
        "# ================================================================\n",
        "def buscar_noticias_generales(nombre_fuente, url_base, termino_busqueda, max_resultados=150):\n",
        "    \"\"\"Scrapea noticias desde sitios como El Tiempo, ADE o FECODE.\"\"\"\n",
        "    print(f\"\\n🔍 Buscando en {nombre_fuente}: {termino_busqueda}\")\n",
        "    datos = []\n",
        "    termino_codificado = quote_plus(termino_busqueda)\n",
        "    url_busqueda = f\"{url_base}{termino_codificado}\"\n",
        "\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url_busqueda, headers=headers, timeout=20)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        articulos = soup.find_all('article', limit=max_resultados)\n",
        "        print(f\"📰 Encontrados {len(articulos)} artículos en {nombre_fuente}\")\n",
        "\n",
        "        for art in articulos:\n",
        "            titulo = (art.find('h2') or art.find('h3'))\n",
        "            enlace = art.find('a', href=True)\n",
        "\n",
        "            if not titulo or not enlace:\n",
        "                continue\n",
        "\n",
        "            link = enlace['href']\n",
        "            if not link.startswith('http'):\n",
        "                link = f\"{url_base.rstrip('/')}/{link.lstrip('/')}\"\n",
        "\n",
        "            if not link_valido(link):\n",
        "                continue\n",
        "\n",
        "            descripcion = art.find('p').get_text(strip=True) if art.find('p') else ''\n",
        "            fecha_elem = art.find('time')\n",
        "            fecha = fecha_elem.get_text(strip=True) if fecha_elem else 'No especificada'\n",
        "\n",
        "            datos.append({\n",
        "                'fuente': nombre_fuente,\n",
        "                'titulo': titulo.get_text(strip=True),\n",
        "                'descripcion': descripcion,\n",
        "                'fecha_publicacion': fecha,\n",
        "                'url': link,\n",
        "                'periodo_busqueda': termino_busqueda,\n",
        "                'fecha_extraccion': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error en {nombre_fuente}: {e}\")\n",
        "\n",
        "    time.sleep(random.uniform(1.5, 3.5))\n",
        "    return datos\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "#  GOOGLE NEWS\n",
        "# ================================================================\n",
        "def buscar_con_googlenews():\n",
        "    googlenews = GoogleNews(lang='es', encode='utf-8')\n",
        "    googlenews.set_time_range('12/01/2022', '02/01/2024')\n",
        "    resultados = []\n",
        "\n",
        "    queries = [\n",
        "        'paro docente Colombia 2023', 'paro maestros Bogotá 2023', 'FECODE paro 2023',\n",
        "        'huelga de profesores Colombia 2023', 'protestas docentes educación 2023',\n",
        "        'ADE Bogotá paro 2023', 'magisterio colombiano paro 2023',\n",
        "        'ministerio educación paro maestros 2023', 'paro educativo nacional Colombia 2023',\n",
        "        'suspensión de clases por paro docente 2023'\n",
        "    ]\n",
        "\n",
        "    for q in queries:\n",
        "        googlenews.search(q)\n",
        "        time.sleep(random.uniform(2, 4))\n",
        "        res = googlenews.result()\n",
        "        for r in res:\n",
        "            resultados.append({\n",
        "                'fuente': r.get('media', 'GoogleNews'),\n",
        "                'titulo': r.get('title'),\n",
        "                'descripcion': r.get('desc', ''),\n",
        "                'url': r.get('link', ''),\n",
        "                'fecha_publicacion': r.get('date', ''),\n",
        "                'periodo_busqueda': q,\n",
        "                'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            })\n",
        "    print(f\"✅ GoogleNews: {len(resultados)} resultados\")\n",
        "    return resultados\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "#  SERPAPI\n",
        "# ================================================================\n",
        "def buscar_con_serpapi(api_key):\n",
        "    print(\"\\n🔍 Buscando con SerpAPI...\")\n",
        "    resultados = []\n",
        "    queries = [\n",
        "        '(paro docente OR paro maestros OR huelga profesores OR FECODE OR ADE) Colombia 2023',\n",
        "        '(paro educativo OR suspensión clases) Bogotá 2023',\n",
        "        '(FECODE protesta OR paro) Colombia 2023',\n",
        "        '(magisterio colombiano OR sindicato maestros) paro 2023',\n",
        "    ]\n",
        "\n",
        "    for query in queries:\n",
        "        params = {\n",
        "            \"engine\": \"google\",\n",
        "            \"q\": f\"{query} after:2022-12-01 before:2024-02-01\",\n",
        "            \"api_key\": api_key,\n",
        "            \"num\": 190\n",
        "        }\n",
        "        try:\n",
        "            search = GoogleSearch(params)\n",
        "            results = search.get_dict()\n",
        "            items = results.get(\"organic_results\", [])\n",
        "            for item in items:\n",
        "                resultados.append({\n",
        "                    'fuente': 'Google (SerpAPI)',\n",
        "                    'titulo': item.get('title'),\n",
        "                    'descripcion': item.get('snippet', ''),\n",
        "                    'url': item.get('link'),\n",
        "                    'fecha_publicacion': '',\n",
        "                    'periodo_busqueda': query,\n",
        "                    'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error en SerpAPI: {e}\")\n",
        "            time.sleep(random.uniform(1, 2))\n",
        "    print(f\"✅ SerpAPI: {len(resultados)} resultados\")\n",
        "    return resultados\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "# ANÁLISIS CON IA\n",
        "# ================================================================\n",
        "\n",
        "def obtener_texto_completo(url):\n",
        "\n",
        "    try:\n",
        "        r = requests.get(url, timeout=15)\n",
        "        r.raise_for_status()\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "\n",
        "        # Elimina elementos que no son contenido principal\n",
        "        for s in soup([\"script\", \"style\", \"noscript\", \"header\", \"footer\", \"aside\", \"form\"]):\n",
        "            s.extract()\n",
        "\n",
        "        texto = \" \".join(soup.stripped_strings)\n",
        "        return texto[:8000]  # Máximo 8000 caracteres\n",
        "    except Exception as e:\n",
        "        return f\"Error al obtener contenido: {e}\"\n",
        "\n",
        "\n",
        "def analizar_con_ia(titulo, descripcion, url):\n",
        "    \"\"\"\n",
        "    🤖 EXPLICACIÓN (LA MÁS IMPORTANTE):\n",
        "    Esta función envía la noticia a GPT-4 para que la analice siguiendo criterios estrictos.\n",
        "\n",
        "    PROCESO:\n",
        "    1. Intenta descargar el contenido completo de la URL\n",
        "    2. Si falla, usa solo título + descripción, indicame si pudiste o no acceder al URL\n",
        "    3. Construye un prompt detallado con instrucciones para la IA\n",
        "    4. Envía el prompt a OpenAI (modelo gpt-4o-mini)\n",
        "    5. Recibe respuesta en formato JSON\n",
        "    6. Parsea el JSON y devuelve un diccionario con las características\n",
        "\n",
        "    CARACTERÍSTICAS QUE ANALIZA:\n",
        "    - es_paro_docente: ¿Hubo suspensión de clases?\n",
        "    - organizaciones_sindicales: ¿Qué sindicatos u organizaciones políticas participaron?\n",
        "    - duracion_dias: ¿Cuántos días duró?\n",
        "    - ubicacion_bogota: ¿Ocurrió en Bogotá?\n",
        "    - ubicacion_Colombia: ¿Abarcó todo el territorio Nacional=\n",
        "    - costo_mencionado: ¿Se habla de costos económicos?\n",
        "    - fecha_paro: ¿cuál es la fecha exacta del paro (día, mes, año)?\n",
        "    \"\"\"\n",
        "    print(f\"  🤖 Analizando: {titulo[:60]}...\")\n",
        "\n",
        "    contenido_completo = obtener_texto_completo(url) if url else \"\"\n",
        "\n",
        "    if \"Error\" in contenido_completo or not contenido_completo:\n",
        "        texto_analizar = f\"Título: {titulo}\\nDescripción: {descripcion}\"\n",
        "    else:\n",
        "        texto_analizar = contenido_completo\n",
        "\n",
        "    # ============================================\n",
        "    #  PROMPT IA\n",
        "    # ============================================\n",
        "    prompt = f\"\"\"\n",
        "Analiza la siguiente noticia en español sobre educación, sindicatos o protestas de docentes.\n",
        "\n",
        "CRITERIOS ESTRICTOS:\n",
        "- Un **paro docente verdadero** solo existe si hubo suspensión de clases programadas.\n",
        "- Si fue marcha, manifestación o concentración SIN suspensión de clases, NO es paro.\n",
        "- Debes explicar tu razonamiento.\n",
        "\n",
        "Devuelve un JSON con estas claves:\n",
        "\n",
        "- \"es_paro_docente\": true/false → true solo si hubo suspensión de clases\n",
        "- \"justificacion_paro\": texto breve (2-4 líneas) explicando por qué es o no un paro\n",
        "- \"organizaciones_sindicales\": lista de sindicatos mencionados u organizaciones políticas o partidos políticos (ej: [\"FECODE\", \"ADE\"]), o []\n",
        "- \"hay_suspension_clases\": true/false → si se suspendieron clases\n",
        "- \"duracion_dias\": número de días estimados, o null\n",
        "- \"razones_paro\": resumen de las demandas principales\n",
        "- \"ubicacion_bogota\": true/false → si ocurre en Bogotá/Cundinamarca\n",
        "- \"ubicacion_Colombia\": true/false → si el paro abarca el territorio Nacional\n",
        "- \"costo_mencionado\": monto económico si se menciona, o null\n",
        "- \"resumen\": breve resumen (máx. 3 líneas)\n",
        "- \"fecha_paro\": ¿cuál es la fecha exacta del paro (día, mes, año)?\n",
        "- \"tipo_movilizacion\": ¿cuál es el tipo de movilización, paro docente con las caracteristicas que ya vimos, paro de otro gremio, demostración, plantón, toma, marcha pacífica, etc?\n",
        "- \"ubicacion\": además del país y ciudad, podemos identificar localidades? barrios? calles? edificios? colegios específicos o barrios?\n",
        "Devuelve SOLO el JSON válido, sin texto extra.\n",
        "- \"fuente_oficial\": ¿es una fuente oficial de algún sindicato o es media, si es media cual, si es sindicato, cual?\n",
        "\n",
        "Texto a analizar:\n",
        "{texto_analizar}\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        # ============================================\n",
        "        #  API DE OPENAI\n",
        "        # ============================================\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0.1,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "\n",
        "        # Extrae el texto de la respuesta\n",
        "        respuesta_texto = response.choices[0].message.content.strip()\n",
        "\n",
        "        # ============================================\n",
        "        # PARSEO DEL JSON\n",
        "        # ============================================\n",
        "        # La IA devuelve un JSON como string, lo convertimos a diccionario\n",
        "        try:\n",
        "            # Intenta parsear directamente\n",
        "            analisis = json.loads(respuesta_texto)\n",
        "        except json.JSONDecodeError:\n",
        "            # Si falla, busca el JSON dentro de bloques de código ```json```\n",
        "            if \"```json\" in respuesta_texto:\n",
        "                inicio = respuesta_texto.find(\"```json\") + 7\n",
        "                fin = respuesta_texto.find(\"```\", inicio)\n",
        "                json_str = respuesta_texto[inicio:fin].strip()\n",
        "                analisis = json.loads(json_str)\n",
        "            else:\n",
        "                # Si todo falla, devuelve valores por defecto\n",
        "                print(\"    ⚠️ No se pudo parsear el JSON\")\n",
        "                analisis = {\n",
        "                    'es_paro_docente': False,\n",
        "                    'justificacion_paro': 'Error al analizar',\n",
        "                    'organizaciones_sindicales': [],\n",
        "                    'hay_suspension_clases': False,\n",
        "                    'duracion_dias': None,\n",
        "                    'razones_paro': '',\n",
        "                    'ubicacion_bogota': False,\n",
        "                    'ubicacion_Colombia': False,\n",
        "                    'costo_mencionado': None,\n",
        "                    'resumen': '',\n",
        "                    'fecha_paro': None,\n",
        "                    'tipo_movilizacion': '',\n",
        "                    'ubicacion': '',\n",
        "                    'fuente_oficial': ''\n",
        "                }\n",
        "\n",
        "        return analisis\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"    ❌ Error en análisis IA: {e}\")\n",
        "        if \"insufficient_quota\" in str(e):\n",
        "            print(\"    Please check your OpenAI API plan and billing details.\")\n",
        "        return {\n",
        "            'es_paro_docente': False,\n",
        "            'justificacion_paro': f'Error: {str(e)}',\n",
        "            'organizaciones_sindicales': [],\n",
        "            'hay_suspension_clases': False,\n",
        "            'duracion_dias': None,\n",
        "            'razones_paro': '',\n",
        "            'ubicacion_bogota': False,\n",
        "            'ubicacion_Colombia': False,\n",
        "            'costo_mencionado': None,\n",
        "            'resumen': '',\n",
        "            'fecha_paro': None,\n",
        "            'tipo_movilizacion': '',\n",
        "            'ubicacion': '',\n",
        "            'fuente_oficial': ''\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "# ================================================================\n",
        "#  EJECUCIÓN PRINCIPAL\n",
        "# ================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\"*60)\n",
        "    print(\" INICIANDO SCRAPER + ANÁLISIS IA\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    resultados_totales = []\n",
        "\n",
        "    # 1) Fuentes oficiales primero (mayor recall de 2023)\n",
        "    print(\"\\n FASE 1: Recopilando noticias...\")\n",
        "\n",
        "    fuentes = {\n",
        "        \"El Tiempo\": \"https://www.eltiempo.com/buscar/\",\n",
        "        \"El Espectador\": \"https://www.elespectador.com/buscador/\",\n",
        "        \"FECODE\": \"https://fecode.edu.co/?s=\",\n",
        "        \"ADE Bogotá\": \"https://adebogota.org/index.php/buscar?q=\",\n",
        "        \"SED\": \"https://www.educacionbogota.edu.co/noticias?field_noticia_descripcion_value=\",\n",
        "        \"Bogota.gov\": \"https://bogota.gov.co/tag/ingreso-minimo-garantizado?search_api_fulltext=\",\n",
        "        \"Caracol\" : \"https://www.noticiascaracol.com/busqueda?q=\",\n",
        "        \"Valora Analitik\" : \"https://www.valoraanalitik.com/?s=\",\n",
        "        \"Portafolio\": \"https://www.portafolio.co/buscar?q=\",\n",
        "    }\n",
        "    terminos = [\n",
        "        \"paro docentes\", \"paro maestros\", \"suspensión de clases 2023\",\n",
        "        \"cese de actividades escolares 2023\", \"FECODE 2023\", \"huelga de profesores\",\n",
        "        \"protesta docente 2023\"\n",
        "    ]\n",
        "    for fuente, url_base in fuentes.items():\n",
        "        for termino in terminos:\n",
        "            resultados_totales.extend(\n",
        "                buscar_noticias_generales(fuente, url_base, termino)\n",
        "            )\n",
        "            time.sleep(random.uniform(2, 4))\n",
        "\n",
        "   # 2) GoogleNews y SerpAPI\n",
        "    resultados_totales.extend(buscar_con_googlenews())\n",
        "    resultados_totales.extend(buscar_con_serpapi(SerpAPI_tkn1))\n",
        "\n",
        "    df = pd.DataFrame(resultados_totales).drop_duplicates(subset=\"url\")\n",
        "    df.to_csv(\"noticias_paros_docentes_2023_SUPER.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "    print(f\"\\n✅ Total de noticias recopiladas: {len(resultados_totales)}\")\n",
        "\n",
        "    # ============================================\n",
        "    # ANÁLISIS CON IA\n",
        "    # ============================================\n",
        "    print(\"\\n FASE 2: Analizando con IA\")\n",
        "\n",
        "    for i, noticia in enumerate(resultados_totales, 1):\n",
        "        print(f\"\\n[{i}/{len(resultados_totales)}]\", end=\" \")\n",
        "\n",
        "        # Llama a la función de análisis IA\n",
        "        analisis = analizar_con_ia(\n",
        "            noticia['titulo'],\n",
        "            noticia.get('descripcion', ''),\n",
        "            noticia.get('url', '')\n",
        "        )\n",
        "\n",
        "        # Agrega los resultados del análisis al diccionario de la noticia\n",
        "        noticia.update(analisis)\n",
        "\n",
        "        # Espera 2 seconds between calls (to avoid saturating the OpenAI API)\n",
        "        time.sleep(2)\n",
        "\n",
        "    # ============================================\n",
        "    # FASE 3: GUARDAR RESULTADOS EN CSV\n",
        "    # ============================================\n",
        "    print(\"\\n FASE 3: Guardando resultados...\")\n",
        "\n",
        "    df = pd.DataFrame(resultados_totales)\n",
        "    if not df.empty:\n",
        "       df = df.drop_duplicates(subset='url', keep='first')\n",
        "    columnas_importantes = [\n",
        "        'titulo', 'fuente', 'fecha_publicacion', 'url',\n",
        "        'es_paro_docente', 'hay_suspension_clases', 'ubicacion_bogota',\n",
        "        'ubicacion_Colombia', 'duracion_dias', 'organizaciones_sindicales',\n",
        "        'razones_paro', 'costo_mencionado', 'justificacion_paro', 'resumen',\n",
        "        'fecha_paro', 'tipo_movilizacion', 'ubicacion',\n",
        "        'descripcion', 'periodo_busqueda', 'fecha_extraccion', 'fuente_oficial'\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Solo incluye columnas que existan en el DataFrame\n",
        "    columnas_finales = [col for col in columnas_importantes if col in df.columns]\n",
        "    df = df[columnas_finales]\n",
        "\n",
        "    # Guarda en CSV\n",
        "    nombre_archivo = \"noticias_paros_docentes_2023_ANALIZADO.csv\"\n",
        "    df.to_csv(nombre_archivo, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "    print(f\"✅ Archivo guardado: {nombre_archivo}\")\n",
        "    print(f\"📊 Total de noticias: {len(df)}\")\n",
        "\n",
        "    # ============================================\n",
        "    # ESTADÍSTICAS FINALES\n",
        "    # ============================================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"📈 ESTADÍSTICAS DEL ANÁLISIS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    paros_verdaderos = df[df['es_paro_docente'] == True]\n",
        "    print(f\"🔴 Paros verdaderos (con suspensión de clases): {len(paros_verdaderos)}\")\n",
        "\n",
        "    en_bogota = df[df['ubicacion_bogota'] == True]\n",
        "    print(f\"📍 Eventos en Bogotá: {len(en_bogota)}\")\n",
        "\n",
        "    con_duracion = df[df['duracion_dias'].notna()]\n",
        "    if len(con_duracion) > 0:\n",
        "        print(f\"⏱️ Duración promedio: {con_duracion['duracion_dias'].mean():.1f} días\")\n",
        "\n",
        "    print(\"\\n🎉 ¡Análisis completado!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}