{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip  install pandas\n",
        "!pip  install numpy\n",
        "!pip  install datetime\n",
        "!pip  install regex\n",
        "!pip  install openai\n",
        "!pip  install bs4\n",
        "!pip  install requests\n",
        "!pip  install json\n",
        "!pip  install numpy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMF9PrGneH1b",
        "outputId": "2a1b5566-0e10-46b3-a5b6-63966e528449",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.12/dist-packages (5.5)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.12/dist-packages (from datetime) (8.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from datetime) (2025.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.12/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from bs4) (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (4.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ==============================\n",
        "# 1. Cargar archivo CSV\n",
        "# ==============================\n",
        "df = pd.read_csv(\"bq-results-20251023-000630-1761178021663.csv\", encoding=\"utf-8-sig\")\n",
        "\n",
        "# Limpieza de encabezados para evitar errores por espacios o caracteres invisibles\n",
        "df.columns = (\n",
        "    df.columns.str.encode('utf-8').str.decode('utf-8', 'ignore')\n",
        "    .str.replace(\"√Ø¬ª¬ø\", \"\", regex=False)\n",
        "    .str.strip()\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 2. Limpieza y formato de fecha\n",
        "# ==============================\n",
        "# Verificar si la columna SQLDATE existe\n",
        "col_fecha = [c for c in df.columns if \"SQLDATE\" in c.upper()]\n",
        "if not col_fecha:\n",
        "    raise ValueError(\"No se encontr√≥ la columna SQLDATE en el archivo CSV.\")\n",
        "col_fecha = col_fecha[0]\n",
        "\n",
        "# Convertir fechas con detecci√≥n autom√°tica\n",
        "df[col_fecha] = pd.to_datetime(df[col_fecha].astype(str), errors='coerce')\n",
        "\n",
        "# ==============================\n",
        "# 3. Filtro por a√±o 2023\n",
        "# ==============================\n",
        "df_2023 = df[df[col_fecha].dt.year == 2023].copy()\n",
        "\n",
        "# ==============================\n",
        "# 4. Filtro por pa√≠s Colombia\n",
        "# ==============================\n",
        "col_pais = [c for c in df.columns if \"COUNTRYCODE\" in c.upper()]\n",
        "if not col_pais:\n",
        "    raise ValueError(\"No se encontr√≥ la columna ActionGeo_CountryCode en el archivo CSV.\")\n",
        "col_pais = col_pais[0]\n",
        "\n",
        "df_colombia = df_2023[df_2023[col_pais].astype(str).str.upper() == \"CO\"].copy()\n",
        "\n",
        "# ==============================\n",
        "# 5. Filtro por contenido del SOURCEURL\n",
        "# ==============================\n",
        "col_url = [c for c in df.columns if \"SOURCEURL\" in c.upper()]\n",
        "if not col_url:\n",
        "    raise ValueError(\"No se encontr√≥ la columna SOURCEURL en el archivo CSV.\")\n",
        "col_url = col_url[0]\n",
        "\n",
        "df_colombia[col_url] = df_colombia[col_url].astype(str).str.lower()\n",
        "\n",
        "palabras_clave = ['paro-docente', 'fecode', 'maestros', 'protesta-docente', 'paro-maestros']\n",
        "\n",
        "filtro_tema = df_colombia[col_url].apply(\n",
        "    lambda x: any(palabra in x for palabra in palabras_clave)\n",
        ")\n",
        "\n",
        "df_filtrado = df_colombia.loc[filtro_tema, [col_fecha, 'ActionGeo_FullName', col_url]].copy()\n",
        "\n",
        "# ==============================\n",
        "# 6. Eliminar duplicados\n",
        "# ==============================\n",
        "df_filtrado = df_filtrado.drop_duplicates(subset=[col_url], keep='first')\n",
        "\n",
        "# ==============================\n",
        "# 7. Guardar resultado final\n",
        "# ==============================\n",
        "print(\"Noticias filtradas:\", len(df_filtrado))\n",
        "print(df_filtrado.head())\n",
        "\n",
        "df_filtrado.to_csv(\"BQ_Noticias_Paro_Docente_2023.csv\", index=False, encoding=\"utf-8-sig\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hUuh6OW9cwQ",
        "outputId": "6707cdf3-db02-400d-cc55-66d3e0d213a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noticias filtradas: 6\n",
            "         SQLDATE              ActionGeo_FullName  \\\n",
            "2160  2023-03-11                        Colombia   \n",
            "3283  2023-08-30                        Colombia   \n",
            "3287  2023-08-30      Cartagena, Bol√≠r, Colombia   \n",
            "10036 2023-08-24                        Colombia   \n",
            "14469 2023-02-08  Bogota, Cundinamarca, Colombia   \n",
            "\n",
            "                                               SOURCEURL  \n",
            "2160   https://eldeber.com.bo/pais/maestros-protestan...  \n",
            "3283      https://diariodelhuila.com/ahora-los-maestros/  \n",
            "3287   https://elpais.com/america-colombia/2023-08-30...  \n",
            "10036  https://www.larepublica.co/economia/fecode-con...  \n",
            "14469  https://pulsoslp.com.mx/mundo/maestros-de-colo...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === 1. Cargar el archivo ===\n",
        "df = pd.read_csv(\"Base-SGI-suspensi√≥n-clases-2012-2025-03_08_2025_VALIDACION-SED.csv\")\n",
        "\n",
        "# Normalizar nombres de columnas (elimina espacios, may√∫sculas y tildes)\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\"√°\", \"a\").str.replace(\"√©\", \"e\").str.replace(\"√≠\", \"i\").str.replace(\"√≥\", \"o\").str.replace(\"√∫\", \"u\")\n",
        "\n",
        "# === 2. Unificar formato de fechas ===\n",
        "for col in df.columns:\n",
        "    if \"fecha\" in col:\n",
        "        df[col] = pd.to_datetime(df[col], errors=\"coerce\", dayfirst=True)\n",
        "\n",
        "# === 3. Filtrar por a√±o 2023 ===\n",
        "df_2023 = df[\n",
        "    (df[\"fecha inicio\"].dt.year == 2023) |\n",
        "    (df[\"fecha fin\"].dt.year == 2023)\n",
        "]\n",
        "\n",
        "# === 5. Identificar las columnas disponibles ===\n",
        "print(\"üßæ Columnas disponibles:\", list(df_2023.columns))\n",
        "\n",
        "# Seleccionar las m√°s relevantes si existen\n",
        "cols_posibles = [\n",
        "    \"fecha inicio\", \"fecha fin\", \"convocante\", \"hecho\",\n",
        "    \"ubicacion\", \"medio de verificacion\",\"medio de verificacion 2\", \"tipo de protesta\", \"alcance\"\n",
        "]\n",
        "cols_finales = [c for c in cols_posibles if c in df_2023.columns]\n",
        "\n",
        "# === 6. Subconjunto limpio ===\n",
        "df_resultado = df_2023[cols_finales].reset_index(drop=True)\n",
        "\n",
        "# === 8. (Opcional) Guardar en CSV ===\n",
        "df_resultado.to_csv(\"SED_Paros_Docentes_Colombia_2023.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nyPkGByi3Cot",
        "outputId": "ed0a3d2d-2162-4bec-cdcf-cea1bbaf7b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßæ Columnas disponibles: ['convocante', 'fecha inicio', 'fecha fin', 'hecho', 'evento', 'tipo de protesta', 'alcance', 'tiempo', 'suspension clases', 'dias suspension clases', 'aforo', 'ubicacion', 'medio de verificacion', 'medio de verificacion 2', 'medio de verificacion 3', 'medio de verificacion organizacion sindical', 'medio de verificacion organizacion sindical.1', 'observaciones', 'unnamed: 18', 'unnamed: 19', 'unnamed: 20', 'unnamed: 21', 'unnamed: 22', 'unnamed: 23', 'unnamed: 24', 'unnamed: 25']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === 1. Cargar archivo ===\n",
        "df = pd.read_csv(\"web_noticias_paros_docentes_2023.csv\")\n",
        "\n",
        "# === 2. Estandarizar nombres de columnas ===\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\"√°\", \"a\").str.replace(\"√©\", \"e\").str.replace(\"√≠\", \"i\").str.replace(\"√≥\", \"o\").str.replace(\"√∫\", \"u\")\n",
        "\n",
        "# === 3. Convertir la columna de fecha_paro a formato fecha ===\n",
        "df[\"fecha_paro\"] = pd.to_datetime(df[\"fecha_paro\"], errors=\"coerce\", dayfirst=True)\n",
        "\n",
        "# === 4. Filtrar los paros del a√±o 2023 ===\n",
        "df_2023 = df[df[\"fecha_paro\"].dt.year == 2023]\n",
        "\n",
        "# === 5. Seleccionar columnas relevantes ===\n",
        "cols_finales = [\n",
        "    \"titulo\",\n",
        "    \"fuente\",\n",
        "    \"url\",\n",
        "    \"fecha_paro\",\n",
        "    \"duracion_dias\",\n",
        "    \"organizaciones_sindicales\",\n",
        "    \"razones_paro\",\n",
        "    \"resumen\",\n",
        "    \"ubicacion\",\n",
        "    \"tipo_movilizacion\"\n",
        "]\n",
        "\n",
        "df_reducido = df_2023[cols_finales].reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "# === 7. (Opcional) Exportar a CSV ===\n",
        "df_reducido.to_csv(\"WEB_Paros_Docentes_2023_Reducido.csv\" , index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "esBBD_eEIHiB",
        "outputId": "804a6e32-6120-48e7-dc7c-a03ee7a9bb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2078167426.py:10: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
            "  df[\"fecha_paro\"] = pd.to_datetime(df[\"fecha_paro\"], errors=\"coerce\", dayfirst=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install os\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install requests\n",
        "!pip install json\n",
        "!pip install bs4\n",
        "!pip install datetime\n",
        "!pip install time\n",
        "!pip install urllib.parse\n",
        "!pip install difflib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QMDMrbFMdYVI",
        "outputId": "5a7a8706-65cb-47bf-facc-8c9a70f40f77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from bs4) (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (4.15.0)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting zope.interface (from datetime)\n",
            "  Downloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from datetime) (2025.2)\n",
            "Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m264.7/264.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-5.5 zope.interface-8.0.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement urllib.parse (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for urllib.parse\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement difflib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for difflib\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re\n",
        "import pandas as pd, numpy as np, requests, json, time\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from openai import OpenAI\n",
        "from urllib.parse import urlparse, parse_qsl, urlencode, urlunparse\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# Inicializa el cliente\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "RGUYefg2c2WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "FILE_WEB = \"WEB_Paros_Docentes_2023_Reducido.csv\"\n",
        "FILE_SED = \"SED_Paros_Docentes_Colombia_2023.csv\"\n",
        "FILE_BQ  = \"BQ_Noticias_Paro_Docente_2023.csv\"\n",
        "\n",
        "# -------------------- UTILIDADES --------------------\n",
        "def norm_cols(df):\n",
        "    df.columns = (df.columns.str.strip().str.lower()\n",
        "                  .str.replace(\"√°\",\"a\").str.replace(\"√©\",\"e\")\n",
        "                  .str.replace(\"√≠\",\"i\").str.replace(\"√≥\",\"o\").str.replace(\"√∫\",\"u\"))\n",
        "    return df\n",
        "\n",
        "def safe_dt(x, dayfirst=False):\n",
        "    return pd.to_datetime(x, errors=\"coerce\", dayfirst=dayfirst)\n",
        "\n",
        "def get_col(df, keys):\n",
        "    for k in keys:\n",
        "        hits = [c for c in df.columns if k in c]\n",
        "        if hits: return hits[0]\n",
        "    return None\n",
        "\n",
        "def ensure_cols(df, cols, fill=np.nan):\n",
        "    for c in cols:\n",
        "        if c not in df.columns:\n",
        "            df[c] = fill\n",
        "    return df\n",
        "\n",
        "# -------------------- CARGA --------------------\n",
        "web = norm_cols(pd.read_csv(FILE_WEB))\n",
        "sed = norm_cols(pd.read_csv(FILE_SED))\n",
        "bq  = norm_cols(pd.read_csv(FILE_BQ))\n",
        "\n",
        "for df in [web, sed, bq]:\n",
        "    for c in df.columns:\n",
        "        if \"fecha\" in c:\n",
        "            df[c] = safe_dt(df[c], dayfirst=False)\n",
        "\n",
        "# ================================================================\n",
        "# BASE SED\n",
        "# ================================================================\n",
        "col_fecha = get_col(sed, [\"fecha inicio\",\"fechainicio\",\"fecha\"])\n",
        "col_fin   = get_col(sed, [\"fecha fin\",\"fechafin\",\"fin\"])\n",
        "col_hecho = get_col(sed, [\"hecho\",\"evento\",\"descripcion\"])\n",
        "col_tipo  = get_col(sed, [\"tipo de protesta\",\"tipo\",\"movilizacion\"])\n",
        "col_conv  = get_col(sed, [\"convocante\",\"organizacion\",\"sindicato\"])\n",
        "col_ubic  = get_col(sed, [\"ubicacion\",\"lugar\",\"region\"])\n",
        "col_dias  = get_col(sed, [\"dias suspension\",\"duracion_dias\",\"dias\",\"duracion\"])\n",
        "\n",
        "if not col_dias and col_fecha and col_fin:\n",
        "    sed[\"duracion_dias\"] = (safe_dt(sed[col_fin]) - safe_dt(sed[col_fecha])).dt.days + 1\n",
        "    sed.loc[sed[\"duracion_dias\"] < 1, \"duracion_dias\"] = 1\n",
        "    col_dias = \"duracion_dias\"\n",
        "elif not col_dias:\n",
        "    sed[\"duracion_dias\"] = np.nan\n",
        "    col_dias = \"duracion_dias\"\n",
        "\n",
        "sel = [c for c in [col_fecha,col_hecho,col_tipo,col_conv,col_ubic,col_dias] if c]\n",
        "sed_final = sed[sel].rename(columns={\n",
        "    col_fecha:\"fecha_evento\",\n",
        "    col_hecho:\"razones_paro\",\n",
        "    col_tipo:\"tipo_movilizacion\",\n",
        "    col_conv:\"organizaciones_sindicales\",\n",
        "    col_ubic:\"region\",\n",
        "    col_dias:\"duracion_dias\"\n",
        "}).copy()\n",
        "\n",
        "std = [\"fecha_evento\",\"region\",\"organizaciones_sindicales\",\"tipo_movilizacion\",\n",
        "       \"duracion_dias\",\"razones_paro\",\"resumen\",\"titulo_ref\",\"urls\",\"fuentes_presentes\"]\n",
        "sed_final = ensure_cols(sed_final, std)\n",
        "sed_final[\"resumen\"] = sed_final[\"razones_paro\"]\n",
        "sed_final[\"titulo_ref\"] = sed_final[\"razones_paro\"].astype(str).str[:90]\n",
        "sed_final[\"fuentes_presentes\"] = \"SED\"\n",
        "\n",
        "col_url_sed = get_col(sed, [\"medio de verificacion\",\"url\",\"enlace\"])\n",
        "sed_final[\"urls\"] = sed[col_url_sed] if col_url_sed else np.nan\n",
        "\n",
        "# ================================================================\n",
        "#  BASE WEB\n",
        "# ================================================================\n",
        "web_final = web.rename(columns={\"fecha_paro\":\"fecha_evento\",\"ubicacion\":\"region\"}).copy()\n",
        "web_final = ensure_cols(web_final, std)\n",
        "web_final[\"fuentes_presentes\"] = \"WEB\"\n",
        "if \"url\" in web_final.columns: web_final[\"urls\"] = web_final[\"url\"]\n",
        "if \"titulo\" in web_final.columns: web_final[\"titulo_ref\"] = web_final[\"titulo\"]\n",
        "\n",
        "# ================================================================\n",
        "#  BASE BQ\n",
        "# ================================================================\n",
        "\n",
        "# Normalizar encabezados\n",
        "bq.columns = (\n",
        "    bq.columns.str.encode('utf-8').str.decode('utf-8', 'ignore')\n",
        "    .str.replace(\"√Ø¬ª¬ø\", \"\", regex=False)\n",
        "    .str.strip()\n",
        "    .str.lower()\n",
        ")\n",
        "\n",
        "col_sqldate = [c for c in bq.columns if \"sqldate\" in c]\n",
        "col_url_bq = [c for c in bq.columns if \"sourceurl\" in c or \"url\" in c]\n",
        "col_region_bq = [c for c in bq.columns if \"actiongeo_fullname\" in c or \"region\" in c]\n",
        "\n",
        "if not col_sqldate:\n",
        "    raise ValueError(\"No se encontr√≥ la columna SQLDATE en la base BQ.\")\n",
        "col_sqldate = col_sqldate[0]\n",
        "col_url_bq = col_url_bq[0] if col_url_bq else None\n",
        "col_region_bq = col_region_bq[0] if col_region_bq else None\n",
        "\n",
        "def parse_fecha(f):\n",
        "    if pd.isna(f):\n",
        "        return pd.NaT\n",
        "    f = str(f).strip()\n",
        "    for fmt in (\"%Y%m%d\", \"%d/%m/%Y\", \"%Y-%m-%d\"):\n",
        "        try:\n",
        "            return pd.to_datetime(f, format=fmt)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return pd.to_datetime(f, errors=\"coerce\")\n",
        "\n",
        "bq[\"fecha_evento\"] = bq[col_sqldate].apply(parse_fecha)\n",
        "\n",
        "# Crear DataFrame final con columnas estandarizadas\n",
        "bq_final = pd.DataFrame({\n",
        "    \"fecha_evento\": bq[\"fecha_evento\"],\n",
        "    \"urls\": bq[col_url_bq] if col_url_bq else np.nan,\n",
        "    \"region\": bq[col_region_bq] if col_region_bq else np.nan,\n",
        "    \"organizaciones_sindicales\": bq.get(\"organizaciones_sindicales\", np.nan),\n",
        "    \"tipo_movilizacion\": bq.get(\"tipo_movilizacion\", \"paro docente\"),\n",
        "    \"razones_paro\": bq.get(\"razones_paro\", np.nan),\n",
        "    \"resumen\": bq.get(\"resumen\", np.nan),\n",
        "    \"duracion_dias\": bq.get(\"duracion_dias\", np.nan),\n",
        "    \"titulo_ref\": bq.get(\"titulo\", np.nan)\n",
        "})\n",
        "\n",
        "bq_final = ensure_cols(bq_final, std)\n",
        "bq_final[\"fuentes_presentes\"] = \"BQ\"\n",
        "\n",
        "# ================================================================\n",
        "# ESTANDARIZAR LOCALIZACI√ìN\n",
        "# ================================================================\n",
        "CIUDADES_CO = {\n",
        "    \"bogota\":\"Bogot√°\",\"bogot√°\":\"Bogot√°\",\"medellin\":\"Medell√≠n\",\"medell√≠n\":\"Medell√≠n\",\n",
        "    \"cali\":\"Cali\",\"barranquilla\":\"Barranquilla\",\"cartagena\":\"Cartagena\",\"pereira\":\"Pereira\",\n",
        "    \"armenia\":\"Armenia\",\"manizales\":\"Manizales\",\"bucaramanga\":\"Bucaramanga\",\"cucuta\":\"C√∫cuta\",\n",
        "    \"c√∫cuta\":\"C√∫cuta\",\"ibague\":\"Ibagu√©\",\"ibagu√©\":\"Ibagu√©\",\"villavicencio\":\"Villavicencio\",\n",
        "    \"santa marta\":\"Santa Marta\",\"monteria\":\"Monter√≠a\",\"neiva\":\"Neiva\",\"tunja\":\"Tunja\",\n",
        "    \"yopal\":\"Yopal\",\"pasto\":\"Pasto\",\"popayan\":\"Popay√°n\",\"riohacha\":\"Riohacha\",\"quibdo\":\"Quibd√≥\",\n",
        "    \"leticia\":\"Leticia\",\"mocoa\":\"Mocoa\"\n",
        "}\n",
        "\n",
        "def _clean(s):\n",
        "    if s is None or (isinstance(s,float) and pd.isna(s)): return \"\"\n",
        "    return str(s).strip()\n",
        "\n",
        "def parse_region_to_pais_ciudad(val):\n",
        "    v = _clean(val)\n",
        "    if v == \"\" or v.upper() in {\"S/I\",\"S. I.\",\"NA\",\"N/A\"}:\n",
        "        return (\"Colombia\",\"\")\n",
        "    if \"colombia\" in v.lower():\n",
        "        partes = [p.strip() for p in re.split(r\",\", v) if p.strip()]\n",
        "        if len(partes) >= 2:\n",
        "            return (\"Colombia\", CIUDADES_CO.get(partes[0].lower(), partes[0]))\n",
        "    for k, pretty in CIUDADES_CO.items():\n",
        "        if re.search(rf\"\\b{k}\\b\", v.lower()):\n",
        "            return (\"Colombia\", pretty)\n",
        "    return (\"Colombia\", v[:80])\n",
        "\n",
        "def add_pais_ciudad(df):\n",
        "    p, c = zip(*df[\"region\"].apply(parse_region_to_pais_ciudad))\n",
        "    df[\"pais\"], df[\"ciudad\"] = p, c\n",
        "    return df\n",
        "\n",
        "sed_final = add_pais_ciudad(sed_final)\n",
        "web_final = add_pais_ciudad(web_final)\n",
        "bq_final  = add_pais_ciudad(bq_final)\n",
        "\n",
        "# ================================================================\n",
        "#  UNIR BASES\n",
        "# ================================================================\n",
        "cols_union = [\"fecha_evento\",\"pais\",\"ciudad\",\"organizaciones_sindicales\",\"tipo_movilizacion\",\n",
        "              \"duracion_dias\",\"razones_paro\",\"resumen\",\"titulo_ref\",\"urls\",\"fuentes_presentes\",\"region\"]\n",
        "\n",
        "for df in [sed_final, web_final, bq_final]:\n",
        "    for c in cols_union:\n",
        "        if c not in df.columns: df[c] = np.nan\n",
        "\n",
        "base = pd.concat([sed_final[cols_union], web_final[cols_union], bq_final[cols_union]], ignore_index=True)\n",
        "base = base.sort_values([\"fecha_evento\",\"ciudad\"]).reset_index(drop=True)\n",
        "\n",
        "# ================================================================\n",
        "# UNIFICAR Y LIMPIAR ORGANIZACIONES SINDICALES\n",
        "# ================================================================\n",
        "def estandarizar_orgs(valor):\n",
        "    \"\"\"Limpia, normaliza y unifica nombres de sindicatos.\"\"\"\n",
        "    if pd.isna(valor):\n",
        "        return \"NO ESPEC√çFICA\"\n",
        "\n",
        "    if isinstance(valor, (list, tuple, set)):\n",
        "        texto = \" | \".join(map(str, valor))\n",
        "    else:\n",
        "        texto = str(valor)\n",
        "\n",
        "    texto = re.sub(r\"[\\[\\]'\\\"{}]\", \"\", texto).upper()\n",
        "    partes = re.split(r\"[;|,/\\-]+\", texto)\n",
        "    partes = [p.strip() for p in partes if p.strip()]\n",
        "    if not partes:\n",
        "        return \"NO ESPEC√çFICA\"\n",
        "\n",
        "    equivalencias = {\n",
        "        \"FEDERACION COLOMBIANA DE TRABAJADORES DE LA EDUCACION\": \"FECODE\",\n",
        "        \"FECODE\": \"FECODE\",\n",
        "        \"ADE\": \"ADE\",\n",
        "        \"ADIDA\": \"ADIDA\",\n",
        "        \"CUT\": \"CUT\",\n",
        "        \"CENTRAL UNITARIA DE TRABAJADORES\": \"CUT\",\n",
        "        \"CENTRAL UNITARIA DE TRABAJADORES DE COLOMBIA\": \"CUT\",\n",
        "        \"CONFEDERACION DE TRABAJADORES DE COLOMBIA\": \"CTC\",\n",
        "        \"CTC\": \"CTC\",\n",
        "        \"CGT\": \"CGT\",\n",
        "        \"CONFEDERACION GENERAL DEL TRABAJO\": \"CGT\",\n",
        "        \"SINTRANAL\": \"SINTRANAL\",\n",
        "        \"SINTRANAL EDU\": \"SINTRANAL\",\n",
        "        \"NO ESPECIFICA\": \"NO ESPEC√çFICA\",\n",
        "        \"NO ESPEC√çFICA\": \"NO ESPEC√çFICA\"\n",
        "    }\n",
        "\n",
        "    normalizados = []\n",
        "    for p in partes:\n",
        "        p_clean = re.sub(r\"[^A-Z√Å√â√ç√ì√ö√ú√ë ]\", \"\", p).strip()\n",
        "        for k, v in equivalencias.items():\n",
        "            if k in p_clean:\n",
        "                normalizados.append(v)\n",
        "                break\n",
        "        else:\n",
        "            normalizados.append(p_clean)\n",
        "\n",
        "    limpio = [x for x in sorted(set(normalizados)) if x]\n",
        "    if not limpio:\n",
        "        return \"NO ESPEC√çFICA\"\n",
        "    return \" | \".join(limpio)\n",
        "\n",
        "base[\"organizaciones_sindicales\"] = base[\"organizaciones_sindicales\"].apply(estandarizar_orgs)\n",
        "\n",
        "# ================================================================\n",
        "# ESTAD√çSTICAS DESCRIPTIVAS\n",
        "# ================================================================\n",
        "stats = {\n",
        "    \"Total_paros\": len(base),\n",
        "    \"Promedio_duracion\": round(base[\"duracion_dias\"].mean(skipna=True), 2),\n",
        "    \"Max_duracion\": base[\"duracion_dias\"].max(),\n",
        "    \"Min_duracion\": base[\"duracion_dias\"].min(),\n",
        "    \"Tipos_movilizacion\": base[\"tipo_movilizacion\"].value_counts().to_dict(),\n",
        "    \"Ciudades_principales\": base[\"ciudad\"].value_counts().head(5).to_dict(),\n",
        "    \"Sindicatos_principales\": base[\"organizaciones_sindicales\"].value_counts().head(5).to_dict(),\n",
        "    \"Fuentes\": base[\"fuentes_presentes\"].value_counts().to_dict()\n",
        "}\n",
        "pd.DataFrame([stats]).to_csv(\"ESTADISTICAS_PAROS_DOCENTES_2023.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# ================================================================\n",
        "# EXPORTAR BASE FINAL\n",
        "# ================================================================\n",
        "cols_export = [\"fecha_evento\",\"pais\",\"ciudad\",\"organizaciones_sindicales\",\"tipo_movilizacion\",\n",
        "               \"duracion_dias\",\"razones_paro\",\"resumen\",\"titulo_ref\",\"urls\",\"fuentes_presentes\"]\n",
        "base[\"fecha_evento\"] = pd.to_datetime(base[\"fecha_evento\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
        "base[cols_export].to_csv(\"BASE_FINAL_PAROS_DOCENTES_2023_VALIDADA.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"\\n‚úÖ BASE_FINAL_PAROS_DOCENTES_2023_VALIDADA.csv generada correctamente\")\n",
        "print(\"\\nResumen general:\")\n",
        "for k, v in stats.items():\n",
        "    print(f\"- {k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrbHGmGi8XnK",
        "outputId": "ad74c8bb-fc70-49ea-e031-9d5c7b05e160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ BASE_FINAL_PAROS_DOCENTES_2023_VALIDADA.csv generada correctamente\n",
            "\n",
            "Resumen general:\n",
            "- Total_paros: 55\n",
            "- Promedio_duracion: 1.44\n",
            "- Max_duracion: 5.0\n",
            "- Min_duracion: 1.0\n",
            "- Tipos_movilizacion: {'paro docente': 37, 'Plant√≥n': 7, 'Paro': 5, 'paro estudiantil': 2, 'Toma': 2, 'Marcha': 1, 'Sin evidencia': 1}\n",
            "- Ciudades_principales: {\"{'pais': 'Colombia'\": 33, 'Plazoleta SED': 4, 'Colombia': 3, 'Bogot√°': 1, 'Cl. 127c #9-89': 1}\n",
            "- Sindicatos_principales: {'FECODE': 17, 'NO ESPEC√çFICA': 12, 'ADE': 10, 'ADE | FECODE': 5, 'CUT | FECODE': 4}\n",
            "- Fuentes: {'WEB': 33, 'SED': 16, 'BQ': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================\n",
        "# CARGA DE BASE FINAL\n",
        "# ================================================================\n",
        "df = pd.read_csv(\"BASE_FINAL_PAROS_DOCENTES_2023_VALIDADA.csv\", encoding=\"utf-8-sig\")\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# ================================================================\n",
        "# FUNCIONES AUXILIARES\n",
        "# ================================================================\n",
        "def limpiar_texto(texto):\n",
        "    if pd.isna(texto):\n",
        "        return \"\"\n",
        "    return re.sub(r\"\\s+\", \" \", str(texto)).strip()\n",
        "\n",
        "def obtener_contenido_web(url):\n",
        "    \"\"\"Extrae el texto de la p√°gina si la URL es v√°lida.\"\"\"\n",
        "    if not isinstance(url, str) or url.strip() in [\"\", \"S/I\", \"s/i\", \"N/A\"]:\n",
        "        return \"\"\n",
        "    try:\n",
        "        r = requests.get(url, timeout=15)\n",
        "        if r.status_code != 200:\n",
        "            return \"\"\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        for tag in soup([\"script\", \"style\", \"noscript\", \"footer\", \"header\", \"aside\"]):\n",
        "            tag.extract()\n",
        "        texto = \" \".join(soup.stripped_strings)\n",
        "        return texto[:8000]\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "# ================================================================\n",
        "# IA: COMPLETAR DATOS FALTANTES (solo SED y BQ)\n",
        "# ================================================================\n",
        "def analizar_noticia_ia(fila):\n",
        "    \"\"\"Usa GPT-4o para estandarizar y completar informaci√≥n de una noticia.\"\"\"\n",
        "    url = fila.get(\"urls\", \"\")\n",
        "    titulo = fila.get(\"titulo_ref\", \"\")\n",
        "    texto = obtener_contenido_web(url)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Estandariza y completa la informaci√≥n de una noticia sobre paros docentes en Colombia.\n",
        "\n",
        "Entrada:\n",
        "T√≠tulo: {titulo}\n",
        "Texto de la noticia: {texto[:1500]}\n",
        "\n",
        "Devuelve un JSON v√°lido con las siguientes claves:\n",
        "{{\n",
        "  \"pais\": \"Colombia\",\n",
        "  \"ciudad\": \"nombre de la ciudad (si se menciona o vac√≠a si no)\",\n",
        "  \"organizaciones_sindicales\": [\"nombres de sindicatos mencionados\"],\n",
        "  \"tipo_movilizacion\": \"paro docente / plant√≥n / marcha / toma / protesta / asamblea\",\n",
        "  \"duracion_dias\": n√∫mero o null,\n",
        "  \"razones_paro\": \"resumen breve de motivos (salud, reformas, infraestructura, etc.)\",\n",
        "  \"resumen\": \"s√≠ntesis breve del hecho (m√°ximo 3 l√≠neas)\"\n",
        "}}\n",
        "Si la informaci√≥n no est√° expl√≠cita, infiere con contexto general sobre paros docentes en Colombia.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0.2,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "        salida = response.choices[0].message.content.strip()\n",
        "\n",
        "        try:\n",
        "            datos = json.loads(salida)\n",
        "        except:\n",
        "            match = re.search(r\"\\{.*\\}\", salida, re.DOTALL)\n",
        "            datos = json.loads(match.group(0)) if match else {}\n",
        "\n",
        "        return datos\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error IA: {e}\")\n",
        "        return {\n",
        "            \"pais\": \"Colombia\",\n",
        "            \"ciudad\": \"\",\n",
        "            \"organizaciones_sindicales\": [],\n",
        "            \"tipo_movilizacion\": \"\",\n",
        "            \"duracion_dias\": None,\n",
        "            \"razones_paro\": \"\",\n",
        "            \"resumen\": \"\"\n",
        "        }\n",
        "\n",
        "# ================================================================\n",
        "# FILTRAR SOLO LAS FUENTES SED Y BQ PARA IA\n",
        "# ================================================================\n",
        "df[\"fuentes_presentes\"] = df[\"fuentes_presentes\"].astype(str).str.upper().str.strip()\n",
        "\n",
        "mask_ia = df[\"fuentes_presentes\"].isin([\"SED\", \"BQ\"])\n",
        "df_sin_ia = df[~mask_ia].copy()\n",
        "df_con_ia = df[mask_ia].copy()\n",
        "\n",
        "print(f\"Noticias a analizar con IA: {len(df_con_ia)} de {len(df)} totales\")\n",
        "\n",
        "# ================================================================\n",
        "# PROCESAR SOLO SED Y BQ CON IA\n",
        "# ================================================================\n",
        "resultados_ia = []\n",
        "\n",
        "for i, fila in enumerate(df_con_ia.to_dict(\"records\")):\n",
        "    url = fila.get(\"urls\", \"\")\n",
        "    fuente = fila.get(\"fuentes_presentes\", \"\")\n",
        "    print(f\"[{i+1}/{len(df_con_ia)}] Fuente: {fuente} | URL: {url[:80]}\")\n",
        "\n",
        "    try:\n",
        "        analisis = analizar_noticia_ia(fila)\n",
        "        fila.update(analisis)\n",
        "        resultados_ia.append(fila)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en fila {i+1}: {e}\")\n",
        "        resultados_ia.append(fila)\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "df_analizadas = pd.DataFrame(resultados_ia)\n",
        "\n",
        "# ================================================================\n",
        "# UNIR CON LAS DEM√ÅS NOTICIAS (WEB)\n",
        "# ================================================================\n",
        "df_ia = pd.concat([df_sin_ia, df_analizadas], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TerrAF5XA0fm",
        "outputId": "4c49f0fe-474c-48ba-9701-336cbbf15fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noticias a analizar con IA: 22 de 55 totales\n",
            "[1/22] Fuente: SED | URL: S/I\n",
            "[2/22] Fuente: BQ | URL: https://pulsoslp.com.mx/mundo/maestros-de-colombia-protestan-frente-al-congreso-\n",
            "[3/22] Fuente: SED | URL: https://www.infobae.com/colombia/2023/03/13/fecode-anuncio-nuevo-paro-de-profeso\n",
            "[4/22] Fuente: SED | URL: S/I\n",
            "[5/22] Fuente: SED | URL: https://www.infobae.com/colombia/2023/03/13/fecode-anuncio-nuevo-paro-de-profeso\n",
            "[6/22] Fuente: BQ | URL: https://eldeber.com.bo/pais/maestros-protestan-dedicando-canciones-de-shakira-y-\n",
            "[7/22] Fuente: SED | URL: https://www.infobae.com/america/colombia/2022/11/03/paro-de-maestros-este-jueves\n",
            "[8/22] Fuente: SED | URL: https://www.infobae.com/colombia/2023/03/13/fecode-anuncio-nuevo-paro-de-profeso\n",
            "[9/22] Fuente: SED | URL: https://caracol.com.co/2023/03/27/protestas-en-bogota-el-28-y-29-de-marzo-2023-r\n",
            "[10/22] Fuente: SED | URL: S/I\n",
            "[11/22] Fuente: SED | URL: S/I\n",
            "[12/22] Fuente: SED | URL: https://www.radionacional.co/actualidad/politica/marchas-7-de-junio-2023-quienes\n",
            "[13/22] Fuente: SED | URL: S/I\n",
            "[14/22] Fuente: SED | URL: S/I\n",
            "[15/22] Fuente: SED | URL: https://caracol.com.co/2023/07/19/marchas-20-de-julio-en-colombia-razones-y-punt\n",
            "[16/22] Fuente: BQ | URL: https://www.larepublica.co/economia/fecode-convoco-un-paro-de-de-maestros-24-hor\n",
            "[17/22] Fuente: BQ | URL: https://www.infobae.com/colombia/2023/08/30/en-vivo-asi-avanza-la-nueva-jornada-\n",
            "[18/22] Fuente: BQ | URL: https://elpais.com/america-colombia/2023-08-30/los-viejos-y-nuevos-motivos-de-la\n",
            "[19/22] Fuente: SED | URL: https://www.elespectador.com/educacion/paro-de-fecode-de-este-miercoles-puntos-d\n",
            "[20/22] Fuente: BQ | URL: https://diariodelhuila.com/ahora-los-maestros/\n",
            "[21/22] Fuente: SED | URL: https://www.infobae.com/colombia/2023/09/27/fecode-se-unio-a-las-movilizaciones-\n",
            "[22/22] Fuente: SED | URL: S/I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ESTANDARIZAR ORGANIZACIONES SINDICALES\n",
        "# ================================================================\n",
        "def estandarizar_orgs(valor):\n",
        "    \"\"\"Estandariza nombres de sindicatos en formato √∫nico y consistente.\"\"\"\n",
        "    # Manejar valores vac√≠os, listas o arrays\n",
        "    if valor is None:\n",
        "        return \"\"\n",
        "    if isinstance(valor, (list, set, tuple)):\n",
        "        texto = \" \".join(map(str, valor))\n",
        "    elif isinstance(valor, (pd.Series, np.ndarray)):\n",
        "        texto = \" \".join(map(str, valor.tolist()))\n",
        "    else:\n",
        "        texto = str(valor)\n",
        "\n",
        "    texto = texto.strip()\n",
        "    if texto == \"\" or texto.upper() in [\"NAN\", \"NONE\"]:\n",
        "        return \"NO ESPEC√çFICA\"\n",
        "\n",
        "    texto = re.sub(r\"[\\[\\]'\\\"{}]\", \"\", texto)\n",
        "    partes = re.split(r\"[;|,/\\-]+\", texto)\n",
        "    partes = [p.strip().upper() for p in partes if p.strip()]\n",
        "\n",
        "    equivalencias = {\n",
        "        \"ADE\": [\"ADE\", \"ASOCIACION DISTRITAL DE EDUCADORES\", \"ASOCIACI√ìN DISTRITAL DE EDUCADORES\"],\n",
        "        \"FECODE\": [\"FECODE\", \"FEDERACION COLOMBIANA DE TRABAJADORES DE LA EDUCACION\", \"FEDERACI√ìN COLOMBIANA DE TRABAJADORES DE LA EDUCACI√ìN\"],\n",
        "        \"CUT\": [\"CUT\", \"CENTRAL UNITARIA DE TRABAJADORES\"],\n",
        "        \"CTC\": [\"CTC\", \"CONFEDERACION DE TRABAJADORES DE COLOMBIA\", \"CONFEDERACI√ìN DE TRABAJADORES DE COLOMBIA\"],\n",
        "        \"SINTRANAL\": [\"SINTRANAL\", \"SINDICATO NACIONAL DE TRABAJADORES DE LA EDUCACION\", \"SINDICATO NACIONAL DE TRABAJADORES DE LA EDUCACI√ìN\"],\n",
        "        \"ADIDA\": [\"ADIDA\", \"ASOCIACION DE INSTITUTO DE ANTIOQUIA\", \"ASOCIACI√ìN DE INSTITUTO DE ANTIOQUIA\"]\n",
        "    }\n",
        "\n",
        "    normalizados = set()\n",
        "    for p in partes:\n",
        "        for clave, variantes in equivalencias.items():\n",
        "            if any(v in p for v in variantes):\n",
        "                normalizados.add(clave)\n",
        "                break\n",
        "        else:\n",
        "            if p and p not in [\"NO ESPECIFICA\", \"NO ESPEC√çFICA\", \"NO APLICA\"]:\n",
        "                normalizados.add(p)\n",
        "\n",
        "    return \" | \".join(sorted(normalizados)) if normalizados else \"NO ESPEC√çFICA\"\n",
        "\n",
        "\n",
        "df_ia[\"organizaciones_sindicales\"] = df_ia[\"organizaciones_sindicales\"].apply(estandarizar_orgs)\n",
        "\n",
        "# ================================================================\n",
        "# GUARDAR RESULTADO FINAL\n",
        "# ================================================================\n",
        "df_ia.to_csv(\"BASE_PAROS_DOCENTES_2023_IA.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Proceso completado correctamente.\")\n",
        "print(\"Archivo generado: BASE_PAROS_DOCENTES_2023_IA.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "bmu6oQN5CCb_",
        "outputId": "edd6b62d-1819-47c2-adc3-b05c33ad5036"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_ia' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2649917062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdf_ia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"organizaciones_sindicales\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"organizaciones_sindicales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestandarizar_orgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_ia' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# UNIFICAR PAROS DOCENTES 2023\n",
        "# ================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import timedelta\n",
        "\n",
        "# -----------------------------\n",
        "# 1. CARGAR BASE\n",
        "# -----------------------------\n",
        "df = pd.read_csv(\"BASE_PAROS_DOCENTES_2023_IA.csv\", encoding=\"utf-8-sig\")\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "if \"fecha_evento\" in df.columns:\n",
        "    df[\"fecha_evento\"] = pd.to_datetime(df[\"fecha_evento\"], errors=\"coerce\")\n",
        "\n",
        "df = df.dropna(subset=[\"fecha_evento\"]).sort_values(\"fecha_evento\").reset_index(drop=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. FUNCIONES AUXILIARES\n",
        "# -----------------------------\n",
        "def combinar_textos(series):\n",
        "    \"\"\"Combina textos o listas de textos sin duplicar informaci√≥n.\"\"\"\n",
        "    textos = []\n",
        "    for val in series.dropna():\n",
        "        if isinstance(val, str):\n",
        "            partes = re.split(r\"[|;]+\", val)\n",
        "            textos.extend([p.strip() for p in partes if p.strip()])\n",
        "        elif isinstance(val, (list, set, tuple)):\n",
        "            textos.extend([str(p).strip() for p in val if str(p).strip()])\n",
        "    return \"; \".join(sorted(set(textos)))\n",
        "\n",
        "def combinar_numeros(series):\n",
        "    \"\"\"Promedio de valores num√©ricos.\"\"\"\n",
        "    vals = pd.to_numeric(series, errors=\"coerce\")\n",
        "    return round(vals.mean(skipna=True), 1) if vals.notna().any() else np.nan\n",
        "\n",
        "def combinar_fuentes(series):\n",
        "    \"\"\"Une todas las fuentes sin repetir.\"\"\"\n",
        "    return \"; \".join(sorted(set(\n",
        "        re.split(r\"[;|,]+\", \";\".join(series.dropna().astype(str)))\n",
        "    )))\n",
        "\n",
        "def combinar_urls(series):\n",
        "    \"\"\"Combina todas las URLs √∫nicas, creando columnas url_1, url_2, ...\"\"\"\n",
        "    urls = []\n",
        "    for val in series.dropna():\n",
        "        if isinstance(val, str):\n",
        "            for u in re.split(r\"[|,;]+\", val):\n",
        "                if u.strip() and u.strip().startswith(\"http\"):\n",
        "                    urls.append(u.strip())\n",
        "    return sorted(set(urls))\n",
        "\n",
        "# -----------------------------\n",
        "# 3. AGRUPAR POR FECHA CON TOLERANCIA DE ¬±2 D√çAS\n",
        "# -----------------------------\n",
        "# Ordenar por fecha\n",
        "df = df.sort_values(\"fecha_evento\").reset_index(drop=True)\n",
        "\n",
        "# Crear grupos de eventos cercanos (ventana de 2 d√≠as)\n",
        "grupos = []\n",
        "grupo_actual = 0\n",
        "fechas = df[\"fecha_evento\"].tolist()\n",
        "\n",
        "for i in range(len(fechas)):\n",
        "    if i == 0:\n",
        "        grupos.append(grupo_actual)\n",
        "        continue\n",
        "    diff = (fechas[i] - fechas[i - 1]).days\n",
        "    if diff <= 2:\n",
        "        grupos.append(grupo_actual)\n",
        "    else:\n",
        "        grupo_actual += 1\n",
        "        grupos.append(grupo_actual)\n",
        "\n",
        "df[\"grupo_paro\"] = grupos\n",
        "\n",
        "# -----------------------------\n",
        "# 4. FUSIONAR INFORMACI√ìN POR GRUPO\n",
        "# -----------------------------\n",
        "agrupado = []\n",
        "for gid, sub in df.groupby(\"grupo_paro\"):\n",
        "    fila = {}\n",
        "    fila[\"fecha_inicio\"] = sub[\"fecha_evento\"].min()\n",
        "    fila[\"fecha_fin\"] = sub[\"fecha_evento\"].max()\n",
        "    fila[\"fecha_referencia\"] = fila[\"fecha_inicio\"].strftime(\"%Y-%m-%d\") if not pd.isna(fila[\"fecha_inicio\"]) else \"\"\n",
        "\n",
        "    fila[\"ciudad\"] = combinar_textos(sub.get(\"ciudad\", pd.Series([])))\n",
        "    fila[\"organizaciones_sindicales\"] = combinar_textos(sub.get(\"organizaciones_sindicales\", pd.Series([])))\n",
        "    fila[\"tipo_movilizacion\"] = combinar_textos(sub.get(\"tipo_movilizacion\", pd.Series([])))\n",
        "    fila[\"duracion_dias\"] = combinar_numeros(sub.get(\"duracion_dias\", pd.Series([])))\n",
        "    fila[\"razones_paro\"] = combinar_textos(sub.get(\"razones_paro\", pd.Series([])))\n",
        "    fila[\"resumen\"] = combinar_textos(sub.get(\"resumen\", pd.Series([])))\n",
        "    fila[\"fuentes_presentes\"] = combinar_fuentes(sub.get(\"fuentes_presentes\", pd.Series([])))\n",
        "\n",
        "    urls_unicas = combinar_urls(sub.get(\"urls\", pd.Series([])))\n",
        "    for i, url in enumerate(urls_unicas, start=1):\n",
        "        fila[f\"url_{i}\"] = url\n",
        "\n",
        "    agrupado.append(fila)\n",
        "\n",
        "base_unificada = pd.DataFrame(agrupado).sort_values(\"fecha_inicio\").reset_index(drop=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. EXPORTAR RESULTADO\n",
        "# -----------------------------\n",
        "base_unificada[\"fecha_inicio\"] = pd.to_datetime(base_unificada[\"fecha_inicio\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
        "base_unificada[\"fecha_fin\"] = pd.to_datetime(base_unificada[\"fecha_fin\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "base_unificada.to_csv(\"BASE_PAROS_UNIFICADOS_2023.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Base unificada generada: BASE_PAROS_UNIFICADOS_2023.csv\")\n",
        "print(\"Paros √∫nicos encontrados:\", len(base_unificada))\n",
        "print(\"N√∫mero m√°ximo de columnas URL:\", base_unificada.filter(like='url_').shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C30UpnA82cPc",
        "outputId": "14f7db3a-5e73-4c87-d453-fd758e3d6c9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base unificada generada: BASE_PAROS_UNIFICADOS_2023.csv\n",
            "Paros √∫nicos encontrados: 22\n",
            "N√∫mero m√°ximo de columnas URL: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ESTAD√çSTICAS BASE PAROS UNIFICADOS (\n",
        "# ================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ================================================================\n",
        "# 1. CARGAR BASE UNIFICADA\n",
        "# ================================================================\n",
        "base = pd.read_csv(\"BASE_PAROS_UNIFICADOS_2023.csv\", encoding=\"utf-8-sig\")\n",
        "base.columns = base.columns.str.strip().str.lower()\n",
        "\n",
        "# --- Fechas ---\n",
        "if \"fecha_inicio\" in base.columns:\n",
        "    base[\"fecha_inicio\"] = pd.to_datetime(base[\"fecha_inicio\"], errors=\"coerce\")\n",
        "if \"fecha_fin\" in base.columns:\n",
        "    base[\"fecha_fin\"] = pd.to_datetime(base[\"fecha_fin\"], errors=\"coerce\")\n",
        "\n",
        "# --- Duraci√≥n calculada si falta ---\n",
        "if \"duracion_dias\" not in base.columns or base[\"duracion_dias\"].isna().all():\n",
        "    base[\"duracion_dias\"] = (base[\"fecha_fin\"] - base[\"fecha_inicio\"]).dt.days + 1\n",
        "\n",
        "# Asegurar valores positivos\n",
        "base[\"duracion_dias\"] = base[\"duracion_dias\"].clip(lower=1)\n",
        "\n",
        "# ================================================================\n",
        "# 2. LIMPIEZA Y PREPARACI√ìN\n",
        "# ================================================================\n",
        "def limpiar_texto(x):\n",
        "    if pd.isna(x):\n",
        "        return \"\"\n",
        "    x = str(x).strip().lower()\n",
        "    x = re.sub(r\"[\\[\\]{}'\\\"]\", \"\", x)\n",
        "    return re.sub(r\"\\s+\", \" \", x).strip()\n",
        "\n",
        "base[\"tipo_movilizacion\"] = base[\"tipo_movilizacion\"].apply(limpiar_texto)\n",
        "base[\"organizaciones_sindicales\"] = base[\"organizaciones_sindicales\"].apply(limpiar_texto)\n",
        "base[\"fuentes_presentes\"] = base[\"fuentes_presentes\"].apply(limpiar_texto)\n",
        "\n",
        "# Mes de referencia seg√∫n fecha_inicio\n",
        "base[\"mes\"] = base[\"fecha_inicio\"].dt.to_period(\"M\")\n",
        "\n",
        "# ================================================================\n",
        "# 3. ESTAD√çSTICAS DESCRIPTIVAS\n",
        "# ================================================================\n",
        "print(\"\\nGenerando estad√≠sticas descriptivas de paros unificados...\")\n",
        "\n",
        "# ---- 3.1 Total de paros por mes\n",
        "paros_mes = base[\"mes\"].value_counts().sort_index().reset_index()\n",
        "paros_mes.columns = [\"Mes\", \"Total_Paros\"]\n",
        "\n",
        "# ---- 3.2 Tipos de movilizaci√≥n\n",
        "tipos = (\n",
        "    base[\"tipo_movilizacion\"]\n",
        "    .str.split(r\"[;|,]+\")\n",
        "    .explode()\n",
        "    .str.strip()\n",
        "    .replace(\"\", np.nan)\n",
        "    .dropna()\n",
        "    .value_counts()\n",
        "    .reset_index()\n",
        ")\n",
        "tipos.columns = [\"Tipo de Movilizaci√≥n\", \"Total\"]\n",
        "\n",
        "# ---- 3.3 Duraci√≥n promedio, mediana y rango\n",
        "base[\"duracion_dias\"] = pd.to_numeric(base[\"duracion_dias\"], errors=\"coerce\")\n",
        "duracion_stats = {\n",
        "    \"Promedio (d√≠as)\": round(base[\"duracion_dias\"].mean(skipna=True), 2),\n",
        "    \"Mediana (d√≠as)\": base[\"duracion_dias\"].median(skipna=True),\n",
        "    \"M√°ximo (d√≠as)\": base[\"duracion_dias\"].max(),\n",
        "    \"M√≠nimo (d√≠as)\": base[\"duracion_dias\"].min(),\n",
        "    \"Desviaci√≥n est√°ndar\": round(base[\"duracion_dias\"].std(skipna=True), 2)\n",
        "}\n",
        "\n",
        "# ---- 3.4 Organizaciones sindicales\n",
        "def limpiar_orgs(x):\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        parts = re.split(r\"[,;|]+\", x)\n",
        "        return [p.strip().upper() for p in parts if p.strip()]\n",
        "    return []\n",
        "\n",
        "orgs = (\n",
        "    base[\"organizaciones_sindicales\"]\n",
        "    .apply(limpiar_orgs)\n",
        "    .explode()\n",
        "    .value_counts()\n",
        "    .head(15)\n",
        "    .reset_index()\n",
        ")\n",
        "orgs.columns = [\"Organizaci√≥n Sindical\", \"Frecuencia\"]\n",
        "\n",
        "# ---- 3.5 Fuentes m√°s comunes\n",
        "def limpiar_fuentes(x):\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        return [f.strip().upper() for f in re.split(r\"[,;|]+\", x) if f.strip()]\n",
        "    return []\n",
        "\n",
        "fuentes = (\n",
        "    base[\"fuentes_presentes\"]\n",
        "    .apply(limpiar_fuentes)\n",
        "    .explode()\n",
        "    .value_counts()\n",
        "    .reset_index()\n",
        ")\n",
        "fuentes.columns = [\"Fuente\", \"Total_Paros\"]\n",
        "\n",
        "# ---- 3.6 Rango de fechas analizado\n",
        "rango_fechas = {\n",
        "    \"Fecha m√°s antigua\": base[\"fecha_inicio\"].min().strftime(\"%Y-%m-%d\"),\n",
        "    \"Fecha m√°s reciente\": base[\"fecha_fin\"].max().strftime(\"%Y-%m-%d\"),\n",
        "    \"Total paros\": len(base)\n",
        "}\n",
        "\n",
        "# ================================================================\n",
        "# 4. EXPORTAR RESULTADOS\n",
        "# ================================================================\n",
        "with pd.ExcelWriter(\"Estadisticas_Paros_Unificados_2023.xlsx\", engine=\"openpyxl\") as writer:\n",
        "    paros_mes.to_excel(writer, sheet_name=\"Paros por Mes\", index=False)\n",
        "    tipos.to_excel(writer, sheet_name=\"Tipos de Movilizaci√≥n\", index=False)\n",
        "    orgs.to_excel(writer, sheet_name=\"Organizaciones\", index=False)\n",
        "    fuentes.to_excel(writer, sheet_name=\"Fuentes\", index=False)\n",
        "    pd.DataFrame([duracion_stats]).to_excel(writer, sheet_name=\"Duraci√≥n\", index=False)\n",
        "    pd.DataFrame([rango_fechas]).to_excel(writer, sheet_name=\"Resumen General\", index=False)\n",
        "\n",
        "# ================================================================\n",
        "# 5. RESUMEN EN CONSOLA\n",
        "# ================================================================\n",
        "print(\"\\nResumen r√°pido:\")\n",
        "print(f\"Total de paros √∫nicos: {len(base)}\")\n",
        "print(f\"Meses con paros: {base['mes'].nunique()}\")\n",
        "print(f\"Promedio de duraci√≥n: {duracion_stats['Promedio (d√≠as)']} d√≠as\")\n",
        "print(f\"Rango de fechas: {rango_fechas['Fecha m√°s antigua']} ‚Üí {rango_fechas['Fecha m√°s reciente']}\")\n",
        "\n",
        "print(\"\\nArchivo generado: Estadisticas_Paros_Unificados_2023.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLPEnynp3aN2",
        "outputId": "184c85e5-d48c-4d3a-d6ed-d57e80493680"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generando estad√≠sticas descriptivas de paros unificados...\n",
            "\n",
            "Resumen r√°pido:\n",
            "Total de paros √∫nicos: 22\n",
            "Meses con paros: 10\n",
            "Promedio de duraci√≥n: 1.97 d√≠as\n",
            "Rango de fechas: 2023-01-18 ‚Üí 2023-11-29\n",
            "\n",
            "Archivo generado: Estadisticas_Paros_Unificados_2023.xlsx\n"
          ]
        }
      ]
    }
  ]
}