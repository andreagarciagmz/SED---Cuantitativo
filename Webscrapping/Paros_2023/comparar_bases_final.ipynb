{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip  install pandas\n",
        "!pip  install numpy\n",
        "!pip  install datetime\n",
        "!pip  install regex\n",
        "!pip  install openai\n",
        "!pip  install bs4\n",
        "!pip  install requests\n",
        "!pip  install json\n",
        "!pip  install numpy\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMF9PrGneH1b",
        "outputId": "2a1b5566-0e10-46b3-a5b6-63966e528449",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.12/dist-packages (5.5)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.12/dist-packages (from datetime) (8.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from datetime) (2025.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2024.11.6)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.12/dist-packages (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from bs4) (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (4.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ==============================\n",
        "# 1. Cargar archivo CSV\n",
        "# ==============================\n",
        "df = pd.read_csv(\"bq-results-20251023-000630-1761178021663.csv\", encoding=\"utf-8-sig\")\n",
        "\n",
        "# Limpieza de encabezados para evitar errores por espacios o caracteres invisibles\n",
        "df.columns = (\n",
        "    df.columns.str.encode('utf-8').str.decode('utf-8', 'ignore')\n",
        "    .str.replace(\"ï»¿\", \"\", regex=False)\n",
        "    .str.strip()\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# 2. Limpieza y formato de fecha\n",
        "# ==============================\n",
        "# Verificar si la columna SQLDATE existe\n",
        "col_fecha = [c for c in df.columns if \"SQLDATE\" in c.upper()]\n",
        "if not col_fecha:\n",
        "    raise ValueError(\"No se encontró la columna SQLDATE en el archivo CSV.\")\n",
        "col_fecha = col_fecha[0]\n",
        "\n",
        "# Convertir fechas con detección automática\n",
        "df[col_fecha] = pd.to_datetime(df[col_fecha].astype(str), errors='coerce')\n",
        "\n",
        "# ==============================\n",
        "# 3. Filtro por año 2023\n",
        "# ==============================\n",
        "df_2023 = df[df[col_fecha].dt.year == 2023].copy()\n",
        "\n",
        "# ==============================\n",
        "# 4. Filtro por país Colombia\n",
        "# ==============================\n",
        "col_pais = [c for c in df.columns if \"COUNTRYCODE\" in c.upper()]\n",
        "if not col_pais:\n",
        "    raise ValueError(\"No se encontró la columna ActionGeo_CountryCode en el archivo CSV.\")\n",
        "col_pais = col_pais[0]\n",
        "\n",
        "df_colombia = df_2023[df_2023[col_pais].astype(str).str.upper() == \"CO\"].copy()\n",
        "\n",
        "# ==============================\n",
        "# 5. Filtro por contenido del SOURCEURL\n",
        "# ==============================\n",
        "col_url = [c for c in df.columns if \"SOURCEURL\" in c.upper()]\n",
        "if not col_url:\n",
        "    raise ValueError(\"No se encontró la columna SOURCEURL en el archivo CSV.\")\n",
        "col_url = col_url[0]\n",
        "\n",
        "df_colombia[col_url] = df_colombia[col_url].astype(str).str.lower()\n",
        "\n",
        "palabras_clave = ['paro-docente', 'fecode', 'maestros', 'protesta-docente', 'paro-maestros']\n",
        "\n",
        "filtro_tema = df_colombia[col_url].apply(\n",
        "    lambda x: any(palabra in x for palabra in palabras_clave)\n",
        ")\n",
        "\n",
        "df_filtrado = df_colombia.loc[filtro_tema, [col_fecha, 'ActionGeo_FullName', col_url]].copy()\n",
        "\n",
        "# ==============================\n",
        "# 6. Eliminar duplicados\n",
        "# ==============================\n",
        "df_filtrado = df_filtrado.drop_duplicates(subset=[col_url], keep='first')\n",
        "\n",
        "# ==============================\n",
        "# 7. Guardar resultado final\n",
        "# ==============================\n",
        "print(\"Noticias filtradas:\", len(df_filtrado))\n",
        "print(df_filtrado.head())\n",
        "\n",
        "df_filtrado.to_csv(\"BQ_Noticias_Paro_Docente_2023.csv\", index=False, encoding=\"utf-8-sig\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hUuh6OW9cwQ",
        "outputId": "6707cdf3-db02-400d-cc55-66d3e0d213a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noticias filtradas: 6\n",
            "         SQLDATE              ActionGeo_FullName  \\\n",
            "2160  2023-03-11                        Colombia   \n",
            "3283  2023-08-30                        Colombia   \n",
            "3287  2023-08-30      Cartagena, Bolír, Colombia   \n",
            "10036 2023-08-24                        Colombia   \n",
            "14469 2023-02-08  Bogota, Cundinamarca, Colombia   \n",
            "\n",
            "                                               SOURCEURL  \n",
            "2160   https://eldeber.com.bo/pais/maestros-protestan...  \n",
            "3283      https://diariodelhuila.com/ahora-los-maestros/  \n",
            "3287   https://elpais.com/america-colombia/2023-08-30...  \n",
            "10036  https://www.larepublica.co/economia/fecode-con...  \n",
            "14469  https://pulsoslp.com.mx/mundo/maestros-de-colo...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === 1. Cargar el archivo ===\n",
        "df = pd.read_csv(\"Base-SGI-suspensión-clases-2012-2025-03_08_2025_VALIDACION-SED.csv\")\n",
        "\n",
        "# Normalizar nombres de columnas (elimina espacios, mayúsculas y tildes)\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\"á\", \"a\").str.replace(\"é\", \"e\").str.replace(\"í\", \"i\").str.replace(\"ó\", \"o\").str.replace(\"ú\", \"u\")\n",
        "\n",
        "# === 2. Unificar formato de fechas ===\n",
        "for col in df.columns:\n",
        "    if \"fecha\" in col:\n",
        "        df[col] = pd.to_datetime(df[col], errors=\"coerce\", dayfirst=True)\n",
        "\n",
        "# === 3. Filtrar por año 2023 ===\n",
        "df_2023 = df[\n",
        "    (df[\"fecha inicio\"].dt.year == 2023) |\n",
        "    (df[\"fecha fin\"].dt.year == 2023)\n",
        "]\n",
        "\n",
        "# === 5. Identificar las columnas disponibles ===\n",
        "print(\"🧾 Columnas disponibles:\", list(df_2023.columns))\n",
        "\n",
        "# Seleccionar las más relevantes si existen\n",
        "cols_posibles = [\n",
        "    \"fecha inicio\", \"fecha fin\", \"convocante\", \"hecho\",\n",
        "    \"ubicacion\", \"medio de verificacion\",\"medio de verificacion 2\", \"tipo de protesta\", \"alcance\"\n",
        "]\n",
        "cols_finales = [c for c in cols_posibles if c in df_2023.columns]\n",
        "\n",
        "# === 6. Subconjunto limpio ===\n",
        "df_resultado = df_2023[cols_finales].reset_index(drop=True)\n",
        "\n",
        "# === 8. (Opcional) Guardar en CSV ===\n",
        "df_resultado.to_csv(\"SED_Paros_Docentes_Colombia_2023.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nyPkGByi3Cot",
        "outputId": "ed0a3d2d-2162-4bec-cdcf-cea1bbaf7b64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧾 Columnas disponibles: ['convocante', 'fecha inicio', 'fecha fin', 'hecho', 'evento', 'tipo de protesta', 'alcance', 'tiempo', 'suspension clases', 'dias suspension clases', 'aforo', 'ubicacion', 'medio de verificacion', 'medio de verificacion 2', 'medio de verificacion 3', 'medio de verificacion organizacion sindical', 'medio de verificacion organizacion sindical.1', 'observaciones', 'unnamed: 18', 'unnamed: 19', 'unnamed: 20', 'unnamed: 21', 'unnamed: 22', 'unnamed: 23', 'unnamed: 24', 'unnamed: 25']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# === 1. Cargar archivo ===\n",
        "df = pd.read_csv(\"web_noticias_paros_docentes_2023.csv\")\n",
        "\n",
        "# === 2. Estandarizar nombres de columnas ===\n",
        "df.columns = df.columns.str.strip().str.lower().str.replace(\"á\", \"a\").str.replace(\"é\", \"e\").str.replace(\"í\", \"i\").str.replace(\"ó\", \"o\").str.replace(\"ú\", \"u\")\n",
        "\n",
        "# === 3. Convertir la columna de fecha_paro a formato fecha ===\n",
        "df[\"fecha_paro\"] = pd.to_datetime(df[\"fecha_paro\"], errors=\"coerce\", dayfirst=True)\n",
        "\n",
        "# === 4. Filtrar los paros del año 2023 ===\n",
        "df_2023 = df[df[\"fecha_paro\"].dt.year == 2023]\n",
        "\n",
        "# === 5. Seleccionar columnas relevantes ===\n",
        "cols_finales = [\n",
        "    \"titulo\",\n",
        "    \"fuente\",\n",
        "    \"url\",\n",
        "    \"fecha_paro\",\n",
        "    \"duracion_dias\",\n",
        "    \"organizaciones_sindicales\",\n",
        "    \"razones_paro\",\n",
        "    \"resumen\",\n",
        "    \"ubicacion\",\n",
        "    \"tipo_movilizacion\"\n",
        "]\n",
        "\n",
        "df_reducido = df_2023[cols_finales].reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "# === 7. (Opcional) Exportar a CSV ===\n",
        "df_reducido.to_csv(\"WEB_Paros_Docentes_2023_Reducido.csv\" , index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "esBBD_eEIHiB",
        "outputId": "804a6e32-6120-48e7-dc7c-a03ee7a9bb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2078167426.py:10: UserWarning: Parsing dates in %Y-%m-%d format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
            "  df[\"fecha_paro\"] = pd.to_datetime(df[\"fecha_paro\"], errors=\"coerce\", dayfirst=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install os\n",
        "!pip install pandas\n",
        "!pip install numpy\n",
        "!pip install requests\n",
        "!pip install json\n",
        "!pip install bs4\n",
        "!pip install datetime\n",
        "!pip install time\n",
        "!pip install urllib.parse\n",
        "!pip install difflib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QMDMrbFMdYVI",
        "outputId": "5a7a8706-65cb-47bf-facc-8c9a70f40f77"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for json\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting bs4\n",
            "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from bs4) (4.13.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (4.15.0)\n",
            "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
            "Installing collected packages: bs4\n",
            "Successfully installed bs4-0.0.2\n",
            "Collecting datetime\n",
            "  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting zope.interface (from datetime)\n",
            "  Downloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from datetime) (2025.2)\n",
            "Downloading DateTime-5.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zope_interface-8.0.1-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.7/264.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: zope.interface, datetime\n",
            "Successfully installed datetime-5.5 zope.interface-8.0.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement time (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for time\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement urllib.parse (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for urllib.parse\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement difflib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for difflib\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, re\n",
        "import pandas as pd, numpy as np, requests, json, time\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from openai import OpenAI\n",
        "from urllib.parse import urlparse, parse_qsl, urlencode, urlunparse\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "# Inicializa el cliente\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "RGUYefg2c2WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "FILE_WEB = \"WEB_Paros_Docentes_2023_Reducido.csv\"\n",
        "FILE_SED = \"SED_Paros_Docentes_Colombia_2023.csv\"\n",
        "FILE_BQ  = \"BQ_Noticias_Paro_Docente_2023.csv\"\n",
        "\n",
        "# -------------------- UTILIDADES --------------------\n",
        "def norm_cols(df):\n",
        "    df.columns = (df.columns.str.strip().str.lower()\n",
        "                  .str.replace(\"á\",\"a\").str.replace(\"é\",\"e\")\n",
        "                  .str.replace(\"í\",\"i\").str.replace(\"ó\",\"o\").str.replace(\"ú\",\"u\"))\n",
        "    return df\n",
        "\n",
        "def safe_dt(x, dayfirst=False):\n",
        "    return pd.to_datetime(x, errors=\"coerce\", dayfirst=dayfirst)\n",
        "\n",
        "def get_col(df, keys):\n",
        "    for k in keys:\n",
        "        hits = [c for c in df.columns if k in c]\n",
        "        if hits: return hits[0]\n",
        "    return None\n",
        "\n",
        "def ensure_cols(df, cols, fill=np.nan):\n",
        "    for c in cols:\n",
        "        if c not in df.columns:\n",
        "            df[c] = fill\n",
        "    return df\n",
        "\n",
        "# -------------------- CARGA --------------------\n",
        "web = norm_cols(pd.read_csv(FILE_WEB))\n",
        "sed = norm_cols(pd.read_csv(FILE_SED))\n",
        "bq  = norm_cols(pd.read_csv(FILE_BQ))\n",
        "\n",
        "for df in [web, sed, bq]:\n",
        "    for c in df.columns:\n",
        "        if \"fecha\" in c:\n",
        "            df[c] = safe_dt(df[c], dayfirst=False)\n",
        "\n",
        "# ================================================================\n",
        "# BASE SED\n",
        "# ================================================================\n",
        "col_fecha = get_col(sed, [\"fecha inicio\",\"fechainicio\",\"fecha\"])\n",
        "col_fin   = get_col(sed, [\"fecha fin\",\"fechafin\",\"fin\"])\n",
        "col_hecho = get_col(sed, [\"hecho\",\"evento\",\"descripcion\"])\n",
        "col_tipo  = get_col(sed, [\"tipo de protesta\",\"tipo\",\"movilizacion\"])\n",
        "col_conv  = get_col(sed, [\"convocante\",\"organizacion\",\"sindicato\"])\n",
        "col_ubic  = get_col(sed, [\"ubicacion\",\"lugar\",\"region\"])\n",
        "col_dias  = get_col(sed, [\"dias suspension\",\"duracion_dias\",\"dias\",\"duracion\"])\n",
        "\n",
        "if not col_dias and col_fecha and col_fin:\n",
        "    sed[\"duracion_dias\"] = (safe_dt(sed[col_fin]) - safe_dt(sed[col_fecha])).dt.days + 1\n",
        "    sed.loc[sed[\"duracion_dias\"] < 1, \"duracion_dias\"] = 1\n",
        "    col_dias = \"duracion_dias\"\n",
        "elif not col_dias:\n",
        "    sed[\"duracion_dias\"] = np.nan\n",
        "    col_dias = \"duracion_dias\"\n",
        "\n",
        "sel = [c for c in [col_fecha,col_hecho,col_tipo,col_conv,col_ubic,col_dias] if c]\n",
        "sed_final = sed[sel].rename(columns={\n",
        "    col_fecha:\"fecha_evento\",\n",
        "    col_hecho:\"razones_paro\",\n",
        "    col_tipo:\"tipo_movilizacion\",\n",
        "    col_conv:\"organizaciones_sindicales\",\n",
        "    col_ubic:\"region\",\n",
        "    col_dias:\"duracion_dias\"\n",
        "}).copy()\n",
        "\n",
        "std = [\"fecha_evento\",\"region\",\"organizaciones_sindicales\",\"tipo_movilizacion\",\n",
        "       \"duracion_dias\",\"razones_paro\",\"resumen\",\"titulo_ref\",\"urls\",\"fuentes_presentes\"]\n",
        "sed_final = ensure_cols(sed_final, std)\n",
        "sed_final[\"resumen\"] = sed_final[\"razones_paro\"]\n",
        "sed_final[\"titulo_ref\"] = sed_final[\"razones_paro\"].astype(str).str[:90]\n",
        "sed_final[\"fuentes_presentes\"] = \"SED\"\n",
        "\n",
        "col_url_sed = get_col(sed, [\"medio de verificacion\",\"url\",\"enlace\"])\n",
        "sed_final[\"urls\"] = sed[col_url_sed] if col_url_sed else np.nan\n",
        "\n",
        "# ================================================================\n",
        "#  BASE WEB\n",
        "# ================================================================\n",
        "web_final = web.rename(columns={\"fecha_paro\":\"fecha_evento\",\"ubicacion\":\"region\"}).copy()\n",
        "web_final = ensure_cols(web_final, std)\n",
        "web_final[\"fuentes_presentes\"] = \"WEB\"\n",
        "if \"url\" in web_final.columns: web_final[\"urls\"] = web_final[\"url\"]\n",
        "if \"titulo\" in web_final.columns: web_final[\"titulo_ref\"] = web_final[\"titulo\"]\n",
        "\n",
        "# ================================================================\n",
        "#  BASE BQ\n",
        "# ================================================================\n",
        "\n",
        "# Normalizar encabezados\n",
        "bq.columns = (\n",
        "    bq.columns.str.encode('utf-8').str.decode('utf-8', 'ignore')\n",
        "    .str.replace(\"ï»¿\", \"\", regex=False)\n",
        "    .str.strip()\n",
        "    .str.lower()\n",
        ")\n",
        "\n",
        "col_sqldate = [c for c in bq.columns if \"sqldate\" in c]\n",
        "col_url_bq = [c for c in bq.columns if \"sourceurl\" in c or \"url\" in c]\n",
        "col_region_bq = [c for c in bq.columns if \"actiongeo_fullname\" in c or \"region\" in c]\n",
        "\n",
        "if not col_sqldate:\n",
        "    raise ValueError(\"No se encontró la columna SQLDATE en la base BQ.\")\n",
        "col_sqldate = col_sqldate[0]\n",
        "col_url_bq = col_url_bq[0] if col_url_bq else None\n",
        "col_region_bq = col_region_bq[0] if col_region_bq else None\n",
        "\n",
        "def parse_fecha(f):\n",
        "    if pd.isna(f):\n",
        "        return pd.NaT\n",
        "    f = str(f).strip()\n",
        "    for fmt in (\"%Y%m%d\", \"%d/%m/%Y\", \"%Y-%m-%d\"):\n",
        "        try:\n",
        "            return pd.to_datetime(f, format=fmt)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return pd.to_datetime(f, errors=\"coerce\")\n",
        "\n",
        "bq[\"fecha_evento\"] = bq[col_sqldate].apply(parse_fecha)\n",
        "\n",
        "# Crear DataFrame final con columnas estandarizadas\n",
        "bq_final = pd.DataFrame({\n",
        "    \"fecha_evento\": bq[\"fecha_evento\"],\n",
        "    \"urls\": bq[col_url_bq] if col_url_bq else np.nan,\n",
        "    \"region\": bq[col_region_bq] if col_region_bq else np.nan,\n",
        "    \"organizaciones_sindicales\": bq.get(\"organizaciones_sindicales\", np.nan),\n",
        "    \"tipo_movilizacion\": bq.get(\"tipo_movilizacion\", \"paro docente\"),\n",
        "    \"razones_paro\": bq.get(\"razones_paro\", np.nan),\n",
        "    \"resumen\": bq.get(\"resumen\", np.nan),\n",
        "    \"duracion_dias\": bq.get(\"duracion_dias\", np.nan),\n",
        "    \"titulo_ref\": bq.get(\"titulo\", np.nan)\n",
        "})\n",
        "\n",
        "bq_final = ensure_cols(bq_final, std)\n",
        "bq_final[\"fuentes_presentes\"] = \"BQ\"\n",
        "\n",
        "# ================================================================\n",
        "# ESTANDARIZAR LOCALIZACIÓN\n",
        "# ================================================================\n",
        "CIUDADES_CO = {\n",
        "    \"bogota\":\"Bogotá\",\"bogotá\":\"Bogotá\",\"medellin\":\"Medellín\",\"medellín\":\"Medellín\",\n",
        "    \"cali\":\"Cali\",\"barranquilla\":\"Barranquilla\",\"cartagena\":\"Cartagena\",\"pereira\":\"Pereira\",\n",
        "    \"armenia\":\"Armenia\",\"manizales\":\"Manizales\",\"bucaramanga\":\"Bucaramanga\",\"cucuta\":\"Cúcuta\",\n",
        "    \"cúcuta\":\"Cúcuta\",\"ibague\":\"Ibagué\",\"ibagué\":\"Ibagué\",\"villavicencio\":\"Villavicencio\",\n",
        "    \"santa marta\":\"Santa Marta\",\"monteria\":\"Montería\",\"neiva\":\"Neiva\",\"tunja\":\"Tunja\",\n",
        "    \"yopal\":\"Yopal\",\"pasto\":\"Pasto\",\"popayan\":\"Popayán\",\"riohacha\":\"Riohacha\",\"quibdo\":\"Quibdó\",\n",
        "    \"leticia\":\"Leticia\",\"mocoa\":\"Mocoa\"\n",
        "}\n",
        "\n",
        "def _clean(s):\n",
        "    if s is None or (isinstance(s,float) and pd.isna(s)): return \"\"\n",
        "    return str(s).strip()\n",
        "\n",
        "def parse_region_to_pais_ciudad(val):\n",
        "    v = _clean(val)\n",
        "    if v == \"\" or v.upper() in {\"S/I\",\"S. I.\",\"NA\",\"N/A\"}:\n",
        "        return (\"Colombia\",\"\")\n",
        "    if \"colombia\" in v.lower():\n",
        "        partes = [p.strip() for p in re.split(r\",\", v) if p.strip()]\n",
        "        if len(partes) >= 2:\n",
        "            return (\"Colombia\", CIUDADES_CO.get(partes[0].lower(), partes[0]))\n",
        "    for k, pretty in CIUDADES_CO.items():\n",
        "        if re.search(rf\"\\b{k}\\b\", v.lower()):\n",
        "            return (\"Colombia\", pretty)\n",
        "    return (\"Colombia\", v[:80])\n",
        "\n",
        "def add_pais_ciudad(df):\n",
        "    p, c = zip(*df[\"region\"].apply(parse_region_to_pais_ciudad))\n",
        "    df[\"pais\"], df[\"ciudad\"] = p, c\n",
        "    return df\n",
        "\n",
        "sed_final = add_pais_ciudad(sed_final)\n",
        "web_final = add_pais_ciudad(web_final)\n",
        "bq_final  = add_pais_ciudad(bq_final)\n",
        "\n",
        "# ================================================================\n",
        "#  UNIR BASES\n",
        "# ================================================================\n",
        "cols_union = [\"fecha_evento\",\"pais\",\"ciudad\",\"organizaciones_sindicales\",\"tipo_movilizacion\",\n",
        "              \"duracion_dias\",\"razones_paro\",\"resumen\",\"titulo_ref\",\"urls\",\"fuentes_presentes\",\"region\"]\n",
        "\n",
        "for df in [sed_final, web_final, bq_final]:\n",
        "    for c in cols_union:\n",
        "        if c not in df.columns: df[c] = np.nan\n",
        "\n",
        "base = pd.concat([sed_final[cols_union], web_final[cols_union], bq_final[cols_union]], ignore_index=True)\n",
        "base = base.sort_values([\"fecha_evento\",\"ciudad\"]).reset_index(drop=True)\n",
        "\n",
        "# ================================================================\n",
        "# UNIFICAR Y LIMPIAR ORGANIZACIONES SINDICALES\n",
        "# ================================================================\n",
        "def estandarizar_orgs(valor):\n",
        "    \"\"\"Limpia, normaliza y unifica nombres de sindicatos.\"\"\"\n",
        "    if pd.isna(valor):\n",
        "        return \"NO ESPECÍFICA\"\n",
        "\n",
        "    if isinstance(valor, (list, tuple, set)):\n",
        "        texto = \" | \".join(map(str, valor))\n",
        "    else:\n",
        "        texto = str(valor)\n",
        "\n",
        "    texto = re.sub(r\"[\\[\\]'\\\"{}]\", \"\", texto).upper()\n",
        "    partes = re.split(r\"[;|,/\\-]+\", texto)\n",
        "    partes = [p.strip() for p in partes if p.strip()]\n",
        "    if not partes:\n",
        "        return \"NO ESPECÍFICA\"\n",
        "\n",
        "    equivalencias = {\n",
        "        \"FEDERACION COLOMBIANA DE TRABAJADORES DE LA EDUCACION\": \"FECODE\",\n",
        "        \"FECODE\": \"FECODE\",\n",
        "        \"ADE\": \"ADE\",\n",
        "        \"ADIDA\": \"ADIDA\",\n",
        "        \"CUT\": \"CUT\",\n",
        "        \"CENTRAL UNITARIA DE TRABAJADORES\": \"CUT\",\n",
        "        \"CENTRAL UNITARIA DE TRABAJADORES DE COLOMBIA\": \"CUT\",\n",
        "        \"CONFEDERACION DE TRABAJADORES DE COLOMBIA\": \"CTC\",\n",
        "        \"CTC\": \"CTC\",\n",
        "        \"CGT\": \"CGT\",\n",
        "        \"CONFEDERACION GENERAL DEL TRABAJO\": \"CGT\",\n",
        "        \"SINTRANAL\": \"SINTRANAL\",\n",
        "        \"SINTRANAL EDU\": \"SINTRANAL\",\n",
        "        \"NO ESPECIFICA\": \"NO ESPECÍFICA\",\n",
        "        \"NO ESPECÍFICA\": \"NO ESPECÍFICA\"\n",
        "    }\n",
        "\n",
        "    normalizados = []\n",
        "    for p in partes:\n",
        "        p_clean = re.sub(r\"[^A-ZÁÉÍÓÚÜÑ ]\", \"\", p).strip()\n",
        "        for k, v in equivalencias.items():\n",
        "            if k in p_clean:\n",
        "                normalizados.append(v)\n",
        "                break\n",
        "        else:\n",
        "            normalizados.append(p_clean)\n",
        "\n",
        "    limpio = [x for x in sorted(set(normalizados)) if x]\n",
        "    if not limpio:\n",
        "        return \"NO ESPECÍFICA\"\n",
        "    return \" | \".join(limpio)\n",
        "\n",
        "base[\"organizaciones_sindicales\"] = base[\"organizaciones_sindicales\"].apply(estandarizar_orgs)\n",
        "\n",
        "# ================================================================\n",
        "# ESTADÍSTICAS DESCRIPTIVAS\n",
        "# ================================================================\n",
        "stats = {\n",
        "    \"Total_paros\": len(base),\n",
        "    \"Promedio_duracion\": round(base[\"duracion_dias\"].mean(skipna=True), 2),\n",
        "    \"Max_duracion\": base[\"duracion_dias\"].max(),\n",
        "    \"Min_duracion\": base[\"duracion_dias\"].min(),\n",
        "    \"Tipos_movilizacion\": base[\"tipo_movilizacion\"].value_counts().to_dict(),\n",
        "    \"Ciudades_principales\": base[\"ciudad\"].value_counts().head(5).to_dict(),\n",
        "    \"Sindicatos_principales\": base[\"organizaciones_sindicales\"].value_counts().head(5).to_dict(),\n",
        "    \"Fuentes\": base[\"fuentes_presentes\"].value_counts().to_dict()\n",
        "}\n",
        "pd.DataFrame([stats]).to_csv(\"ESTADISTICAS_PAROS_DOCENTES_2023.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "# ================================================================\n",
        "# EXPORTAR BASE FINAL\n",
        "# ================================================================\n",
        "cols_export = [\"fecha_evento\",\"pais\",\"ciudad\",\"organizaciones_sindicales\",\"tipo_movilizacion\",\n",
        "               \"duracion_dias\",\"razones_paro\",\"resumen\",\"titulo_ref\",\"urls\",\"fuentes_presentes\"]\n",
        "base[\"fecha_evento\"] = pd.to_datetime(base[\"fecha_evento\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
        "base[cols_export].to_csv(\"BASE_FINAL_PAROS_DOCENTES_2023_VALIDADA.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"\\n✅ BASE_FINAL_PAROS_DOCENTES_2023_VALIDADA.csv generada correctamente\")\n",
        "print(\"\\nResumen general:\")\n",
        "for k, v in stats.items():\n",
        "    print(f\"- {k}: {v}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrbHGmGi8XnK",
        "outputId": "ad74c8bb-fc70-49ea-e031-9d5c7b05e160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ BASE_FINAL_PAROS_DOCENTES_2023_VALIDADA.csv generada correctamente\n",
            "\n",
            "Resumen general:\n",
            "- Total_paros: 55\n",
            "- Promedio_duracion: 1.44\n",
            "- Max_duracion: 5.0\n",
            "- Min_duracion: 1.0\n",
            "- Tipos_movilizacion: {'paro docente': 37, 'Plantón': 7, 'Paro': 5, 'paro estudiantil': 2, 'Toma': 2, 'Marcha': 1, 'Sin evidencia': 1}\n",
            "- Ciudades_principales: {\"{'pais': 'Colombia'\": 33, 'Plazoleta SED': 4, 'Colombia': 3, 'Bogotá': 1, 'Cl. 127c #9-89': 1}\n",
            "- Sindicatos_principales: {'FECODE': 17, 'NO ESPECÍFICA': 12, 'ADE': 10, 'ADE | FECODE': 5, 'CUT | FECODE': 4}\n",
            "- Fuentes: {'WEB': 33, 'SED': 16, 'BQ': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ================================================================\n",
        "# CARGA DE BASE FINAL\n",
        "# ================================================================\n",
        "df = pd.read_csv(\"BASE_FINAL_PAROS_DOCENTES_2023_VALIDADA.csv\", encoding=\"utf-8-sig\")\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# ================================================================\n",
        "# FUNCIONES AUXILIARES\n",
        "# ================================================================\n",
        "def limpiar_texto(texto):\n",
        "    if pd.isna(texto):\n",
        "        return \"\"\n",
        "    return re.sub(r\"\\s+\", \" \", str(texto)).strip()\n",
        "\n",
        "def obtener_contenido_web(url):\n",
        "    \"\"\"Extrae el texto de la página si la URL es válida.\"\"\"\n",
        "    if not isinstance(url, str) or url.strip() in [\"\", \"S/I\", \"s/i\", \"N/A\"]:\n",
        "        return \"\"\n",
        "    try:\n",
        "        r = requests.get(url, timeout=15)\n",
        "        if r.status_code != 200:\n",
        "            return \"\"\n",
        "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
        "        for tag in soup([\"script\", \"style\", \"noscript\", \"footer\", \"header\", \"aside\"]):\n",
        "            tag.extract()\n",
        "        texto = \" \".join(soup.stripped_strings)\n",
        "        return texto[:8000]\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "# ================================================================\n",
        "# IA: COMPLETAR DATOS FALTANTES (solo SED y BQ)\n",
        "# ================================================================\n",
        "def analizar_noticia_ia(fila):\n",
        "    \"\"\"Usa GPT-4o para estandarizar y completar información de una noticia.\"\"\"\n",
        "    url = fila.get(\"urls\", \"\")\n",
        "    titulo = fila.get(\"titulo_ref\", \"\")\n",
        "    texto = obtener_contenido_web(url)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "Estandariza y completa la información de una noticia sobre paros docentes en Colombia.\n",
        "\n",
        "Entrada:\n",
        "Título: {titulo}\n",
        "Texto de la noticia: {texto[:1500]}\n",
        "\n",
        "Devuelve un JSON válido con las siguientes claves:\n",
        "{{\n",
        "  \"pais\": \"Colombia\",\n",
        "  \"ciudad\": \"nombre de la ciudad (si se menciona o vacía si no)\",\n",
        "  \"organizaciones_sindicales\": [\"nombres de sindicatos mencionados\"],\n",
        "  \"tipo_movilizacion\": \"paro docente / plantón / marcha / toma / protesta / asamblea\",\n",
        "  \"duracion_dias\": número o null,\n",
        "  \"razones_paro\": \"resumen breve de motivos (salud, reformas, infraestructura, etc.)\",\n",
        "  \"resumen\": \"síntesis breve del hecho (máximo 3 líneas)\"\n",
        "}}\n",
        "Si la información no está explícita, infiere con contexto general sobre paros docentes en Colombia.\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            temperature=0.2,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        )\n",
        "        salida = response.choices[0].message.content.strip()\n",
        "\n",
        "        try:\n",
        "            datos = json.loads(salida)\n",
        "        except:\n",
        "            match = re.search(r\"\\{.*\\}\", salida, re.DOTALL)\n",
        "            datos = json.loads(match.group(0)) if match else {}\n",
        "\n",
        "        return datos\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error IA: {e}\")\n",
        "        return {\n",
        "            \"pais\": \"Colombia\",\n",
        "            \"ciudad\": \"\",\n",
        "            \"organizaciones_sindicales\": [],\n",
        "            \"tipo_movilizacion\": \"\",\n",
        "            \"duracion_dias\": None,\n",
        "            \"razones_paro\": \"\",\n",
        "            \"resumen\": \"\"\n",
        "        }\n",
        "\n",
        "# ================================================================\n",
        "# FILTRAR SOLO LAS FUENTES SED Y BQ PARA IA\n",
        "# ================================================================\n",
        "df[\"fuentes_presentes\"] = df[\"fuentes_presentes\"].astype(str).str.upper().str.strip()\n",
        "\n",
        "mask_ia = df[\"fuentes_presentes\"].isin([\"SED\", \"BQ\"])\n",
        "df_sin_ia = df[~mask_ia].copy()\n",
        "df_con_ia = df[mask_ia].copy()\n",
        "\n",
        "print(f\"Noticias a analizar con IA: {len(df_con_ia)} de {len(df)} totales\")\n",
        "\n",
        "# ================================================================\n",
        "# PROCESAR SOLO SED Y BQ CON IA\n",
        "# ================================================================\n",
        "resultados_ia = []\n",
        "\n",
        "for i, fila in enumerate(df_con_ia.to_dict(\"records\")):\n",
        "    url = fila.get(\"urls\", \"\")\n",
        "    fuente = fila.get(\"fuentes_presentes\", \"\")\n",
        "    print(f\"[{i+1}/{len(df_con_ia)}] Fuente: {fuente} | URL: {url[:80]}\")\n",
        "\n",
        "    try:\n",
        "        analisis = analizar_noticia_ia(fila)\n",
        "        fila.update(analisis)\n",
        "        resultados_ia.append(fila)\n",
        "    except Exception as e:\n",
        "        print(f\"Error en fila {i+1}: {e}\")\n",
        "        resultados_ia.append(fila)\n",
        "\n",
        "    time.sleep(2)\n",
        "\n",
        "df_analizadas = pd.DataFrame(resultados_ia)\n",
        "\n",
        "# ================================================================\n",
        "# UNIR CON LAS DEMÁS NOTICIAS (WEB)\n",
        "# ================================================================\n",
        "df_ia = pd.concat([df_sin_ia, df_analizadas], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TerrAF5XA0fm",
        "outputId": "4c49f0fe-474c-48ba-9701-336cbbf15fba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noticias a analizar con IA: 22 de 55 totales\n",
            "[1/22] Fuente: SED | URL: S/I\n",
            "[2/22] Fuente: BQ | URL: https://pulsoslp.com.mx/mundo/maestros-de-colombia-protestan-frente-al-congreso-\n",
            "[3/22] Fuente: SED | URL: https://www.infobae.com/colombia/2023/03/13/fecode-anuncio-nuevo-paro-de-profeso\n",
            "[4/22] Fuente: SED | URL: S/I\n",
            "[5/22] Fuente: SED | URL: https://www.infobae.com/colombia/2023/03/13/fecode-anuncio-nuevo-paro-de-profeso\n",
            "[6/22] Fuente: BQ | URL: https://eldeber.com.bo/pais/maestros-protestan-dedicando-canciones-de-shakira-y-\n",
            "[7/22] Fuente: SED | URL: https://www.infobae.com/america/colombia/2022/11/03/paro-de-maestros-este-jueves\n",
            "[8/22] Fuente: SED | URL: https://www.infobae.com/colombia/2023/03/13/fecode-anuncio-nuevo-paro-de-profeso\n",
            "[9/22] Fuente: SED | URL: https://caracol.com.co/2023/03/27/protestas-en-bogota-el-28-y-29-de-marzo-2023-r\n",
            "[10/22] Fuente: SED | URL: S/I\n",
            "[11/22] Fuente: SED | URL: S/I\n",
            "[12/22] Fuente: SED | URL: https://www.radionacional.co/actualidad/politica/marchas-7-de-junio-2023-quienes\n",
            "[13/22] Fuente: SED | URL: S/I\n",
            "[14/22] Fuente: SED | URL: S/I\n",
            "[15/22] Fuente: SED | URL: https://caracol.com.co/2023/07/19/marchas-20-de-julio-en-colombia-razones-y-punt\n",
            "[16/22] Fuente: BQ | URL: https://www.larepublica.co/economia/fecode-convoco-un-paro-de-de-maestros-24-hor\n",
            "[17/22] Fuente: BQ | URL: https://www.infobae.com/colombia/2023/08/30/en-vivo-asi-avanza-la-nueva-jornada-\n",
            "[18/22] Fuente: BQ | URL: https://elpais.com/america-colombia/2023-08-30/los-viejos-y-nuevos-motivos-de-la\n",
            "[19/22] Fuente: SED | URL: https://www.elespectador.com/educacion/paro-de-fecode-de-este-miercoles-puntos-d\n",
            "[20/22] Fuente: BQ | URL: https://diariodelhuila.com/ahora-los-maestros/\n",
            "[21/22] Fuente: SED | URL: https://www.infobae.com/colombia/2023/09/27/fecode-se-unio-a-las-movilizaciones-\n",
            "[22/22] Fuente: SED | URL: S/I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ESTANDARIZAR ORGANIZACIONES SINDICALES\n",
        "# ================================================================\n",
        "def estandarizar_orgs(valor):\n",
        "    \"\"\"Estandariza nombres de sindicatos en formato único y consistente.\"\"\"\n",
        "    # Manejar valores vacíos, listas o arrays\n",
        "    if valor is None:\n",
        "        return \"\"\n",
        "    if isinstance(valor, (list, set, tuple)):\n",
        "        texto = \" \".join(map(str, valor))\n",
        "    elif isinstance(valor, (pd.Series, np.ndarray)):\n",
        "        texto = \" \".join(map(str, valor.tolist()))\n",
        "    else:\n",
        "        texto = str(valor)\n",
        "\n",
        "    texto = texto.strip()\n",
        "    if texto == \"\" or texto.upper() in [\"NAN\", \"NONE\"]:\n",
        "        return \"NO ESPECÍFICA\"\n",
        "\n",
        "    texto = re.sub(r\"[\\[\\]'\\\"{}]\", \"\", texto)\n",
        "    partes = re.split(r\"[;|,/\\-]+\", texto)\n",
        "    partes = [p.strip().upper() for p in partes if p.strip()]\n",
        "\n",
        "    equivalencias = {\n",
        "        \"ADE\": [\"ADE\", \"ASOCIACION DISTRITAL DE EDUCADORES\", \"ASOCIACIÓN DISTRITAL DE EDUCADORES\"],\n",
        "        \"FECODE\": [\"FECODE\", \"FEDERACION COLOMBIANA DE TRABAJADORES DE LA EDUCACION\", \"FEDERACIÓN COLOMBIANA DE TRABAJADORES DE LA EDUCACIÓN\"],\n",
        "        \"CUT\": [\"CUT\", \"CENTRAL UNITARIA DE TRABAJADORES\"],\n",
        "        \"CTC\": [\"CTC\", \"CONFEDERACION DE TRABAJADORES DE COLOMBIA\", \"CONFEDERACIÓN DE TRABAJADORES DE COLOMBIA\"],\n",
        "        \"SINTRANAL\": [\"SINTRANAL\", \"SINDICATO NACIONAL DE TRABAJADORES DE LA EDUCACION\", \"SINDICATO NACIONAL DE TRABAJADORES DE LA EDUCACIÓN\"],\n",
        "        \"ADIDA\": [\"ADIDA\", \"ASOCIACION DE INSTITUTO DE ANTIOQUIA\", \"ASOCIACIÓN DE INSTITUTO DE ANTIOQUIA\"]\n",
        "    }\n",
        "\n",
        "    normalizados = set()\n",
        "    for p in partes:\n",
        "        for clave, variantes in equivalencias.items():\n",
        "            if any(v in p for v in variantes):\n",
        "                normalizados.add(clave)\n",
        "                break\n",
        "        else:\n",
        "            if p and p not in [\"NO ESPECIFICA\", \"NO ESPECÍFICA\", \"NO APLICA\"]:\n",
        "                normalizados.add(p)\n",
        "\n",
        "    return \" | \".join(sorted(normalizados)) if normalizados else \"NO ESPECÍFICA\"\n",
        "\n",
        "\n",
        "df_ia[\"organizaciones_sindicales\"] = df_ia[\"organizaciones_sindicales\"].apply(estandarizar_orgs)\n",
        "\n",
        "# ================================================================\n",
        "# GUARDAR RESULTADO FINAL\n",
        "# ================================================================\n",
        "df_ia.to_csv(\"BASE_PAROS_DOCENTES_2023_IA.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Proceso completado correctamente.\")\n",
        "print(\"Archivo generado: BASE_PAROS_DOCENTES_2023_IA.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "bmu6oQN5CCb_",
        "outputId": "edd6b62d-1819-47c2-adc3-b05c33ad5036"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_ia' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2649917062.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mdf_ia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"organizaciones_sindicales\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_ia\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"organizaciones_sindicales\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestandarizar_orgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# ================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_ia' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# UNIFICAR PAROS DOCENTES 2023\n",
        "# ================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import timedelta\n",
        "\n",
        "# -----------------------------\n",
        "# 1. CARGAR BASE\n",
        "# -----------------------------\n",
        "df = pd.read_csv(\"BASE_PAROS_DOCENTES_2023_IA.csv\", encoding=\"utf-8-sig\")\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "if \"fecha_evento\" in df.columns:\n",
        "    df[\"fecha_evento\"] = pd.to_datetime(df[\"fecha_evento\"], errors=\"coerce\")\n",
        "\n",
        "df = df.dropna(subset=[\"fecha_evento\"]).sort_values(\"fecha_evento\").reset_index(drop=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 2. FUNCIONES AUXILIARES\n",
        "# -----------------------------\n",
        "def combinar_textos(series):\n",
        "    \"\"\"Combina textos o listas de textos sin duplicar información.\"\"\"\n",
        "    textos = []\n",
        "    for val in series.dropna():\n",
        "        if isinstance(val, str):\n",
        "            partes = re.split(r\"[|;]+\", val)\n",
        "            textos.extend([p.strip() for p in partes if p.strip()])\n",
        "        elif isinstance(val, (list, set, tuple)):\n",
        "            textos.extend([str(p).strip() for p in val if str(p).strip()])\n",
        "    return \"; \".join(sorted(set(textos)))\n",
        "\n",
        "def combinar_numeros(series):\n",
        "    \"\"\"Promedio de valores numéricos.\"\"\"\n",
        "    vals = pd.to_numeric(series, errors=\"coerce\")\n",
        "    return round(vals.mean(skipna=True), 1) if vals.notna().any() else np.nan\n",
        "\n",
        "def combinar_fuentes(series):\n",
        "    \"\"\"Une todas las fuentes sin repetir.\"\"\"\n",
        "    return \"; \".join(sorted(set(\n",
        "        re.split(r\"[;|,]+\", \";\".join(series.dropna().astype(str)))\n",
        "    )))\n",
        "\n",
        "def combinar_urls(series):\n",
        "    \"\"\"Combina todas las URLs únicas, creando columnas url_1, url_2, ...\"\"\"\n",
        "    urls = []\n",
        "    for val in series.dropna():\n",
        "        if isinstance(val, str):\n",
        "            for u in re.split(r\"[|,;]+\", val):\n",
        "                if u.strip() and u.strip().startswith(\"http\"):\n",
        "                    urls.append(u.strip())\n",
        "    return sorted(set(urls))\n",
        "\n",
        "# -----------------------------\n",
        "# 3. AGRUPAR POR FECHA CON TOLERANCIA DE ±2 DÍAS\n",
        "# -----------------------------\n",
        "# Ordenar por fecha\n",
        "df = df.sort_values(\"fecha_evento\").reset_index(drop=True)\n",
        "\n",
        "# Crear grupos de eventos cercanos (ventana de 2 días)\n",
        "grupos = []\n",
        "grupo_actual = 0\n",
        "fechas = df[\"fecha_evento\"].tolist()\n",
        "\n",
        "for i in range(len(fechas)):\n",
        "    if i == 0:\n",
        "        grupos.append(grupo_actual)\n",
        "        continue\n",
        "    diff = (fechas[i] - fechas[i - 1]).days\n",
        "    if diff <= 2:\n",
        "        grupos.append(grupo_actual)\n",
        "    else:\n",
        "        grupo_actual += 1\n",
        "        grupos.append(grupo_actual)\n",
        "\n",
        "df[\"grupo_paro\"] = grupos\n",
        "\n",
        "# -----------------------------\n",
        "# 4. FUSIONAR INFORMACIÓN POR GRUPO\n",
        "# -----------------------------\n",
        "agrupado = []\n",
        "for gid, sub in df.groupby(\"grupo_paro\"):\n",
        "    fila = {}\n",
        "    fila[\"fecha_inicio\"] = sub[\"fecha_evento\"].min()\n",
        "    fila[\"fecha_fin\"] = sub[\"fecha_evento\"].max()\n",
        "    fila[\"fecha_referencia\"] = fila[\"fecha_inicio\"].strftime(\"%Y-%m-%d\") if not pd.isna(fila[\"fecha_inicio\"]) else \"\"\n",
        "\n",
        "    fila[\"ciudad\"] = combinar_textos(sub.get(\"ciudad\", pd.Series([])))\n",
        "    fila[\"organizaciones_sindicales\"] = combinar_textos(sub.get(\"organizaciones_sindicales\", pd.Series([])))\n",
        "    fila[\"tipo_movilizacion\"] = combinar_textos(sub.get(\"tipo_movilizacion\", pd.Series([])))\n",
        "    fila[\"duracion_dias\"] = combinar_numeros(sub.get(\"duracion_dias\", pd.Series([])))\n",
        "    fila[\"razones_paro\"] = combinar_textos(sub.get(\"razones_paro\", pd.Series([])))\n",
        "    fila[\"resumen\"] = combinar_textos(sub.get(\"resumen\", pd.Series([])))\n",
        "    fila[\"fuentes_presentes\"] = combinar_fuentes(sub.get(\"fuentes_presentes\", pd.Series([])))\n",
        "\n",
        "    urls_unicas = combinar_urls(sub.get(\"urls\", pd.Series([])))\n",
        "    for i, url in enumerate(urls_unicas, start=1):\n",
        "        fila[f\"url_{i}\"] = url\n",
        "\n",
        "    agrupado.append(fila)\n",
        "\n",
        "base_unificada = pd.DataFrame(agrupado).sort_values(\"fecha_inicio\").reset_index(drop=True)\n",
        "\n",
        "# -----------------------------\n",
        "# 5. EXPORTAR RESULTADO\n",
        "# -----------------------------\n",
        "base_unificada[\"fecha_inicio\"] = pd.to_datetime(base_unificada[\"fecha_inicio\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
        "base_unificada[\"fecha_fin\"] = pd.to_datetime(base_unificada[\"fecha_fin\"], errors=\"coerce\").dt.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "base_unificada.to_csv(\"BASE_PAROS_UNIFICADOS_2023.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"Base unificada generada: BASE_PAROS_UNIFICADOS_2023.csv\")\n",
        "print(\"Paros únicos encontrados:\", len(base_unificada))\n",
        "print(\"Número máximo de columnas URL:\", base_unificada.filter(like='url_').shape[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C30UpnA82cPc",
        "outputId": "14f7db3a-5e73-4c87-d453-fd758e3d6c9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base unificada generada: BASE_PAROS_UNIFICADOS_2023.csv\n",
            "Paros únicos encontrados: 22\n",
            "Número máximo de columnas URL: 17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================\n",
        "# ESTADÍSTICAS BASE PAROS UNIFICADOS (\n",
        "# ================================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# ================================================================\n",
        "# 1. CARGAR BASE UNIFICADA\n",
        "# ================================================================\n",
        "base = pd.read_csv(\"BASE_PAROS_UNIFICADOS_2023.csv\", encoding=\"utf-8-sig\")\n",
        "base.columns = base.columns.str.strip().str.lower()\n",
        "\n",
        "# --- Fechas ---\n",
        "if \"fecha_inicio\" in base.columns:\n",
        "    base[\"fecha_inicio\"] = pd.to_datetime(base[\"fecha_inicio\"], errors=\"coerce\")\n",
        "if \"fecha_fin\" in base.columns:\n",
        "    base[\"fecha_fin\"] = pd.to_datetime(base[\"fecha_fin\"], errors=\"coerce\")\n",
        "\n",
        "# --- Duración calculada si falta ---\n",
        "if \"duracion_dias\" not in base.columns or base[\"duracion_dias\"].isna().all():\n",
        "    base[\"duracion_dias\"] = (base[\"fecha_fin\"] - base[\"fecha_inicio\"]).dt.days + 1\n",
        "\n",
        "# Asegurar valores positivos\n",
        "base[\"duracion_dias\"] = base[\"duracion_dias\"].clip(lower=1)\n",
        "\n",
        "# ================================================================\n",
        "# 2. LIMPIEZA Y PREPARACIÓN\n",
        "# ================================================================\n",
        "def limpiar_texto(x):\n",
        "    if pd.isna(x):\n",
        "        return \"\"\n",
        "    x = str(x).strip().lower()\n",
        "    x = re.sub(r\"[\\[\\]{}'\\\"]\", \"\", x)\n",
        "    return re.sub(r\"\\s+\", \" \", x).strip()\n",
        "\n",
        "base[\"tipo_movilizacion\"] = base[\"tipo_movilizacion\"].apply(limpiar_texto)\n",
        "base[\"organizaciones_sindicales\"] = base[\"organizaciones_sindicales\"].apply(limpiar_texto)\n",
        "base[\"fuentes_presentes\"] = base[\"fuentes_presentes\"].apply(limpiar_texto)\n",
        "\n",
        "# Mes de referencia según fecha_inicio\n",
        "base[\"mes\"] = base[\"fecha_inicio\"].dt.to_period(\"M\")\n",
        "\n",
        "# ================================================================\n",
        "# 3. ESTADÍSTICAS DESCRIPTIVAS\n",
        "# ================================================================\n",
        "print(\"\\nGenerando estadísticas descriptivas de paros unificados...\")\n",
        "\n",
        "# ---- 3.1 Total de paros por mes\n",
        "paros_mes = base[\"mes\"].value_counts().sort_index().reset_index()\n",
        "paros_mes.columns = [\"Mes\", \"Total_Paros\"]\n",
        "\n",
        "# ---- 3.2 Tipos de movilización\n",
        "tipos = (\n",
        "    base[\"tipo_movilizacion\"]\n",
        "    .str.split(r\"[;|,]+\")\n",
        "    .explode()\n",
        "    .str.strip()\n",
        "    .replace(\"\", np.nan)\n",
        "    .dropna()\n",
        "    .value_counts()\n",
        "    .reset_index()\n",
        ")\n",
        "tipos.columns = [\"Tipo de Movilización\", \"Total\"]\n",
        "\n",
        "# ---- 3.3 Duración promedio, mediana y rango\n",
        "base[\"duracion_dias\"] = pd.to_numeric(base[\"duracion_dias\"], errors=\"coerce\")\n",
        "duracion_stats = {\n",
        "    \"Promedio (días)\": round(base[\"duracion_dias\"].mean(skipna=True), 2),\n",
        "    \"Mediana (días)\": base[\"duracion_dias\"].median(skipna=True),\n",
        "    \"Máximo (días)\": base[\"duracion_dias\"].max(),\n",
        "    \"Mínimo (días)\": base[\"duracion_dias\"].min(),\n",
        "    \"Desviación estándar\": round(base[\"duracion_dias\"].std(skipna=True), 2)\n",
        "}\n",
        "\n",
        "# ---- 3.4 Organizaciones sindicales\n",
        "def limpiar_orgs(x):\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        parts = re.split(r\"[,;|]+\", x)\n",
        "        return [p.strip().upper() for p in parts if p.strip()]\n",
        "    return []\n",
        "\n",
        "orgs = (\n",
        "    base[\"organizaciones_sindicales\"]\n",
        "    .apply(limpiar_orgs)\n",
        "    .explode()\n",
        "    .value_counts()\n",
        "    .head(15)\n",
        "    .reset_index()\n",
        ")\n",
        "orgs.columns = [\"Organización Sindical\", \"Frecuencia\"]\n",
        "\n",
        "# ---- 3.5 Fuentes más comunes\n",
        "def limpiar_fuentes(x):\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    if isinstance(x, str):\n",
        "        return [f.strip().upper() for f in re.split(r\"[,;|]+\", x) if f.strip()]\n",
        "    return []\n",
        "\n",
        "fuentes = (\n",
        "    base[\"fuentes_presentes\"]\n",
        "    .apply(limpiar_fuentes)\n",
        "    .explode()\n",
        "    .value_counts()\n",
        "    .reset_index()\n",
        ")\n",
        "fuentes.columns = [\"Fuente\", \"Total_Paros\"]\n",
        "\n",
        "# ---- 3.6 Rango de fechas analizado\n",
        "rango_fechas = {\n",
        "    \"Fecha más antigua\": base[\"fecha_inicio\"].min().strftime(\"%Y-%m-%d\"),\n",
        "    \"Fecha más reciente\": base[\"fecha_fin\"].max().strftime(\"%Y-%m-%d\"),\n",
        "    \"Total paros\": len(base)\n",
        "}\n",
        "\n",
        "# ================================================================\n",
        "# 4. EXPORTAR RESULTADOS\n",
        "# ================================================================\n",
        "with pd.ExcelWriter(\"Estadisticas_Paros_Unificados_2023.xlsx\", engine=\"openpyxl\") as writer:\n",
        "    paros_mes.to_excel(writer, sheet_name=\"Paros por Mes\", index=False)\n",
        "    tipos.to_excel(writer, sheet_name=\"Tipos de Movilización\", index=False)\n",
        "    orgs.to_excel(writer, sheet_name=\"Organizaciones\", index=False)\n",
        "    fuentes.to_excel(writer, sheet_name=\"Fuentes\", index=False)\n",
        "    pd.DataFrame([duracion_stats]).to_excel(writer, sheet_name=\"Duración\", index=False)\n",
        "    pd.DataFrame([rango_fechas]).to_excel(writer, sheet_name=\"Resumen General\", index=False)\n",
        "\n",
        "# ================================================================\n",
        "# 5. RESUMEN EN CONSOLA\n",
        "# ================================================================\n",
        "print(\"\\nResumen rápido:\")\n",
        "print(f\"Total de paros únicos: {len(base)}\")\n",
        "print(f\"Meses con paros: {base['mes'].nunique()}\")\n",
        "print(f\"Promedio de duración: {duracion_stats['Promedio (días)']} días\")\n",
        "print(f\"Rango de fechas: {rango_fechas['Fecha más antigua']} → {rango_fechas['Fecha más reciente']}\")\n",
        "\n",
        "print(\"\\nArchivo generado: Estadisticas_Paros_Unificados_2023.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLPEnynp3aN2",
        "outputId": "184c85e5-d48c-4d3a-d6ed-d57e80493680"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generando estadísticas descriptivas de paros unificados...\n",
            "\n",
            "Resumen rápido:\n",
            "Total de paros únicos: 22\n",
            "Meses con paros: 10\n",
            "Promedio de duración: 1.97 días\n",
            "Rango de fechas: 2023-01-18 → 2023-11-29\n",
            "\n",
            "Archivo generado: Estadisticas_Paros_Unificados_2023.xlsx\n"
          ]
        }
      ]
    }
  ]
}