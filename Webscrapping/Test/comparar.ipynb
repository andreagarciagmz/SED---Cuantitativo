{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip  install pandas\n",
        "!pip  install numpy\n",
        "!pip  install datetime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMF9PrGneH1b",
        "outputId": "9a5fad3b-15a4-4eff-cbf4-212d9d666741"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: datetime in /usr/local/lib/python3.12/dist-packages (5.5)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.12/dist-packages (from datetime) (8.0.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.12/dist-packages (from datetime) (2025.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# COMPARACI√ìN MULTIFUENTE: PARO DOCENTE 2023\n",
        "# Webscraping (web) vs SGI vs BigQuery (bq)\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "#  CARGA DE DATOS\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "import pandas as pd\n",
        "\n",
        "web = pd.read_csv(\"noticias_paros_docentes_2023_ANALIZADO (1).csv\", encoding=\"utf-8\", low_memory=False)\n",
        "bq  = pd.read_csv(\"bq-results-20251023-000630-1761178021663.csv\", encoding=\"utf-8\", low_memory=False)\n",
        "sgi = pd.read_excel(\"Base SGI suspensi√≥n clases 2012-2025 03_08_2025_VALIDACION SED.xlsx\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# üßπ 3. Normalizar nombres de columnas\n",
        "# ===============================\n",
        "for df in [web, bq, sgi]:\n",
        "    df.columns = df.columns.str.lower().str.strip()\n",
        "\n",
        "# Crear columna de fuente\n",
        "web[\"fuente\"] = \"web\"\n",
        "bq[\"fuente\"] = \"bq\"\n",
        "sgi[\"fuente\"] = \"sgi\"\n",
        "\n",
        "# ===============================\n",
        "# üîó 4. Crear columna 'url_limpia' (para evitar duplicados)\n",
        "# ===============================\n",
        "for df in [web, bq, sgi]:\n",
        "    if \"url\" in df.columns:\n",
        "        df[\"url_limpia\"] = df[\"url\"].astype(str).str.split(\"&ved=\").str[0].str.strip()\n",
        "    else:\n",
        "        df[\"url_limpia\"] = None\n",
        "\n",
        "# ===============================\n",
        "# üîç 5. Filtrar solo noticias relacionadas con paro docente\n",
        "# ===============================\n",
        "palabras_clave = \"paro docente|fecode|maestro|profesor|docente|paros de docentes|huelga de maestros\"\n",
        "\n",
        "def filtrar_paro(df):\n",
        "    texto = df.astype(str).apply(lambda x: \" \".join(x), axis=1).str.lower()\n",
        "    return df[texto.str.contains(palabras_clave, na=False)]\n",
        "\n",
        "web_fil = filtrar_paro(web)\n",
        "bq_fil  = filtrar_paro(bq)\n",
        "sgi_fil = filtrar_paro(sgi)\n",
        "\n",
        "# ===============================\n",
        "# üö´ 6. Quitar duplicados (por URL limpia)\n",
        "# ===============================\n",
        "urls_existentes = set(web_fil[\"url_limpia\"].dropna())\n",
        "bq_nuevas  = bq_fil[~bq_fil[\"url_limpia\"].isin(urls_existentes)]\n",
        "sgi_nuevas = sgi_fil[~sgi_fil[\"url_limpia\"].isin(urls_existentes)]\n",
        "\n",
        "# ===============================\n",
        "# üîÄ 7. Unir todo en una sola base\n",
        "# ===============================\n",
        "noticias_consolidada = pd.concat([web_fil, bq_nuevas, sgi_nuevas], ignore_index=True)\n",
        "\n",
        "# ===============================\n",
        "# üíæ 8. Exportar\n",
        "# ===============================\n",
        "noticias_consolidada.to_csv(\"noticias_paro_docente_consolidada.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"‚úÖ Base consolidada creada correctamente\")\n",
        "print(f\"Total de noticias: {len(noticias_consolidada)}\")\n",
        "print(f\"Nuevas de BQ: {len(bq_nuevas)} | Nuevas de SGI: {len(sgi_nuevas)}\")\n",
        "print(f\"Archivo guardado en:\\n{output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZw794SiezWB",
        "outputId": "fcd12899-a098-48a2-9fda-714ca2016c26"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Base consolidada creada correctamente\n",
            "Total de noticias: 755\n",
            "Nuevas de BQ: 532 | Nuevas de SGI: 66\n",
            "Archivo guardado en:\n",
            "C:/Users/angel/Documents/GitHub/SED---Cuantitativo/Webscrapping/Datos/noticias_paro_docente_consolidada.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# üìÇ 1Ô∏è‚É£ CARGAR ARCHIVOS\n",
        "# ============================================================\n",
        "# Archivos: base consolidada y base de referencia (formato original)\n",
        "consolidada_path = \"noticias_paro_docente_consolidada.csv\"\n",
        "referencia_path  = \"noticias_paros_docentes_2023_ANALIZADO (1).csv\"\n",
        "\n",
        "# Leer archivos\n",
        "df = pd.read_csv(consolidada_path, encoding=\"utf-8\", low_memory=False)\n",
        "ref = pd.read_csv(referencia_path, encoding=\"utf-8\", low_memory=False)\n",
        "\n",
        "print(f\"‚úÖ Base consolidada: {df.shape[0]} filas\")\n",
        "print(f\"‚úÖ Base de referencia: {ref.shape[0]} filas\")\n",
        "\n",
        "# ============================================================\n",
        "# üßπ 2Ô∏è‚É£ FILTRAR SOLO NOTICIAS DEL 2023\n",
        "# ============================================================\n",
        "# Crear columna combinada de texto para buscar \"2023\"\n",
        "df[\"texto_completo\"] = df.astype(str).apply(lambda x: \" \".join(x), axis=1).str.lower()\n",
        "\n",
        "# Filtrar solo aquellas que mencionan \"2023\"\n",
        "df_2023 = df[df[\"texto_completo\"].str.contains(\"2023\", na=False)].copy()\n",
        "\n",
        "print(f\"üóìÔ∏è Noticias con a√±o 2023: {len(df_2023)}\")\n",
        "\n",
        "# ============================================================\n",
        "# üö´ 3Ô∏è‚É£ ELIMINAR DUPLICADOS (por URL o t√≠tulo)\n",
        "# ============================================================\n",
        "# Crear columna de URL limpia (eliminar par√°metros de Google)\n",
        "if \"url\" in df_2023.columns:\n",
        "    df_2023[\"url_limpia\"] = df_2023[\"url\"].astype(str).str.split(\"&ved=\").str[0].str.strip()\n",
        "else:\n",
        "    df_2023[\"url_limpia\"] = None\n",
        "\n",
        "# Eliminar duplicados por URL o t√≠tulo si existen\n",
        "cols_dup = [c for c in [\"url_limpia\", \"titulo\", \"title\"] if c in df_2023.columns]\n",
        "df_sin_dup = df_2023.drop_duplicates(subset=cols_dup, keep=\"first\")\n",
        "\n",
        "print(f\"üßæ Noticias sin duplicados: {len(df_sin_dup)}\")\n",
        "\n",
        "# ============================================================\n",
        "# üß© 4Ô∏è‚É£ IGUALAR ESTRUCTURA AL ARCHIVO \"ANALIZADO\"\n",
        "# ============================================================\n",
        "# Usar las columnas del archivo de referencia\n",
        "cols_ref = ref.columns\n",
        "df_final = df_sin_dup.reindex(columns=cols_ref, fill_value=None)\n",
        "\n",
        "print(f\"üìã Columnas igualadas: {len(cols_ref)} columnas\")\n",
        "\n",
        "# ============================================================\n",
        "# üíæ 5Ô∏è‚É£ GUARDAR RESULTADO FINAL\n",
        "# ============================================================\n",
        "output_path = \"noticias_paro_docente_2023_limpias.csv\"\n",
        "df_final.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
        "\n",
        "print(\"‚úÖ LIMPIEZA FINAL COMPLETADA\")\n",
        "print(f\"Archivo guardado como: {output_path}\")\n",
        "print(f\"Filas finales: {len(df_final)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUXBUjTDsNmx",
        "outputId": "f9805ba8-9af3-456a-dc79-40ed5a90b538"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Base consolidada: 755 filas\n",
            "‚úÖ Base de referencia: 161 filas\n",
            "üóìÔ∏è Noticias con a√±o 2023: 178\n",
            "üßæ Noticias sin duplicados: 123\n",
            "üìã Columnas igualadas: 21 columnas\n",
            "‚úÖ LIMPIEZA FINAL COMPLETADA\n",
            "Archivo guardado como: noticias_paro_docente_2023_limpias.csv\n",
            "Filas finales: 123\n"
          ]
        }
      ]
    }
  ]
}