{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cU_UYmRzPDz8",
    "outputId": "dc89d3ea-8f9e-41c9-e0e8-b7b3423f08df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n",
      "Collecting newspaper3k\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (4.13.5)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (11.3.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (6.0.3)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (5.4.0)\n",
      "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.32.4)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Downloading tldextract-5.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from newspaper3k) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (4.15.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.17.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (8.3.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.2.1->newspaper3k) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->newspaper3k) (2025.10.5)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Downloading requests_file-3.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.20.0)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cssselect-1.3.0-py3-none-any.whl (18 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tldextract-5.3.0-py3-none-any.whl (107 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.4/107.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_file-3.0.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=997db7e1a381de4bec567420045f8f023ac49063edb6d6a7f18c330c2bf09609\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/91/9f/00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=4746e266bd0ba6e20727cbd9ec3dad6b81abf06f09b8402053c56b3ceaaf9e15\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/9f/fb/364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398380 sha256=822bcad6cc44187dae77fa09c3fa0a2c826c7b49ee6a2526155f3e43558e6a35\n",
      "  Stored in directory: /root/.cache/pip/wheels/26/72/f7/fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=e33efaa6e9b6fbf2c03f1f2dc23aaba1dfec9cd317b3615afcb49c254f1ff4b7\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/f5/1a/23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, cssselect, requests-file, feedfinder2, tldextract, newspaper3k\n",
      "Successfully installed cssselect-1.3.0 feedfinder2-0.0.4 feedparser-6.0.12 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-3.0.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.3.0\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.37.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio<1.0,>=0.31.0 (from selenium)\n",
      "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n",
      "Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n",
      "Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
      "Downloading selenium-4.37.0-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 selenium-4.37.0 trio-0.31.0 trio-websocket-0.12.2 wsproto-1.2.0\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Collecting serpapi\n",
      "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from serpapi) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->serpapi) (2025.10.5)\n",
      "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: serpapi\n",
      "Successfully installed serpapi-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install newspaper3k\n",
    "!pip install selenium\n",
    "!pip install openai\n",
    "!pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L9YdtWfhPD0A",
    "outputId": "d548e3b9-730e-4115-89d6-5aaaa02ed9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googlesearch-python\n",
      "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (4.13.5)\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.12/dist-packages (from googlesearch-python) (2.32.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.20->googlesearch-python) (2025.10.5)\n",
      "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
      "Installing collected packages: googlesearch-python\n",
      "Successfully installed googlesearch-python-1.3.0\n",
      "Collecting google-search-results\n",
      "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.10.5)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=c1fc48a2f0c30a3c6fdc9a477e8914209d9be8a43decc2c4d230cd6aa7cbc58a\n",
      "  Stored in directory: /root/.cache/pip/wheels/0c/47/f5/89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install googlesearch-python\n",
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cSrbztgPD0A",
    "outputId": "eb1c2818-e4e6-430f-c71c-0f613749d87f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in /usr/local/lib/python3.12/dist-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from google-search-results) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->google-search-results) (2025.10.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDMSKiNoPD0B",
    "outputId": "2f6478c3-871a-4e24-e9db-6ec449356bd8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: httpx[http2] in /usr/local/lib/python3.12/dist-packages (0.28.1)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.11.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (3.11)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]) (4.3.0)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx[http2]) (0.16.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]) (4.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx[http2]) (4.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"httpx[http2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FlwTheyPD0B",
    "outputId": "3f0484d1-0c16-489d-bcad-756ff7023707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.12/dist-packages (5.4.0)\n",
      "Collecting lxml_html_clean (from lxml[html_clean])\n",
      "  Downloading lxml_html_clean-0.4.3-py3-none-any.whl.metadata (2.3 kB)\n",
      "Downloading lxml_html_clean-0.4.3-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: lxml_html_clean\n",
      "Successfully installed lxml_html_clean-0.4.3\n"
     ]
    }
   ],
   "source": [
    "# Instala el extra necesario para newspaper3k\n",
    "!pip install \"lxml[html_clean]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LNDVaz84PD0C",
    "outputId": "8873384a-890c-4172-9419-7cda35bb9834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GoogleNews\n",
      "  Downloading GoogleNews-1.6.15-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (4.13.5)\n",
      "Collecting dateparser (from GoogleNews)\n",
      "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from GoogleNews) (2.9.0.post0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (2.8)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->GoogleNews) (4.15.0)\n",
      "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2025.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (2024.11.6)\n",
      "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->GoogleNews) (5.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil->GoogleNews) (1.17.0)\n",
      "Downloading GoogleNews-1.6.15-py3-none-any.whl (8.8 kB)\n",
      "Downloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dateparser, GoogleNews\n",
      "Successfully installed GoogleNews-1.6.15 dateparser-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install GoogleNews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "W_1J1C0vCTj9"
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "hcb8wmZkPD0C"
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Librerías estándar (de Python) ---\n",
    "import os  # Acceso a funcionalidades del sistema operativo (rutas, variables de entorno, etc.)\n",
    "import re  # Permite trabajar con expresiones regulares (búsqueda de patrones en texto)\n",
    "import time  # Funciones relacionadas con el tiempo (pausas, medir duración, timestamps)\n",
    "import json  # Para trabajar con archivos y datos en formato JSON\n",
    "import tempfile  # Crear archivos/directorios temporales (útil para manejo temporal de datos)\n",
    "from typing import Dict, List  # Anotaciones de tipo para funciones (mejor legibilidad y autocompletado)\n",
    "from pathlib import Path  # Manejo de rutas de archivos y carpetas de forma más moderna y robusta\n",
    "from GoogleNews import GoogleNews\n",
    "\n",
    "# --- Librerías externas (instaladas con pip) ---\n",
    "import pandas as pd  # Análisis y manipulación de datos tabulares (Excel, CSV, DataFrames, etc.)\n",
    "\n",
    "import openpyxl  # Librería para leer y escribir archivos Excel (.xlsx)\n",
    "from openpyxl import load_workbook  # Cargar y modificar libros de Excel ya existentes\n",
    "\n",
    "import requests  # Realizar peticiones HTTP (GET, POST, etc.) para acceder a contenido web o APIs\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "from bs4 import BeautifulSoup  # Analizar y extraer información de HTML (web scraping)\n",
    "\n",
    "from newspaper import Article  # Extraer automáticamente información estructurada de artículos web (título, texto, etc.)\n",
    "\n",
    "from selenium import webdriver  # Controlar un navegador web desde Python (automatización para scraping dinámico)\n",
    "from selenium.webdriver.chrome.options import Options  # Configurar opciones para Chrome (modo sin cabeza, user-agent, etc.)\n",
    "\n",
    "import openai  # Cliente oficial para acceder a la API de OpenAI (ChatGPT, GPT-4, etc.)\n",
    "\n",
    "#from src.tokens_por_posicion import token_at\n",
    "\n",
    "#from serpapi import GoogleSearch  # Realizar búsquedas en Google a través de la API de SerpAPI (scraping sin bloquearse)\n",
    "\n",
    "# --- Módulos locales del proyecto ---\n",
    "#from src.functions import completar, _debug_api_key_openai\n",
    "# completar: función personalizada (probablemente genera texto con GPT u otra IA)\n",
    "# _debug_api_key_openai: función que permite verificar que la clave de OpenAI está bien cargada\n",
    "\n",
    "#from src.tokens_por_posicion import token_at\n",
    "# token_at: función propia para extraer tokens desde una posición específica (seguramente NLP)\n",
    "\n",
    "#from secrets_local import TOKENS\n",
    "# TOKENS: contiene claves o tokens de autenticación (como API keys privadas). ¡Nunca subir este archivo a repos públicos!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XqUyEy8PD0D"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# Esto tiene formato de código\n",
    "```\n",
    "\n",
    "## Data frame unificado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c5CGykGfpmM"
   },
   "outputs": [],
   "source": [
    "from serpapi.google_search import GoogleSearch\n",
    "import pandas as pd\n",
    "SerpAPI_tkn1 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VtEFKM1kACAW",
    "outputId": "9e08cf54-12b9-4424-b15c-a85f8f162b0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Buscando en El Tiempo: paro maestros 2023\n",
      "📰 Encontrados 15 artículos en El Tiempo\n",
      "\n",
      "🔍 Buscando en El Tiempo: paro nacional docentes 2023\n",
      "📰 Encontrados 15 artículos en El Tiempo\n",
      "\n",
      "🔍 Buscando en El Tiempo: ADE 2023\n",
      "📰 Encontrados 15 artículos en El Tiempo\n",
      "\n",
      "🔍 Buscando en El Tiempo: FECODE 2023\n",
      "📰 Encontrados 15 artículos en El Tiempo\n",
      "\n",
      "🔍 Buscando en ADE: paro docentes\n",
      "📰 Encontrados 0 artículos en ADE\n",
      "\n",
      "🔍 Buscando en ADE: paro maestros\n",
      "📰 Encontrados 0 artículos en ADE\n",
      "\n",
      "🔍 Buscando en ADE: Fecode\n",
      "📰 Encontrados 0 artículos en ADE\n",
      "\n",
      "🔍 Buscando en ADE: educación Bogotá\n",
      "📰 Encontrados 0 artículos en ADE\n",
      "\n",
      "🔍 Buscando en FECODE: paro nacional\n",
      "❌ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=paro+nacional\n",
      "\n",
      "🔍 Buscando en FECODE: paro docentes\n",
      "❌ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=paro+docentes\n",
      "\n",
      "🔍 Buscando en FECODE: maestros\n",
      "❌ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=maestros\n",
      "\n",
      "🔍 Buscando en FECODE: educación Colombia\n",
      "❌ Error en FECODE: 404 Client Error: Not Found for url: https://fecode.edu.co/component/search/?searchword=educaci%C3%B3n+Colombia\n",
      "✅ GoogleNews: 100 resultados\n",
      "\n",
      "🔍 Buscando con SerpAPI...\n",
      "  • (\"suspensión de clases\" OR \"cese de actividades\" OR \"interrupción académica\") Bogotá 2023\n",
      "  • (\"paro de maestros\" OR \"paro docente\" OR \"huelga de profesores\" OR \"protesta de docentes\") Bogotá 2023\n",
      "  • (\"interrupción de clases\" OR \"cancelación de clases\" OR \"no hay clases\") Bogotá 2023\n",
      "  • (\"sindicato de maestros\" OR \"FECODE\" OR \"ADE Bogotá\") AND (paro OR huelga OR protesta) 2023\n",
      "✅ SerpAPI: 40 resultados\n",
      "\n",
      "📊 Total de noticias combinadas: 140\n",
      "💾 Guardado en noticias_paros_docentes_2023.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote_plus\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from GoogleNews import GoogleNews\n",
    "from serpapi import GoogleSearch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# 🔹 FUNCIONES DE SCRAPING\n",
    "# ===================================================\n",
    "\n",
    "def buscar_noticias_generales(nombre_fuente, url_base, termino_busqueda, max_resultados=15):\n",
    "    \"\"\"Scrapea noticias desde sitios como El Tiempo, ADE o FECODE.\"\"\"\n",
    "    print(f\"\\n🔍 Buscando en {nombre_fuente}: {termino_busqueda}\")\n",
    "    datos = []\n",
    "    termino_codificado = quote_plus(termino_busqueda)\n",
    "    url_busqueda = f\"{url_base}{termino_codificado}\"\n",
    "\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url_busqueda, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        articulos = soup.find_all('article', limit=max_resultados)\n",
    "        print(f\"📰 Encontrados {len(articulos)} artículos en {nombre_fuente}\")\n",
    "\n",
    "        for articulo in articulos:\n",
    "            titulo = articulo.find('h2').get_text(strip=True) if articulo.find('h2') else \"\"\n",
    "            descripcion = articulo.find('p').get_text(strip=True) if articulo.find('p') else \"\"\n",
    "            link_elem = articulo.find('a', href=True)\n",
    "            link = link_elem['href'] if link_elem else \"\"\n",
    "            if link and not link.startswith('http'):\n",
    "                link = f\"{url_base.rstrip('/')}/{link.lstrip('/')}\"\n",
    "            fecha_elem = articulo.find('time')\n",
    "            fecha = fecha_elem.get_text(strip=True) if fecha_elem else 'N/A'\n",
    "\n",
    "            if titulo and len(titulo) > 10:\n",
    "                datos.append({\n",
    "                    'titulo': titulo,\n",
    "                    'fuente': nombre_fuente,\n",
    "                    'fecha_publicacion': fecha,\n",
    "                    'descripcion': descripcion,\n",
    "                    'url': link,\n",
    "                    'periodo_busqueda': termino_busqueda,\n",
    "                    'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error en {nombre_fuente}: {e}\")\n",
    "    return datos\n",
    "\n",
    "\n",
    "def buscar_con_googlenews():\n",
    "    \"\"\"Extrae resultados desde GoogleNews API.\"\"\"\n",
    "    googlenews = GoogleNews(lang='es', encode='utf-8')\n",
    "    googlenews.set_time_range('01/01/2023', '12/31/2023')\n",
    "    queries = [\n",
    "        '\"paro de docentes\" Bogotá \"clases suspendidas 2023\"',\n",
    "        '(paro OR \"cese de actividades 2023\") AND (docentes OR maestros) AND Bogotá',\n",
    "        '\"estudiantes sin clase 2023\" AND paro Bogotá 2023',\n",
    "        '\"suspensión de clases\" AND docentes Bogotá'\n",
    "    ]\n",
    "    resultados = []\n",
    "    for q in queries:\n",
    "        googlenews.search(q)\n",
    "        time.sleep(random.uniform(2, 4))\n",
    "        res = googlenews.result()\n",
    "        for r in res:\n",
    "            resultados.append({\n",
    "                'titulo': r.get('title'),\n",
    "                'fuente': r.get('media'),\n",
    "                'fecha_publicacion': r.get('date'),\n",
    "                'descripcion': '',\n",
    "                'url': r.get('link'),\n",
    "                'periodo_busqueda': q,\n",
    "                'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            })\n",
    "    print(f\"✅ GoogleNews: {len(resultados)} resultados\")\n",
    "    return resultados\n",
    "\n",
    "\n",
    "def buscar_con_serpapi(api_key):\n",
    "    \"\"\"Busca en Google usando SerpAPI y devuelve resultados compatibles.\"\"\"\n",
    "    print(\"\\n🔍 Buscando con SerpAPI...\")\n",
    "    queries = [\n",
    "        '(\"suspensión de clases\" OR \"cese de actividades\" OR \"interrupción académica\") Bogotá 2023',\n",
    "        '(\"paro de maestros\" OR \"paro docente\" OR \"huelga de profesores\" OR \"protesta de docentes\") Bogotá 2023',\n",
    "        '(\"interrupción de clases\" OR \"cancelación de clases\" OR \"no hay clases\") Bogotá 2023',\n",
    "        '(\"sindicato de maestros\" OR \"FECODE\" OR \"ADE Bogotá\") AND (paro OR huelga OR protesta) 2023',\n",
    "    ]\n",
    "    resultados = []\n",
    "    for query in queries:\n",
    "        print(f\"  • {query}\")\n",
    "        params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"q\": f\"{query} after:2023-01-01 before:2023-12-31\",\n",
    "            \"api_key\": api_key,\n",
    "            \"num\": 50,\n",
    "        }\n",
    "        try:\n",
    "            search = GoogleSearch(params)\n",
    "            results = search.get_dict()\n",
    "            items = results.get(\"organic_results\", [])\n",
    "            for item in items:\n",
    "                resultados.append({\n",
    "                    'titulo': item.get('title'),\n",
    "                    'fuente': 'Google (SerpAPI)',\n",
    "                    'fecha_publicacion': '',\n",
    "                    'descripcion': item.get('snippet', ''),\n",
    "                    'url': item.get('link'),\n",
    "                    'periodo_busqueda': query,\n",
    "                    'fecha_extraccion': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error con SerpAPI en query '{query}': {e}\")\n",
    "    print(f\"✅ SerpAPI: {len(resultados)} resultados\")\n",
    "    return resultados\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# 🔹 EJECUCIÓN PRINCIPAL\n",
    "# ===================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 👇 pon aquí tu clave de SerpAPI\n",
    "    SerpAPI_tkn1 = \"72ce14c7c062bc7f84a14cdaad42d0773fe66be22644e6addfa422cce5d12417\"\n",
    "\n",
    "    resultados_totales = []\n",
    "\n",
    "    # --- El Tiempo ---\n",
    "    terminos_tiempo = [\"paro maestros 2023\", \"paro nacional docentes 2023\", \"ADE 2023\", \"FECODE 2023\"]\n",
    "    for termino in terminos_tiempo:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"El Tiempo\", \"https://www.eltiempo.com/buscar/\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- ADE ---\n",
    "    terminos_ade = [\"paro docentes\", \"paro maestros\", \"Fecode\", \"educación Bogotá\"]\n",
    "    for termino in terminos_ade:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"ADE\", \"https://adebogota.org/?s=\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- FECODE ---\n",
    "    terminos_fecode = [\"paro nacional\", \"paro docentes\", \"maestros\", \"educación Colombia\"]\n",
    "    for termino in terminos_fecode:\n",
    "        resultados_totales.extend(buscar_noticias_generales(\"FECODE\", \"https://www.fecode.edu.co/index.php/component/search/?searchword=\", termino))\n",
    "        time.sleep(random.uniform(3, 6))\n",
    "\n",
    "    # --- GoogleNews ---\n",
    "    resultados_totales.extend(buscar_con_googlenews())\n",
    "\n",
    "    # --- SerpAPI ---\n",
    "    resultados_totales.extend(buscar_con_serpapi(SerpAPI_tkn1))\n",
    "\n",
    "    # ===================================================\n",
    "    # 🔹 Unir todo y guardar CSV\n",
    "    # ===================================================\n",
    "    df = pd.DataFrame(resultados_totales)\n",
    "    print(f\"\\n📊 Total de noticias combinadas: {len(df)}\")\n",
    "\n",
    "    df.to_csv(\"noticias_paros_docentes_2023.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "    print(\"💾 Guardado en noticias_paros_docentes_2023.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
