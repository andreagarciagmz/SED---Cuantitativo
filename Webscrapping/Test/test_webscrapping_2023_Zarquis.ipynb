{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\anaconda\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in d:\\anaconda\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\anaconda\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\anaconda\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: openpyxl in d:\\anaconda\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in d:\\anaconda\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\anaconda\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Collecting newspaper3k\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (4.12.3)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (6.0.1)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (5.2.1)\n",
      "Requirement already satisfied: nltk>=3.2.1 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (3.9.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (2.32.3)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Downloading feedparser-6.0.12-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (5.1.2)\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "     ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "     ------------ --------------------------- 2.4/7.4 MB 12.2 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 5.0/7.4 MB 12.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  7.3/7.4 MB 11.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.4/7.4 MB 10.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in d:\\anaconda\\lib\\site-packages (from newspaper3k) (2.9.0.post0)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\anaconda\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: click in d:\\anaconda\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
      "Requirement already satisfied: joblib in d:\\anaconda\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.66.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2024.8.30)\n",
      "Requirement already satisfied: requests-file>=1.4 in d:\\anaconda\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in d:\\anaconda\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.6)\n",
      "Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "Downloading feedparser-6.0.12-py3-none-any.whl (81 kB)\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13566 sha256=5e25b2b532ebb69a45ec938d6d677d97abf8b955817ec95b6f4b0ec2184ab76e\n",
      "  Stored in directory: c:\\users\\usuario\\appdata\\local\\pip\\cache\\wheels\\a5\\91\\9f\\00d66475960891a64867914273fcaf78df6cb04d905b104a2a\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3358 sha256=507499fa99d8f41b03d9d875e517b9e89d3fab0d8691375f6e0b7ecf46ce34b3\n",
      "  Stored in directory: c:\\users\\usuario\\appdata\\local\\pip\\cache\\wheels\\9f\\9f\\fb\\364871d7426d3cdd4d293dcf7e53d97f160c508b2ccf00cc79\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398386 sha256=4034fac36f54874ab8938248ed07f926ebe72043574319f17d2d33eac7f9f45e\n",
      "  Stored in directory: c:\\users\\usuario\\appdata\\local\\pip\\cache\\wheels\\26\\72\\f7\\fff392a8d4ea988dea4ccf9788599d09462a7f5e51e04f8a92\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6060 sha256=863b77bd41e6ac2046b24b808e7532cb467ff2c4d26ec48a0678f47c7d6767e4\n",
      "  Stored in directory: c:\\users\\usuario\\appdata\\local\\pip\\cache\\wheels\\03\\f5\\1a\\23761066dac1d0e8e683e5fdb27e12de53209d05a4a37e6246\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: tinysegmenter, sgmllib3k, jieba3k, feedparser, feedfinder2, newspaper3k\n",
      "Successfully installed feedfinder2-0.0.4 feedparser-6.0.12 jieba3k-0.35.1 newspaper3k-0.2.8 sgmllib3k-1.0.0 tinysegmenter-0.3\n",
      "Collecting selenium\n",
      "  Downloading selenium-4.36.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting urllib3<3.0,>=2.5.0 (from urllib3[socks]<3.0,>=2.5.0->selenium)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting trio<1.0,>=0.30.0 (from selenium)\n",
      "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting certifi>=2025.6.15 (from selenium)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting typing_extensions<5.0,>=4.14.0 (from selenium)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in d:\\anaconda\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Collecting attrs>=23.2.0 (from trio<1.0,>=0.30.0->selenium)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: sortedcontainers in d:\\anaconda\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in d:\\anaconda\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (3.7)\n",
      "Collecting outcome (from trio<1.0,>=0.30.0->selenium)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in d:\\anaconda\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.14 in d:\\anaconda\\lib\\site-packages (from trio<1.0,>=0.30.0->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in d:\\anaconda\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in d:\\anaconda\\lib\\site-packages (from cffi>=1.14->trio<1.0,>=0.30.0->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in d:\\anaconda\\lib\\site-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.14.0)\n",
      "Downloading selenium-4.36.0-py3-none-any.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/9.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.7/9.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.3/9.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 12.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 9.6 MB/s eta 0:00:00\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: wsproto, urllib3, typing_extensions, certifi, attrs, outcome, trio, trio-websocket, selenium\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.3\n",
      "    Uninstalling urllib3-2.2.3:\n",
      "      Successfully uninstalled urllib3-2.2.3\n",
      "  Attempting uninstall: typing_extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2024.8.30\n",
      "    Uninstalling certifi-2024.8.30:\n",
      "      Successfully uninstalled certifi-2024.8.30\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 23.1.0\n",
      "    Uninstalling attrs-23.1.0:\n",
      "      Successfully uninstalled attrs-23.1.0\n",
      "Successfully installed attrs-25.4.0 certifi-2025.10.5 outcome-1.3.0.post0 selenium-4.36.0 trio-0.31.0 trio-websocket-0.12.2 typing_extensions-4.15.0 urllib3-2.5.0 wsproto-1.2.0\n",
      "Collecting openai\n",
      "  Downloading openai-2.3.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from openai) (0.27.0)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\anaconda\\lib\\site-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anaconda\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\anaconda\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\anaconda\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\anaconda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in d:\\anaconda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "Requirement already satisfied: colorama in d:\\anaconda\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-2.3.0-py3-none-any.whl (999 kB)\n",
      "   ---------------------------------------- 0.0/999.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 999.8/999.8 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading jiter-0.11.0-cp312-cp312-win_amd64.whl (203 kB)\n",
      "Installing collected packages: jiter, openai\n",
      "Successfully installed jiter-0.11.0 openai-2.3.0\n",
      "Collecting serpapi\n",
      "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests in d:\\anaconda\\lib\\site-packages (from serpapi) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda\\lib\\site-packages (from requests->serpapi) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests->serpapi) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests->serpapi) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests->serpapi) (2025.10.5)\n",
      "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: serpapi\n",
      "Successfully installed serpapi-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install openpyxl\n",
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install newspaper3k\n",
    "!pip install selenium\n",
    "!pip install openai\n",
    "!pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install googlesearch-python\n",
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in /opt/anaconda3/lib/python3.11/site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (from google-search-results) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests->google-search-results) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests->google-search-results) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests->google-search-results) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests->google-search-results) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"httpx[http2]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchrome\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Options  \u001b[38;5;66;03m# Configurar opciones para Chrome (modo sin cabeza, user-agent, etc.)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m  \u001b[38;5;66;03m# Cliente oficial para acceder a la API de OpenAI (ChatGPT, GPT-4, etc.)\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokens_por_posicion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m token_at\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Librerías estándar (de Python) ---\n",
    "import os  # Acceso a funcionalidades del sistema operativo (rutas, variables de entorno, etc.)\n",
    "import re  # Permite trabajar con expresiones regulares (búsqueda de patrones en texto)\n",
    "import time  # Funciones relacionadas con el tiempo (pausas, medir duración, timestamps)\n",
    "import json  # Para trabajar con archivos y datos en formato JSON\n",
    "import tempfile  # Crear archivos/directorios temporales (útil para manejo temporal de datos)\n",
    "from typing import Dict, List  # Anotaciones de tipo para funciones (mejor legibilidad y autocompletado)\n",
    "from pathlib import Path  # Manejo de rutas de archivos y carpetas de forma más moderna y robusta\n",
    "from GoogleNews import GoogleNews\n",
    "\n",
    "# --- Librerías externas (instaladas con pip) ---\n",
    "import pandas as pd  # Análisis y manipulación de datos tabulares (Excel, CSV, DataFrames, etc.)\n",
    "\n",
    "import openpyxl  # Librería para leer y escribir archivos Excel (.xlsx)\n",
    "from openpyxl import load_workbook  # Cargar y modificar libros de Excel ya existentes\n",
    "\n",
    "import requests  # Realizar peticiones HTTP (GET, POST, etc.) para acceder a contenido web o APIs\n",
    "from urllib.parse import urlparse, parse_qs, unquote\n",
    "from bs4 import BeautifulSoup  # Analizar y extraer información de HTML (web scraping)\n",
    "\n",
    "from newspaper import Article  # Extraer automáticamente información estructurada de artículos web (título, texto, etc.)\n",
    "\n",
    "from selenium import webdriver  # Controlar un navegador web desde Python (automatización para scraping dinámico)\n",
    "from selenium.webdriver.chrome.options import Options  # Configurar opciones para Chrome (modo sin cabeza, user-agent, etc.)\n",
    "\n",
    "import openai  # Cliente oficial para acceder a la API de OpenAI (ChatGPT, GPT-4, etc.)\n",
    "\n",
    "from src.tokens_por_posicion import token_at\n",
    "\n",
    "#from serpapi import GoogleSearch  # Realizar búsquedas en Google a través de la API de SerpAPI (scraping sin bloquearse)\n",
    "\n",
    "# --- Módulos locales del proyecto ---\n",
    "#from src.functions import completar, _debug_api_key_openai\n",
    "# completar: función personalizada (probablemente genera texto con GPT u otra IA)\n",
    "# _debug_api_key_openai: función que permite verificar que la clave de OpenAI está bien cargada\n",
    "\n",
    "#from src.tokens_por_posicion import token_at\n",
    "# token_at: función propia para extraer tokens desde una posición específica (seguramente NLP)\n",
    "\n",
    "#from secrets_local import TOKENS\n",
    "# TOKENS: contiene claves o tokens de autenticación (como API keys privadas). ¡Nunca subir este archivo a repos públicos!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            query  \\\n",
      "0  \"paro de docentes\" Bogotá \"clases suspendidas\"   \n",
      "1  \"paro de docentes\" Bogotá \"clases suspendidas\"   \n",
      "2  \"paro de docentes\" Bogotá \"clases suspendidas\"   \n",
      "3  \"paro de docentes\" Bogotá \"clases suspendidas\"   \n",
      "4  \"paro de docentes\" Bogotá \"clases suspendidas\"   \n",
      "\n",
      "                                               title               media  \\\n",
      "0  Soacha suspende clases presenciales por paro d...  Noticias Día a Día   \n",
      "1  Suspenden clases presenciales en Soacha por pa...    Soacha Ilustrada   \n",
      "2  Suspensión de clases presenciales en instituci...  Alcaldia de Soacha   \n",
      "3  Colegios oficiales de Soacha suspenden clases ...    Noticias Caracol   \n",
      "4  Soacha suspende clases presenciales por paro d...       Q´hubo Bogotá   \n",
      "\n",
      "         date                                               link  \n",
      "0  Hace 1 mes  https://www.noticiasdiaadia.com/cundinamarca/s...  \n",
      "1  Hace 1 mes  https://soachailustrada.com/59317/&ved=2ahUKEw...  \n",
      "2  Hace 1 mes  https://www.alcaldiasoacha.gov.co/Noticias/Pag...  \n",
      "3  Hace 1 mes  https://www.noticiascaracol.com/colombia/coleg...  \n",
      "4  Hace 1 mes  https://www.qhubobogota.com/asi-paso/soacha-su...  \n",
      "📁 Resultados guardados en paros_docentes_bogota_2023.csv\n"
     ]
    }
   ],
   "source": [
    "from GoogleNews import GoogleNews\n",
    "import pandas as pd\n",
    "\n",
    "# Inicializamos GoogleNews en español\n",
    "googlenews = GoogleNews(lang='es', encode='utf-8')\n",
    "\n",
    "# Establecer rango de fechas: todo 2023\n",
    "googlenews.set_time_range('01/01/2023', '12/31/2023')\n",
    "\n",
    "# Consultas específicas\n",
    "queries = [\n",
    "    '\"paro de docentes\" Bogotá \"clases suspendidas\"',\n",
    "    '(paro OR \"cese de actividades\") AND (docentes OR maestros) AND Bogotá',\n",
    "    '\"estudiantes sin clase\" AND paro Bogotá',\n",
    "    '\"suspensión de clases\" AND docentes Bogotá'\n",
    "]\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for q in queries:\n",
    "    googlenews.search(q)\n",
    "    results = googlenews.result()\n",
    "    for r in results:\n",
    "        all_results.append({\n",
    "            'query': q,\n",
    "            'title': r.get('title'),\n",
    "            'media': r.get('media'),\n",
    "            'date': r.get('date'),\n",
    "            'link': r.get('link')\n",
    "        })\n",
    "\n",
    "# Guardar en DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "print(df.head())\n",
    "\n",
    "# Exportar a CSV\n",
    "df.to_csv(\"paros_docentes_bogota_2023.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "print(\"📁 Resultados guardados en paros_docentes_bogota_2023.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi.google_search import GoogleSearch\n",
    "import pandas as pd\n",
    "SerpAPI_tkn1 = '0a6f749d6af6ba0055e057b875da0b68d4938d4027e6eb27e34c2aff0f81c59f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Iniciando búsqueda en SerpApi con consulta simple...\n",
      "✅ Búsqueda completada.\n",
      "\n",
      "--- ¡Resultados Encontrados! ---\n",
      "\n",
      "                                               title  \\\n",
      "0  Paro nacional de profesores, 30 de agosto de 2...   \n",
      "1  Los maestros en Colombia no podrían volver a paro   \n",
      "2  Protestas en Colombia Defensoría reporta aumen...   \n",
      "3                      CIRCULAR No. 004 de 2023 PARA   \n",
      "4  RPC Radio | El @meducapma informó la suspensió...   \n",
      "5  Protesta de profesores en Bogotá: así avanza l...   \n",
      "6       Marchas HOY 28 de marzo Bogotá: Minuto a ...   \n",
      "7  Conflictos sociales en Colombia: 34 eventos se...   \n",
      "8  Sala Laboral señala que no puede haber una pro...   \n",
      "9  Concepto 217971 de 2023 Departamento Administr...   \n",
      "\n",
      "                                                link  \\\n",
      "0  https://www.elpais.com.co/colombia/paro-nacion...   \n",
      "1  https://www.infobae.com/colombia/2023/08/02/pa...   \n",
      "2  https://www.eltiempo.com/justicia/investigacio...   \n",
      "3  https://www.educacionbogota.edu.co/portal_inst...   \n",
      "4           https://www.instagram.com/p/CyzPDt9tg_j/   \n",
      "5  https://www.alertabogota.com/noticias/local/pr...   \n",
      "6  https://caracol.com.co/2023/03/28/marchas-hoy-...   \n",
      "7  https://www.infobae.com/colombia/2023/09/28/co...   \n",
      "8  https://cortesuprema.gov.co/sala-laboral-senal...   \n",
      "9  https://www.funcionpublica.gov.co/eva/gestorno...   \n",
      "\n",
      "                                             snippet  \n",
      "0  Las protestas saldrán desde las 9:30 a.m., el ...  \n",
      "1  “Empezaron en 2018 con un cese de actividades ...  \n",
      "2  ... cese de actividades (4 por ciento); y en e...  \n",
      "3  Las actividades programadas previamente en el ...  \n",
      "4  El @meducapma informó la suspensión de clases ...  \n",
      "5  Los docentes hacen un cese de actividades de d...  \n",
      "6  Este martes 28 de marzo, la Asociación Distrit...  \n",
      "7  Marchas y movilizaciones. Paros cívicos. Cese ...  \n",
      "8  Bogotá, D.C., martes 24 de octubre de 2023. Pe...  \n",
      "9  ... cese de actividades en la alcaldía? le ind...  \n",
      "\n",
      "------------------------------\n",
      "\n",
      "📁 Resultados guardados en test_serpapi_simple_resultados.csv\n"
     ]
    }
   ],
   "source": [
    "query = (\n",
    "    '(\"paro docentes\" OR \"suspensión de clases\" OR \"cese de actividades\") '\n",
    "    'Bogotá 2023'\n",
    ")\n",
    "\n",
    "# ⚙️ Parámetros de la Búsqueda\n",
    "params = {\n",
    "    \"engine\": \"google\",\n",
    "    # Mantenemos el filtro de fecha de 2023\n",
    "    \"q\": f\"{query} after:2023-01-01 before:2023-12-31\", \n",
    "    \"api_key\": SerpAPI_tkn1,\n",
    "    \"num\": 50   # Pedimos 10 resultados\n",
    "}\n",
    "\n",
    "# 🚀 Ejecutar la Búsqueda\n",
    "print(\"🔍 Iniciando búsqueda en SerpApi con consulta simple...\")\n",
    "try:\n",
    "    search = GoogleSearch(params)\n",
    "    results = search.get_dict()\n",
    "    print(\"✅ Búsqueda completada.\")\n",
    "\n",
    "    # 📊 Procesar Resultados Orgánicos\n",
    "    items = results.get(\"organic_results\", [])\n",
    "    df = pd.DataFrame(items)\n",
    "\n",
    "    # 💾 Guardar y Mostrar\n",
    "    if not df.empty:\n",
    "        # Seleccionar solo las columnas de interés\n",
    "        df = df[[\"title\", \"link\", \"snippet\"]]\n",
    "        \n",
    "        print(\"\\n--- ¡Resultados Encontrados! ---\\n\")\n",
    "        print(df)\n",
    "        \n",
    "        # Guardar en CSV\n",
    "        df.to_csv(\"test_serpapi_simple_resultados.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "        print(\"\\n------------------------------\\n\")\n",
    "        print(\"📁 Resultados guardados en test_serpapi_simple_resultados.csv\")\n",
    "    else:\n",
    "        print(\"\\n------------------------------\\n\")\n",
    "        print(\"⚠️ No se encontraron resultados. El problema podría ser la clave API o el saldo.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Ocurrió un error al ejecutar la búsqueda: {e}\")\n",
    "    print(\"Esto casi siempre indica una clave API incorrecta, sin saldo o un problema de red.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (230884762.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[102], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    except Exception as e:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from serpapi.google_search import GoogleSearch\n",
    "\n",
    "# Reemplaza con tu propia API key\n",
    "api_key = \"3473fc2d447c6d1244dd8112d79b8d89fb79aa7a\"\n",
    "\n",
    "# Parámetros para la búsqueda\n",
    "params = {\n",
    "    \"engine\": \"google\",\n",
    "    \"q\": \"paros docentes en 2023\",\n",
    "    \"location\": \"Colombia\",  # Cambia si quieres otra región\n",
    "    \"hl\": \"es\",               # Idioma español\n",
    "    \"gl\": \"col\",               # Resultados de Google Argentina\n",
    "    \"api_key\": api_key,\n",
    "}\n",
    "\n",
    "# Realizar la búsqueda\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "\n",
    "# Extraer resultados orgánicos (pueden incluir noticias o páginas web)\n",
    "for i, result in enumerate(results.get(\"organic_results\", []), start=1):\n",
    "    title = result.get(\"title\")\n",
    "    link = result.get(\"link\")\n",
    "    snippet = result.get(\"snippet\", \"\")\n",
    "    print(f\"{i}. {title}\\n   {link}\\n   {snippet}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"error\": \"Invalid API key. Your API key should be here: https://serpapi.com/manage-api-key\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from serpapi.google_search import GoogleSearch\n",
    "\n",
    "params = {\n",
    "    \"engine\": \"google\",\n",
    "    \"q\": \"paro docente 2023\",\n",
    "    \"api_key\": \"3473fc2d447c6d1244dd8112d79b8d89fb79aa7a\"\n",
    "}\n",
    "\n",
    "search = GoogleSearch(params)\n",
    "results = search.get_dict()\n",
    "\n",
    "# Mostrar todo lo que devuelve la API\n",
    "import json\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
